2023-04-27 09:28:34,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-27 09:28:34,116:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-27 09:28:34,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-27 09:28:34,117:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-27 09:28:35,565:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-27 09:29:45,776:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-27 09:29:45,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-27 09:29:45,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-27 09:29:45,777:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-27 09:29:48,133:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-04-27 09:30:27,174:INFO:PyCaret ClassificationExperiment
2023-04-27 09:30:27,175:INFO:Logging name: clf-default-name
2023-04-27 09:30:27,175:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-27 09:30:27,175:INFO:version 3.0.0
2023-04-27 09:30:27,175:INFO:Initializing setup()
2023-04-27 09:30:27,176:INFO:self.USI: 5534
2023-04-27 09:30:27,176:INFO:self._variable_keys: {'data', 'fold_groups_param', 'exp_id', 'html_param', 'fold_shuffle_param', 'fix_imbalance', 'X', 'is_multiclass', 'gpu_n_jobs_param', 'idx', 'y', '_available_plots', 'logging_param', 'n_jobs_param', 'fold_generator', 'X_test', 'y_test', 'seed', 'y_train', '_ml_usecase', 'log_plots_param', 'USI', 'exp_name_log', 'memory', 'X_train', 'target_param', 'gpu_param', 'pipeline'}
2023-04-27 09:30:27,177:INFO:Checking environment
2023-04-27 09:30:27,178:INFO:python_version: 3.10.10
2023-04-27 09:30:27,178:INFO:python_build: ('main', 'Mar 24 2023 20:00:38')
2023-04-27 09:30:27,178:INFO:machine: AMD64
2023-04-27 09:30:27,178:INFO:platform: Windows-10-10.0.19041-SP0
2023-04-27 09:30:27,184:INFO:Memory: svmem(total=8375230464, available=570138624, percent=93.2, used=7805091840, free=570138624)
2023-04-27 09:30:27,185:INFO:Physical Core: 4
2023-04-27 09:30:27,185:INFO:Logical Core: 8
2023-04-27 09:30:27,185:INFO:Checking libraries
2023-04-27 09:30:27,185:INFO:System:
2023-04-27 09:30:27,185:INFO:    python: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:00:38) [MSC v.1934 64 bit (AMD64)]
2023-04-27 09:30:27,185:INFO:executable: c:\Users\vande\anaconda3\envs\article\python.exe
2023-04-27 09:30:27,185:INFO:   machine: Windows-10-10.0.19041-SP0
2023-04-27 09:30:27,186:INFO:PyCaret required dependencies:
2023-04-27 09:30:27,186:INFO:                 pip: 23.1.2
2023-04-27 09:30:27,186:INFO:          setuptools: 67.7.2
2023-04-27 09:30:27,186:INFO:             pycaret: 3.0.0
2023-04-27 09:30:27,186:INFO:             IPython: 8.12.0
2023-04-27 09:30:27,186:INFO:          ipywidgets: 8.0.6
2023-04-27 09:30:27,186:INFO:                tqdm: 4.65.0
2023-04-27 09:30:27,186:INFO:               numpy: 1.23.5
2023-04-27 09:30:27,187:INFO:              pandas: 1.5.3
2023-04-27 09:30:27,187:INFO:              jinja2: 3.1.2
2023-04-27 09:30:27,187:INFO:               scipy: 1.10.1
2023-04-27 09:30:27,187:INFO:              joblib: 1.2.0
2023-04-27 09:30:27,187:INFO:             sklearn: 1.2.2
2023-04-27 09:30:27,187:INFO:                pyod: 1.0.9
2023-04-27 09:30:27,187:INFO:            imblearn: 0.10.1
2023-04-27 09:30:27,187:INFO:   category_encoders: 2.6.0
2023-04-27 09:30:27,187:INFO:            lightgbm: 3.3.5
2023-04-27 09:30:27,188:INFO:               numba: 0.56.4
2023-04-27 09:30:27,188:INFO:            requests: 2.29.0
2023-04-27 09:30:27,188:INFO:          matplotlib: 3.7.1
2023-04-27 09:30:27,188:INFO:          scikitplot: 0.3.7
2023-04-27 09:30:27,188:INFO:         yellowbrick: 1.5
2023-04-27 09:30:27,188:INFO:              plotly: 5.14.1
2023-04-27 09:30:27,188:INFO:             kaleido: 0.2.1
2023-04-27 09:30:27,188:INFO:         statsmodels: 0.13.5
2023-04-27 09:30:27,188:INFO:              sktime: 0.17.2
2023-04-27 09:30:27,188:INFO:               tbats: 1.1.3
2023-04-27 09:30:27,188:INFO:            pmdarima: 2.0.3
2023-04-27 09:30:27,189:INFO:              psutil: 5.9.5
2023-04-27 09:30:27,189:INFO:PyCaret optional dependencies:
2023-04-27 09:30:27,212:INFO:                shap: Not installed
2023-04-27 09:30:27,213:INFO:           interpret: Not installed
2023-04-27 09:30:27,213:INFO:                umap: Not installed
2023-04-27 09:30:27,213:INFO:    pandas_profiling: Not installed
2023-04-27 09:30:27,213:INFO:  explainerdashboard: Not installed
2023-04-27 09:30:27,213:INFO:             autoviz: Not installed
2023-04-27 09:30:27,213:INFO:           fairlearn: Not installed
2023-04-27 09:30:27,213:INFO:             xgboost: Not installed
2023-04-27 09:30:27,213:INFO:            catboost: Not installed
2023-04-27 09:30:27,213:INFO:              kmodes: Not installed
2023-04-27 09:30:27,213:INFO:             mlxtend: Not installed
2023-04-27 09:30:27,213:INFO:       statsforecast: Not installed
2023-04-27 09:30:27,213:INFO:        tune_sklearn: Not installed
2023-04-27 09:30:27,213:INFO:                 ray: Not installed
2023-04-27 09:30:27,213:INFO:            hyperopt: Not installed
2023-04-27 09:30:27,213:INFO:              optuna: Not installed
2023-04-27 09:30:27,214:INFO:               skopt: Not installed
2023-04-27 09:30:27,214:INFO:              mlflow: Not installed
2023-04-27 09:30:27,214:INFO:              gradio: Not installed
2023-04-27 09:30:27,214:INFO:             fastapi: Not installed
2023-04-27 09:30:27,214:INFO:             uvicorn: Not installed
2023-04-27 09:30:27,214:INFO:              m2cgen: Not installed
2023-04-27 09:30:27,214:INFO:           evidently: Not installed
2023-04-27 09:30:27,214:INFO:               fugue: Not installed
2023-04-27 09:30:27,214:INFO:           streamlit: Not installed
2023-04-27 09:30:27,214:INFO:             prophet: Not installed
2023-04-27 09:30:27,214:INFO:None
2023-04-27 09:30:27,214:INFO:Set up data.
2023-04-27 09:30:27,330:INFO:Set up train/test split.
2023-04-27 09:30:27,403:INFO:Set up index.
2023-04-27 09:30:27,403:INFO:Set up folding strategy.
2023-04-27 09:30:27,403:INFO:Assigning column types.
2023-04-27 09:30:27,409:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-27 09:30:27,492:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-27 09:30:27,499:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-27 09:30:27,556:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:27,592:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:27,653:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-27 09:30:27,654:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-27 09:30:27,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:27,696:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:27,697:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-27 09:30:27,776:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-27 09:30:27,835:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:27,836:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:27,931:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-27 09:30:27,974:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:27,975:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:27,975:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-27 09:30:28,079:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:28,079:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:28,180:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:28,180:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:28,185:INFO:Preparing preprocessing pipeline...
2023-04-27 09:30:28,187:INFO:Set up label encoding.
2023-04-27 09:30:28,187:INFO:Set up simple imputation.
2023-04-27 09:30:28,192:INFO:Set up encoding of categorical features.
2023-04-27 09:30:29,518:INFO:Finished creating preprocessing pipeline.
2023-04-27 09:30:29,533:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vande\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,...
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None,
                                    include=['index', 'preprocessed_news'],
                                    transformer=LeaveOneOutEncoder(cols=['index',
                                                                         'preprocessed_news'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=8632,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0)))],
         verbose=False)
2023-04-27 09:30:29,533:INFO:Creating final display dataframe.
2023-04-27 09:30:32,418:INFO:Setup _display_container:                     Description             Value
0                    Session id              8632
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, true: 1
4           Original data shape         (7200, 3)
5        Transformed data shape         (7200, 3)
6   Transformed train set shape         (5040, 3)
7    Transformed test set shape         (2160, 3)
8          Categorical features                 2
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              5534
2023-04-27 09:30:32,604:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:32,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:32,749:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:32,750:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:30:32,750:INFO:setup() successfully completed in 5.58s...............
2023-04-27 09:31:20,187:INFO:Initializing compare_models()
2023-04-27 09:31:20,187:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-27 09:31:20,188:INFO:Checking exceptions
2023-04-27 09:31:20,199:INFO:Preparing display monitor
2023-04-27 09:31:20,264:INFO:Initializing Logistic Regression
2023-04-27 09:31:20,264:INFO:Total runtime is 1.6649564107259113e-05 minutes
2023-04-27 09:31:20,273:INFO:SubProcess create_model() called ==================================
2023-04-27 09:31:20,274:INFO:Initializing create_model()
2023-04-27 09:31:20,274:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:31:20,275:INFO:Checking exceptions
2023-04-27 09:31:20,275:INFO:Importing libraries
2023-04-27 09:31:20,275:INFO:Copying training dataset
2023-04-27 09:31:20,287:INFO:Defining folds
2023-04-27 09:31:20,288:INFO:Declaring metric variables
2023-04-27 09:31:20,299:INFO:Importing untrained model
2023-04-27 09:31:20,308:INFO:Logistic Regression Imported successfully
2023-04-27 09:31:20,324:INFO:Starting cross validation
2023-04-27 09:31:20,328:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:31:36,471:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-27 09:31:36,471:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-27 09:31:36,585:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-27 09:31:36,800:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-27 09:31:36,940:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-27 09:31:37,229:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-27 09:31:38,663:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-27 09:31:38,757:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-27 09:31:38,875:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-27 09:31:39,085:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.10s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-27 09:31:39,274:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-27 09:31:39,308:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 1.07s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-04-27 09:31:40,215:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-27 09:31:40,256:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-04-27 09:31:41,894:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:31:41,988:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:31:42,070:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:31:42,176:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:31:42,267:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:31:42,466:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:31:42,476:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:31:42,617:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:31:42,641:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:31:42,664:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:31:42,712:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:31:42,807:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:31:42,853:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:31:42,944:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:31:46,158:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:31:46,315:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:31:46,336:INFO:Calculating mean and std
2023-04-27 09:31:46,339:INFO:Creating metrics dataframe
2023-04-27 09:31:46,393:INFO:Uploading results into container
2023-04-27 09:31:46,396:INFO:Uploading model into container now
2023-04-27 09:31:46,398:INFO:_master_model_container: 1
2023-04-27 09:31:46,399:INFO:_display_container: 2
2023-04-27 09:31:46,401:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8632, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-27 09:31:46,402:INFO:create_model() successfully completed......................................
2023-04-27 09:31:46,550:INFO:SubProcess create_model() end ==================================
2023-04-27 09:31:46,550:INFO:Creating metrics dataframe
2023-04-27 09:31:46,569:INFO:Initializing K Neighbors Classifier
2023-04-27 09:31:46,569:INFO:Total runtime is 0.4384347120920817 minutes
2023-04-27 09:31:46,575:INFO:SubProcess create_model() called ==================================
2023-04-27 09:31:46,575:INFO:Initializing create_model()
2023-04-27 09:31:46,575:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:31:46,576:INFO:Checking exceptions
2023-04-27 09:31:46,576:INFO:Importing libraries
2023-04-27 09:31:46,577:INFO:Copying training dataset
2023-04-27 09:31:46,588:INFO:Defining folds
2023-04-27 09:31:46,588:INFO:Declaring metric variables
2023-04-27 09:31:46,598:INFO:Importing untrained model
2023-04-27 09:31:46,605:INFO:K Neighbors Classifier Imported successfully
2023-04-27 09:31:46,621:INFO:Starting cross validation
2023-04-27 09:31:46,624:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:31:52,002:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:31:52,456:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:31:53,533:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:31:53,815:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:31:54,154:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:31:54,333:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:31:54,373:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:31:54,594:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:31:55,122:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:31:59,807:INFO:Calculating mean and std
2023-04-27 09:31:59,811:INFO:Creating metrics dataframe
2023-04-27 09:31:59,886:INFO:Uploading results into container
2023-04-27 09:31:59,887:INFO:Uploading model into container now
2023-04-27 09:31:59,888:INFO:_master_model_container: 2
2023-04-27 09:31:59,888:INFO:_display_container: 2
2023-04-27 09:31:59,889:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-27 09:31:59,889:INFO:create_model() successfully completed......................................
2023-04-27 09:32:00,022:INFO:SubProcess create_model() end ==================================
2023-04-27 09:32:00,022:INFO:Creating metrics dataframe
2023-04-27 09:32:00,051:INFO:Initializing Naive Bayes
2023-04-27 09:32:00,051:INFO:Total runtime is 0.6631434281667073 minutes
2023-04-27 09:32:00,059:INFO:SubProcess create_model() called ==================================
2023-04-27 09:32:00,060:INFO:Initializing create_model()
2023-04-27 09:32:00,060:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:32:00,060:INFO:Checking exceptions
2023-04-27 09:32:00,060:INFO:Importing libraries
2023-04-27 09:32:00,061:INFO:Copying training dataset
2023-04-27 09:32:00,071:INFO:Defining folds
2023-04-27 09:32:00,071:INFO:Declaring metric variables
2023-04-27 09:32:00,081:INFO:Importing untrained model
2023-04-27 09:32:00,091:INFO:Naive Bayes Imported successfully
2023-04-27 09:32:00,110:INFO:Starting cross validation
2023-04-27 09:32:00,115:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:32:05,101:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:05,102:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:05,194:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:05,195:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:05,333:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:05,333:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:05,461:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:05,461:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:05,487:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:05,515:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:05,573:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:05,573:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:05,590:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:05,590:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:05,602:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:05,603:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:05,621:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:05,641:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:05,660:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:05,660:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:05,668:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:05,669:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:05,722:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:05,722:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:05,793:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:05,814:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:05,984:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:05,985:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:05,992:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:05,992:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:05,994:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:05,994:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:06,005:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:06,022:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:06,030:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:06,031:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:06,036:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:06,037:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:06,052:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:06,056:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:06,059:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:06,082:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:06,087:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:06,351:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:06,352:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:06,361:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:06,382:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:08,265:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:08,266:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:08,375:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:08,375:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:08,498:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:08,498:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:08,500:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:08,520:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:08,610:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:32:08,610:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:32:08,615:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:08,627:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:08,650:INFO:Calculating mean and std
2023-04-27 09:32:08,653:INFO:Creating metrics dataframe
2023-04-27 09:32:08,722:INFO:Uploading results into container
2023-04-27 09:32:08,723:INFO:Uploading model into container now
2023-04-27 09:32:08,723:INFO:_master_model_container: 3
2023-04-27 09:32:08,724:INFO:_display_container: 2
2023-04-27 09:32:08,724:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-27 09:32:08,724:INFO:create_model() successfully completed......................................
2023-04-27 09:32:08,844:INFO:SubProcess create_model() end ==================================
2023-04-27 09:32:08,844:INFO:Creating metrics dataframe
2023-04-27 09:32:08,867:INFO:Initializing Decision Tree Classifier
2023-04-27 09:32:08,867:INFO:Total runtime is 0.8100750128428141 minutes
2023-04-27 09:32:08,873:INFO:SubProcess create_model() called ==================================
2023-04-27 09:32:08,874:INFO:Initializing create_model()
2023-04-27 09:32:08,874:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:32:08,874:INFO:Checking exceptions
2023-04-27 09:32:08,874:INFO:Importing libraries
2023-04-27 09:32:08,874:INFO:Copying training dataset
2023-04-27 09:32:08,885:INFO:Defining folds
2023-04-27 09:32:08,886:INFO:Declaring metric variables
2023-04-27 09:32:08,892:INFO:Importing untrained model
2023-04-27 09:32:08,902:INFO:Decision Tree Classifier Imported successfully
2023-04-27 09:32:08,917:INFO:Starting cross validation
2023-04-27 09:32:08,919:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:32:13,907:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:13,933:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:14,361:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:14,514:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:14,581:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:14,585:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:14,675:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.82s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:14,809:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:14,876:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:14,990:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:15,042:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:15,124:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:15,188:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:15,337:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:15,585:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:17,091:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:17,459:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:17,482:INFO:Calculating mean and std
2023-04-27 09:32:17,485:INFO:Creating metrics dataframe
2023-04-27 09:32:17,569:INFO:Uploading results into container
2023-04-27 09:32:17,571:INFO:Uploading model into container now
2023-04-27 09:32:17,571:INFO:_master_model_container: 4
2023-04-27 09:32:17,571:INFO:_display_container: 2
2023-04-27 09:32:17,572:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=8632, splitter='best')
2023-04-27 09:32:17,572:INFO:create_model() successfully completed......................................
2023-04-27 09:32:17,672:INFO:SubProcess create_model() end ==================================
2023-04-27 09:32:17,673:INFO:Creating metrics dataframe
2023-04-27 09:32:17,693:INFO:Initializing SVM - Linear Kernel
2023-04-27 09:32:17,693:INFO:Total runtime is 0.9571780920028686 minutes
2023-04-27 09:32:17,703:INFO:SubProcess create_model() called ==================================
2023-04-27 09:32:17,703:INFO:Initializing create_model()
2023-04-27 09:32:17,704:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:32:17,704:INFO:Checking exceptions
2023-04-27 09:32:17,704:INFO:Importing libraries
2023-04-27 09:32:17,704:INFO:Copying training dataset
2023-04-27 09:32:17,710:INFO:Defining folds
2023-04-27 09:32:17,710:INFO:Declaring metric variables
2023-04-27 09:32:17,719:INFO:Importing untrained model
2023-04-27 09:32:17,725:INFO:SVM - Linear Kernel Imported successfully
2023-04-27 09:32:17,738:INFO:Starting cross validation
2023-04-27 09:32:17,740:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:32:21,385:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:32:21,423:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:22,043:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:22,122:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:32:22,172:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:22,172:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.84s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:22,191:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:32:22,186:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:32:22,236:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:22,610:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:22,630:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:32:22,668:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:22,975:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:32:23,033:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:32:23,038:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:32:23,070:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:23,076:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:24,618:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:32:24,819:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:32:24,834:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:24,845:INFO:Calculating mean and std
2023-04-27 09:32:24,848:INFO:Creating metrics dataframe
2023-04-27 09:32:24,925:INFO:Uploading results into container
2023-04-27 09:32:24,927:INFO:Uploading model into container now
2023-04-27 09:32:24,927:INFO:_master_model_container: 5
2023-04-27 09:32:24,927:INFO:_display_container: 2
2023-04-27 09:32:24,928:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=8632, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-27 09:32:24,928:INFO:create_model() successfully completed......................................
2023-04-27 09:32:25,025:INFO:SubProcess create_model() end ==================================
2023-04-27 09:32:25,025:INFO:Creating metrics dataframe
2023-04-27 09:32:25,045:INFO:Initializing Ridge Classifier
2023-04-27 09:32:25,045:INFO:Total runtime is 1.079703934987386 minutes
2023-04-27 09:32:25,055:INFO:SubProcess create_model() called ==================================
2023-04-27 09:32:25,056:INFO:Initializing create_model()
2023-04-27 09:32:25,056:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:32:25,056:INFO:Checking exceptions
2023-04-27 09:32:25,057:INFO:Importing libraries
2023-04-27 09:32:25,057:INFO:Copying training dataset
2023-04-27 09:32:25,066:INFO:Defining folds
2023-04-27 09:32:25,066:INFO:Declaring metric variables
2023-04-27 09:32:25,074:INFO:Importing untrained model
2023-04-27 09:32:25,081:INFO:Ridge Classifier Imported successfully
2023-04-27 09:32:25,093:INFO:Starting cross validation
2023-04-27 09:32:25,096:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:32:29,243:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:29,254:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:32:29,320:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:29,490:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:32:29,541:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:29,566:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:29,578:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:32:29,627:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:29,886:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:29,901:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:32:29,924:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:30,201:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:30,211:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:32:30,231:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:30,240:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:30,250:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:32:30,272:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:30,445:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:30,453:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:32:30,473:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:30,503:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:32:30,524:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:32,213:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:32:32,231:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:32,362:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:32:32,377:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:32,393:INFO:Calculating mean and std
2023-04-27 09:32:32,396:INFO:Creating metrics dataframe
2023-04-27 09:32:32,501:INFO:Uploading results into container
2023-04-27 09:32:32,502:INFO:Uploading model into container now
2023-04-27 09:32:32,503:INFO:_master_model_container: 6
2023-04-27 09:32:32,504:INFO:_display_container: 2
2023-04-27 09:32:32,505:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=8632, solver='auto',
                tol=0.0001)
2023-04-27 09:32:32,505:INFO:create_model() successfully completed......................................
2023-04-27 09:32:32,686:INFO:SubProcess create_model() end ==================================
2023-04-27 09:32:32,686:INFO:Creating metrics dataframe
2023-04-27 09:32:32,714:INFO:Initializing Random Forest Classifier
2023-04-27 09:32:32,714:INFO:Total runtime is 1.2075166384379068 minutes
2023-04-27 09:32:32,725:INFO:SubProcess create_model() called ==================================
2023-04-27 09:32:32,726:INFO:Initializing create_model()
2023-04-27 09:32:32,726:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:32:32,726:INFO:Checking exceptions
2023-04-27 09:32:32,727:INFO:Importing libraries
2023-04-27 09:32:32,727:INFO:Copying training dataset
2023-04-27 09:32:32,739:INFO:Defining folds
2023-04-27 09:32:32,740:INFO:Declaring metric variables
2023-04-27 09:32:32,749:INFO:Importing untrained model
2023-04-27 09:32:32,759:INFO:Random Forest Classifier Imported successfully
2023-04-27 09:32:32,780:INFO:Starting cross validation
2023-04-27 09:32:32,784:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:32:38,559:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:38,566:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:38,622:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.79s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:38,854:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:39,437:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.83s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:39,594:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.96s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:39,620:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:39,708:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.93s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:39,912:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:41,173:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:41,187:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:43,906:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:43,920:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:44,480:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:44,484:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:44,591:INFO:Calculating mean and std
2023-04-27 09:32:44,594:INFO:Creating metrics dataframe
2023-04-27 09:32:44,698:INFO:Uploading results into container
2023-04-27 09:32:44,700:INFO:Uploading model into container now
2023-04-27 09:32:44,701:INFO:_master_model_container: 7
2023-04-27 09:32:44,701:INFO:_display_container: 2
2023-04-27 09:32:44,703:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=8632, verbose=0, warm_start=False)
2023-04-27 09:32:44,704:INFO:create_model() successfully completed......................................
2023-04-27 09:32:44,806:INFO:SubProcess create_model() end ==================================
2023-04-27 09:32:44,807:INFO:Creating metrics dataframe
2023-04-27 09:32:44,828:INFO:Initializing Quadratic Discriminant Analysis
2023-04-27 09:32:44,828:INFO:Total runtime is 1.4094286163647969 minutes
2023-04-27 09:32:44,837:INFO:SubProcess create_model() called ==================================
2023-04-27 09:32:44,837:INFO:Initializing create_model()
2023-04-27 09:32:44,838:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:32:44,838:INFO:Checking exceptions
2023-04-27 09:32:44,838:INFO:Importing libraries
2023-04-27 09:32:44,838:INFO:Copying training dataset
2023-04-27 09:32:44,846:INFO:Defining folds
2023-04-27 09:32:44,847:INFO:Declaring metric variables
2023-04-27 09:32:44,855:INFO:Importing untrained model
2023-04-27 09:32:44,863:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-27 09:32:44,878:INFO:Starting cross validation
2023-04-27 09:32:44,882:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:32:46,937:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:32:46,986:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:32:47,164:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:32:47,242:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:32:47,332:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:32:47,535:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:32:47,649:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:32:47,706:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:32:48,651:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:48,654:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:48,655:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:48,656:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:48,710:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:48,713:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:48,713:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:48,714:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:48,839:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:48,842:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:48,842:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:48,842:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:49,067:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:49,070:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,070:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,071:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:49,089:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,089:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,090:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:49,093:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:49,093:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,094:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,094:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:49,100:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:49,145:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:49,154:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:49,163:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:49,167:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,167:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,168:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:49,189:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,189:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,189:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:49,190:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:49,193:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,193:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,193:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:49,227:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:49,245:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:49,449:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,449:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,449:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:49,467:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,467:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,467:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,467:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:49,467:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:49,470:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:49,470:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:49,490:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:49,491:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:49,595:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:49,599:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,599:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,599:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:49,613:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,613:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,614:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:49,620:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:49,643:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:49,819:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,820:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,820:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:49,823:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:49,844:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:49,943:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,944:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:49,944:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:49,948:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:49,972:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:50,781:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:32:50,927:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:32:51,778:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:51,778:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:51,779:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:51,910:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:51,910:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:51,910:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:51,975:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:51,975:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:51,975:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:51,978:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:51,994:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:52,116:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:52,117:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: invalid value encountered in multiply
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:32:52,117:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:32:52,120:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:32:52,138:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:52,151:INFO:Calculating mean and std
2023-04-27 09:32:52,153:INFO:Creating metrics dataframe
2023-04-27 09:32:52,244:INFO:Uploading results into container
2023-04-27 09:32:52,245:INFO:Uploading model into container now
2023-04-27 09:32:52,245:INFO:_master_model_container: 8
2023-04-27 09:32:52,246:INFO:_display_container: 2
2023-04-27 09:32:52,246:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-27 09:32:52,246:INFO:create_model() successfully completed......................................
2023-04-27 09:32:52,377:INFO:SubProcess create_model() end ==================================
2023-04-27 09:32:52,377:INFO:Creating metrics dataframe
2023-04-27 09:32:52,397:INFO:Initializing Ada Boost Classifier
2023-04-27 09:32:52,398:INFO:Total runtime is 1.5355968793233234 minutes
2023-04-27 09:32:52,405:INFO:SubProcess create_model() called ==================================
2023-04-27 09:32:52,405:INFO:Initializing create_model()
2023-04-27 09:32:52,406:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:32:52,406:INFO:Checking exceptions
2023-04-27 09:32:52,406:INFO:Importing libraries
2023-04-27 09:32:52,406:INFO:Copying training dataset
2023-04-27 09:32:52,412:INFO:Defining folds
2023-04-27 09:32:52,413:INFO:Declaring metric variables
2023-04-27 09:32:52,420:INFO:Importing untrained model
2023-04-27 09:32:52,427:INFO:Ada Boost Classifier Imported successfully
2023-04-27 09:32:52,442:INFO:Starting cross validation
2023-04-27 09:32:52,444:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:32:57,304:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:57,346:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:57,630:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:57,787:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.92s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:57,913:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:57,964:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:57,985:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:58,027:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:58,042:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.85s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:58,145:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.95s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:32:58,396:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:58,494:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:58,553:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:58,677:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:58,688:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:32:58,799:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:01,466:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:01,473:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:01,570:INFO:Calculating mean and std
2023-04-27 09:33:01,573:INFO:Creating metrics dataframe
2023-04-27 09:33:01,687:INFO:Uploading results into container
2023-04-27 09:33:01,688:INFO:Uploading model into container now
2023-04-27 09:33:01,688:INFO:_master_model_container: 9
2023-04-27 09:33:01,689:INFO:_display_container: 2
2023-04-27 09:33:01,689:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=8632)
2023-04-27 09:33:01,689:INFO:create_model() successfully completed......................................
2023-04-27 09:33:01,791:INFO:SubProcess create_model() end ==================================
2023-04-27 09:33:01,791:INFO:Creating metrics dataframe
2023-04-27 09:33:01,820:INFO:Initializing Gradient Boosting Classifier
2023-04-27 09:33:01,821:INFO:Total runtime is 1.692642827828725 minutes
2023-04-27 09:33:01,829:INFO:SubProcess create_model() called ==================================
2023-04-27 09:33:01,829:INFO:Initializing create_model()
2023-04-27 09:33:01,830:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:33:01,830:INFO:Checking exceptions
2023-04-27 09:33:01,830:INFO:Importing libraries
2023-04-27 09:33:01,830:INFO:Copying training dataset
2023-04-27 09:33:01,840:INFO:Defining folds
2023-04-27 09:33:01,841:INFO:Declaring metric variables
2023-04-27 09:33:01,847:INFO:Importing untrained model
2023-04-27 09:33:01,856:INFO:Gradient Boosting Classifier Imported successfully
2023-04-27 09:33:01,871:INFO:Starting cross validation
2023-04-27 09:33:01,873:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:33:06,113:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:06,217:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:06,252:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:06,352:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:06,610:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:06,678:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:06,707:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:06,726:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:06,811:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:06,830:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:06,881:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:06,926:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:07,163:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:07,318:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:07,357:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:07,388:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:09,541:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:09,794:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:09,808:INFO:Calculating mean and std
2023-04-27 09:33:09,809:INFO:Creating metrics dataframe
2023-04-27 09:33:09,923:INFO:Uploading results into container
2023-04-27 09:33:09,924:INFO:Uploading model into container now
2023-04-27 09:33:09,925:INFO:_master_model_container: 10
2023-04-27 09:33:09,925:INFO:_display_container: 2
2023-04-27 09:33:09,926:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=8632, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-27 09:33:09,926:INFO:create_model() successfully completed......................................
2023-04-27 09:33:10,008:INFO:SubProcess create_model() end ==================================
2023-04-27 09:33:10,009:INFO:Creating metrics dataframe
2023-04-27 09:33:10,027:INFO:Initializing Linear Discriminant Analysis
2023-04-27 09:33:10,027:INFO:Total runtime is 1.8294084827105204 minutes
2023-04-27 09:33:10,033:INFO:SubProcess create_model() called ==================================
2023-04-27 09:33:10,034:INFO:Initializing create_model()
2023-04-27 09:33:10,034:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:33:10,035:INFO:Checking exceptions
2023-04-27 09:33:10,035:INFO:Importing libraries
2023-04-27 09:33:10,035:INFO:Copying training dataset
2023-04-27 09:33:10,044:INFO:Defining folds
2023-04-27 09:33:10,044:INFO:Declaring metric variables
2023-04-27 09:33:10,051:INFO:Importing untrained model
2023-04-27 09:33:10,058:INFO:Linear Discriminant Analysis Imported successfully
2023-04-27 09:33:10,067:INFO:Starting cross validation
2023-04-27 09:33:10,070:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:33:13,753:WARNING:create_model() for lda raised an exception or returned all 0.0, trying without fit_kwargs:
2023-04-27 09:33:13,760:WARNING:Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py", line 622, in fit
    self._solve_svd(X, y)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py", line 533, in _solve_svd
    _, S, Vt = svd(X, full_matrices=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\scipy\linalg\_decomp_svd.py", line 123, in svd
    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\scipy\linalg\lapack.py", line 1004, in _compute_lwork
    raise ValueError("Internal work array size computation failed: "
ValueError: Internal work array size computation failed: -10


2023-04-27 09:33:13,761:INFO:Initializing create_model()
2023-04-27 09:33:13,761:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:33:13,761:INFO:Checking exceptions
2023-04-27 09:33:13,761:INFO:Importing libraries
2023-04-27 09:33:13,762:INFO:Copying training dataset
2023-04-27 09:33:13,775:INFO:Defining folds
2023-04-27 09:33:13,776:INFO:Declaring metric variables
2023-04-27 09:33:13,788:INFO:Importing untrained model
2023-04-27 09:33:13,798:INFO:Linear Discriminant Analysis Imported successfully
2023-04-27 09:33:13,817:INFO:Starting cross validation
2023-04-27 09:33:13,819:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:33:17,695:ERROR:create_model() for lda raised an exception or returned all 0.0:
2023-04-27 09:33:17,697:ERROR:Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 794, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py", line 622, in fit
    self._solve_svd(X, y)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py", line 533, in _solve_svd
    _, S, Vt = svd(X, full_matrices=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\scipy\linalg\_decomp_svd.py", line 123, in svd
    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\scipy\linalg\lapack.py", line 1004, in _compute_lwork
    raise ValueError("Internal work array size computation failed: "
ValueError: Internal work array size computation failed: -10


During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 810, in compare_models
    model, model_fit_time = self._create_model(**create_model_args)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1523, in _create_model
    model, model_fit_time, model_results, _ = self._create_model_with_cv(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py", line 1117, in _create_model_with_cv
    scores = cross_validate(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py", line 285, in cross_validate
    _warn_or_raise_about_fit_failures(results, error_score)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py", line 367, in _warn_or_raise_about_fit_failures
    raise ValueError(all_fits_failed_message)
ValueError: 
All the 10 fits failed.
It is very likely that your model is misconfigured.
You can try to debug the error by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
10 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py", line 622, in fit
    self._solve_svd(X, y)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py", line 533, in _solve_svd
    _, S, Vt = svd(X, full_matrices=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\scipy\linalg\_decomp_svd.py", line 123, in svd
    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\scipy\linalg\lapack.py", line 1004, in _compute_lwork
    raise ValueError("Internal work array size computation failed: "
ValueError: Internal work array size computation failed: -10


2023-04-27 09:33:17,912:INFO:Initializing Extra Trees Classifier
2023-04-27 09:33:17,912:INFO:Total runtime is 1.960818024476369 minutes
2023-04-27 09:33:17,918:INFO:SubProcess create_model() called ==================================
2023-04-27 09:33:17,919:INFO:Initializing create_model()
2023-04-27 09:33:17,919:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:33:17,919:INFO:Checking exceptions
2023-04-27 09:33:17,920:INFO:Importing libraries
2023-04-27 09:33:17,920:INFO:Copying training dataset
2023-04-27 09:33:17,927:INFO:Defining folds
2023-04-27 09:33:17,927:INFO:Declaring metric variables
2023-04-27 09:33:17,935:INFO:Importing untrained model
2023-04-27 09:33:17,941:INFO:Extra Trees Classifier Imported successfully
2023-04-27 09:33:17,956:INFO:Starting cross validation
2023-04-27 09:33:17,959:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:33:22,929:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:23,013:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:23,081:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:23,094:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:23,222:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:23,232:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:23,295:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:23,547:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:23,870:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:23,895:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:23,912:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:24,159:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:24,177:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:24,199:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:24,211:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:24,525:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:27,028:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:27,071:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:27,154:INFO:Calculating mean and std
2023-04-27 09:33:27,156:INFO:Creating metrics dataframe
2023-04-27 09:33:27,293:INFO:Uploading results into container
2023-04-27 09:33:27,294:INFO:Uploading model into container now
2023-04-27 09:33:27,294:INFO:_master_model_container: 11
2023-04-27 09:33:27,295:INFO:_display_container: 2
2023-04-27 09:33:27,296:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=8632, verbose=0, warm_start=False)
2023-04-27 09:33:27,296:INFO:create_model() successfully completed......................................
2023-04-27 09:33:27,391:INFO:SubProcess create_model() end ==================================
2023-04-27 09:33:27,391:INFO:Creating metrics dataframe
2023-04-27 09:33:27,412:INFO:Initializing Light Gradient Boosting Machine
2023-04-27 09:33:27,412:INFO:Total runtime is 2.119164486726125 minutes
2023-04-27 09:33:27,419:INFO:SubProcess create_model() called ==================================
2023-04-27 09:33:27,419:INFO:Initializing create_model()
2023-04-27 09:33:27,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:33:27,420:INFO:Checking exceptions
2023-04-27 09:33:27,420:INFO:Importing libraries
2023-04-27 09:33:27,420:INFO:Copying training dataset
2023-04-27 09:33:27,428:INFO:Defining folds
2023-04-27 09:33:27,428:INFO:Declaring metric variables
2023-04-27 09:33:27,436:INFO:Importing untrained model
2023-04-27 09:33:27,444:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-27 09:33:27,458:INFO:Starting cross validation
2023-04-27 09:33:27,461:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:33:31,075:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:31,163:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:31,211:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:31,336:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:31,425:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:31,512:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:31,558:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:31,578:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:31,632:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:31,645:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:31,758:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:31,779:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:31,935:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:33,867:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:34,178:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:34,191:INFO:Calculating mean and std
2023-04-27 09:33:34,193:INFO:Creating metrics dataframe
2023-04-27 09:33:34,345:INFO:Uploading results into container
2023-04-27 09:33:34,346:INFO:Uploading model into container now
2023-04-27 09:33:34,347:INFO:_master_model_container: 12
2023-04-27 09:33:34,347:INFO:_display_container: 2
2023-04-27 09:33:34,348:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=8632, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-27 09:33:34,349:INFO:create_model() successfully completed......................................
2023-04-27 09:33:34,449:INFO:SubProcess create_model() end ==================================
2023-04-27 09:33:34,450:INFO:Creating metrics dataframe
2023-04-27 09:33:34,472:INFO:Initializing Dummy Classifier
2023-04-27 09:33:34,473:INFO:Total runtime is 2.236842282613118 minutes
2023-04-27 09:33:34,479:INFO:SubProcess create_model() called ==================================
2023-04-27 09:33:34,480:INFO:Initializing create_model()
2023-04-27 09:33:34,480:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A7475B0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:33:34,480:INFO:Checking exceptions
2023-04-27 09:33:34,480:INFO:Importing libraries
2023-04-27 09:33:34,480:INFO:Copying training dataset
2023-04-27 09:33:34,491:INFO:Defining folds
2023-04-27 09:33:34,491:INFO:Declaring metric variables
2023-04-27 09:33:34,498:INFO:Importing untrained model
2023-04-27 09:33:34,507:INFO:Dummy Classifier Imported successfully
2023-04-27 09:33:34,520:INFO:Starting cross validation
2023-04-27 09:33:34,523:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:33:37,680:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:37,998:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:38,069:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:38,165:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:38,165:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:38,297:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:38,487:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:33:38,521:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:38,538:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:38,569:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:38,577:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:38,688:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:38,842:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:40,552:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:40,716:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:33:40,729:INFO:Calculating mean and std
2023-04-27 09:33:40,732:INFO:Creating metrics dataframe
2023-04-27 09:33:40,877:INFO:Uploading results into container
2023-04-27 09:33:40,878:INFO:Uploading model into container now
2023-04-27 09:33:40,879:INFO:_master_model_container: 13
2023-04-27 09:33:40,879:INFO:_display_container: 2
2023-04-27 09:33:40,880:INFO:DummyClassifier(constant=None, random_state=8632, strategy='prior')
2023-04-27 09:33:40,880:INFO:create_model() successfully completed......................................
2023-04-27 09:33:40,975:INFO:SubProcess create_model() end ==================================
2023-04-27 09:33:40,975:INFO:Creating metrics dataframe
2023-04-27 09:33:41,012:INFO:Initializing create_model()
2023-04-27 09:33:41,012:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8632, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:33:41,013:INFO:Checking exceptions
2023-04-27 09:33:41,015:INFO:Importing libraries
2023-04-27 09:33:41,015:INFO:Copying training dataset
2023-04-27 09:33:41,021:INFO:Defining folds
2023-04-27 09:33:41,021:INFO:Declaring metric variables
2023-04-27 09:33:41,021:INFO:Importing untrained model
2023-04-27 09:33:41,021:INFO:Declaring custom model
2023-04-27 09:33:41,022:INFO:Logistic Regression Imported successfully
2023-04-27 09:33:41,023:INFO:Cross validation set to False
2023-04-27 09:33:41,023:INFO:Fitting Model
2023-04-27 09:33:42,480:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8632, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-27 09:33:42,480:INFO:create_model() successfully completed......................................
2023-04-27 09:33:42,607:INFO:_master_model_container: 13
2023-04-27 09:33:42,608:INFO:_display_container: 2
2023-04-27 09:33:42,608:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8632, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-27 09:33:42,608:INFO:compare_models() successfully completed......................................
2023-04-27 09:34:22,373:INFO:Initializing create_model()
2023-04-27 09:34:22,373:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8632, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:34:22,373:INFO:Checking exceptions
2023-04-27 09:34:22,397:INFO:Importing libraries
2023-04-27 09:34:22,397:INFO:Copying training dataset
2023-04-27 09:34:22,411:INFO:Defining folds
2023-04-27 09:34:22,412:INFO:Declaring metric variables
2023-04-27 09:34:22,420:INFO:Importing untrained model
2023-04-27 09:34:22,420:INFO:Declaring custom model
2023-04-27 09:34:22,432:INFO:Logistic Regression Imported successfully
2023-04-27 09:34:22,445:INFO:Starting cross validation
2023-04-27 09:34:22,448:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:34:25,876:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:34:26,067:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:34:26,290:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:34:26,298:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:34:26,314:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:34:26,439:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:34:26,528:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:34:26,629:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:34:26,631:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:34:26,698:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:34:26,711:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:34:26,812:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:34:27,011:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:34:27,032:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:34:27,150:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:34:28,976:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:34:29,022:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:34:29,088:INFO:Calculating mean and std
2023-04-27 09:34:29,090:INFO:Creating metrics dataframe
2023-04-27 09:34:29,103:INFO:Finalizing model
2023-04-27 09:34:30,215:INFO:Uploading results into container
2023-04-27 09:34:30,217:INFO:Uploading model into container now
2023-04-27 09:34:30,231:INFO:_master_model_container: 14
2023-04-27 09:34:30,231:INFO:_display_container: 3
2023-04-27 09:34:30,232:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8632, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-27 09:34:30,232:INFO:create_model() successfully completed......................................
2023-04-27 09:34:41,050:INFO:Initializing evaluate_model()
2023-04-27 09:34:41,050:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8632, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-04-27 09:34:41,076:INFO:Initializing plot_model()
2023-04-27 09:34:41,077:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8632, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, system=True)
2023-04-27 09:34:41,077:INFO:Checking exceptions
2023-04-27 09:34:41,080:INFO:Preloading libraries
2023-04-27 09:34:41,081:INFO:Copying training dataset
2023-04-27 09:34:41,081:INFO:Plot type: pipeline
2023-04-27 09:34:45,381:INFO:Initializing evaluate_model()
2023-04-27 09:34:45,381:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8632, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-04-27 09:34:45,400:INFO:Initializing plot_model()
2023-04-27 09:34:45,400:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=8632, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187192FF3A0>, system=True)
2023-04-27 09:34:45,401:INFO:Checking exceptions
2023-04-27 09:34:45,404:INFO:Preloading libraries
2023-04-27 09:34:45,405:INFO:Copying training dataset
2023-04-27 09:34:45,405:INFO:Plot type: pipeline
2023-04-27 09:38:14,304:INFO:PyCaret ClassificationExperiment
2023-04-27 09:38:14,304:INFO:Logging name: clf-default-name
2023-04-27 09:38:14,304:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-04-27 09:38:14,304:INFO:version 3.0.0
2023-04-27 09:38:14,305:INFO:Initializing setup()
2023-04-27 09:38:14,305:INFO:self.USI: 5d12
2023-04-27 09:38:14,305:INFO:self._variable_keys: {'data', 'fold_groups_param', 'exp_id', 'html_param', 'fold_shuffle_param', 'fix_imbalance', 'X', 'is_multiclass', 'gpu_n_jobs_param', 'idx', 'y', '_available_plots', 'logging_param', 'n_jobs_param', 'fold_generator', 'X_test', 'y_test', 'seed', 'y_train', '_ml_usecase', 'log_plots_param', 'USI', 'exp_name_log', 'memory', 'X_train', 'target_param', 'gpu_param', 'pipeline'}
2023-04-27 09:38:14,305:INFO:Checking environment
2023-04-27 09:38:14,305:INFO:python_version: 3.10.10
2023-04-27 09:38:14,305:INFO:python_build: ('main', 'Mar 24 2023 20:00:38')
2023-04-27 09:38:14,305:INFO:machine: AMD64
2023-04-27 09:38:14,305:INFO:platform: Windows-10-10.0.19041-SP0
2023-04-27 09:38:14,310:INFO:Memory: svmem(total=8375230464, available=657444864, percent=92.2, used=7717785600, free=657444864)
2023-04-27 09:38:14,310:INFO:Physical Core: 4
2023-04-27 09:38:14,310:INFO:Logical Core: 8
2023-04-27 09:38:14,310:INFO:Checking libraries
2023-04-27 09:38:14,310:INFO:System:
2023-04-27 09:38:14,311:INFO:    python: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:00:38) [MSC v.1934 64 bit (AMD64)]
2023-04-27 09:38:14,311:INFO:executable: c:\Users\vande\anaconda3\envs\article\python.exe
2023-04-27 09:38:14,311:INFO:   machine: Windows-10-10.0.19041-SP0
2023-04-27 09:38:14,311:INFO:PyCaret required dependencies:
2023-04-27 09:38:14,311:INFO:                 pip: 23.1.2
2023-04-27 09:38:14,311:INFO:          setuptools: 67.7.2
2023-04-27 09:38:14,311:INFO:             pycaret: 3.0.0
2023-04-27 09:38:14,311:INFO:             IPython: 8.12.0
2023-04-27 09:38:14,311:INFO:          ipywidgets: 8.0.6
2023-04-27 09:38:14,311:INFO:                tqdm: 4.65.0
2023-04-27 09:38:14,311:INFO:               numpy: 1.23.5
2023-04-27 09:38:14,311:INFO:              pandas: 1.5.3
2023-04-27 09:38:14,311:INFO:              jinja2: 3.1.2
2023-04-27 09:38:14,311:INFO:               scipy: 1.10.1
2023-04-27 09:38:14,311:INFO:              joblib: 1.2.0
2023-04-27 09:38:14,311:INFO:             sklearn: 1.2.2
2023-04-27 09:38:14,311:INFO:                pyod: 1.0.9
2023-04-27 09:38:14,311:INFO:            imblearn: 0.10.1
2023-04-27 09:38:14,311:INFO:   category_encoders: 2.6.0
2023-04-27 09:38:14,312:INFO:            lightgbm: 3.3.5
2023-04-27 09:38:14,312:INFO:               numba: 0.56.4
2023-04-27 09:38:14,312:INFO:            requests: 2.29.0
2023-04-27 09:38:14,312:INFO:          matplotlib: 3.7.1
2023-04-27 09:38:14,312:INFO:          scikitplot: 0.3.7
2023-04-27 09:38:14,312:INFO:         yellowbrick: 1.5
2023-04-27 09:38:14,312:INFO:              plotly: 5.14.1
2023-04-27 09:38:14,312:INFO:             kaleido: 0.2.1
2023-04-27 09:38:14,312:INFO:         statsmodels: 0.13.5
2023-04-27 09:38:14,312:INFO:              sktime: 0.17.2
2023-04-27 09:38:14,312:INFO:               tbats: 1.1.3
2023-04-27 09:38:14,312:INFO:            pmdarima: 2.0.3
2023-04-27 09:38:14,312:INFO:              psutil: 5.9.5
2023-04-27 09:38:14,312:INFO:PyCaret optional dependencies:
2023-04-27 09:38:14,312:INFO:                shap: Not installed
2023-04-27 09:38:14,312:INFO:           interpret: Not installed
2023-04-27 09:38:14,312:INFO:                umap: Not installed
2023-04-27 09:38:14,312:INFO:    pandas_profiling: Not installed
2023-04-27 09:38:14,312:INFO:  explainerdashboard: Not installed
2023-04-27 09:38:14,312:INFO:             autoviz: Not installed
2023-04-27 09:38:14,312:INFO:           fairlearn: Not installed
2023-04-27 09:38:14,313:INFO:             xgboost: Not installed
2023-04-27 09:38:14,313:INFO:            catboost: Not installed
2023-04-27 09:38:14,313:INFO:              kmodes: Not installed
2023-04-27 09:38:14,313:INFO:             mlxtend: Not installed
2023-04-27 09:38:14,313:INFO:       statsforecast: Not installed
2023-04-27 09:38:14,313:INFO:        tune_sklearn: Not installed
2023-04-27 09:38:14,313:INFO:                 ray: Not installed
2023-04-27 09:38:14,313:INFO:            hyperopt: Not installed
2023-04-27 09:38:14,313:INFO:              optuna: Not installed
2023-04-27 09:38:14,313:INFO:               skopt: Not installed
2023-04-27 09:38:14,313:INFO:              mlflow: Not installed
2023-04-27 09:38:14,313:INFO:              gradio: Not installed
2023-04-27 09:38:14,313:INFO:             fastapi: Not installed
2023-04-27 09:38:14,313:INFO:             uvicorn: Not installed
2023-04-27 09:38:14,313:INFO:              m2cgen: Not installed
2023-04-27 09:38:14,313:INFO:           evidently: Not installed
2023-04-27 09:38:14,313:INFO:               fugue: Not installed
2023-04-27 09:38:14,313:INFO:           streamlit: Not installed
2023-04-27 09:38:14,313:INFO:             prophet: Not installed
2023-04-27 09:38:14,314:INFO:None
2023-04-27 09:38:14,314:INFO:Set up data.
2023-04-27 09:38:14,398:INFO:Set up train/test split.
2023-04-27 09:38:14,442:INFO:Set up index.
2023-04-27 09:38:14,443:INFO:Set up folding strategy.
2023-04-27 09:38:14,443:INFO:Assigning column types.
2023-04-27 09:38:14,446:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-04-27 09:38:14,511:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-27 09:38:14,513:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-27 09:38:14,545:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:14,545:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:14,609:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-04-27 09:38:14,610:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-27 09:38:14,654:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:14,654:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:14,655:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-04-27 09:38:14,718:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-27 09:38:14,767:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:14,767:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:14,849:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-04-27 09:38:14,900:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:14,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:14,902:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-04-27 09:38:15,034:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:15,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:15,164:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:15,164:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:15,166:INFO:Preparing preprocessing pipeline...
2023-04-27 09:38:15,167:INFO:Set up label encoding.
2023-04-27 09:38:15,168:INFO:Set up simple imputation.
2023-04-27 09:38:15,171:INFO:Set up encoding of categorical features.
2023-04-27 09:38:16,168:INFO:Finished creating preprocessing pipeline.
2023-04-27 09:38:16,174:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vande\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['preprocessed_news'],
                                    transformer=LeaveOneOutEncoder(cols=['preprocessed_news'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=5259,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0)))],
         verbose=False)
2023-04-27 09:38:16,174:INFO:Creating final display dataframe.
2023-04-27 09:38:22,560:INFO:Setup _display_container:                     Description             Value
0                    Session id              5259
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, true: 1
4           Original data shape         (7200, 2)
5        Transformed data shape         (7200, 2)
6   Transformed train set shape         (5040, 2)
7    Transformed test set shape         (2160, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              5d12
2023-04-27 09:38:22,695:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:22,695:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:22,771:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:22,771:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-04-27 09:38:22,772:INFO:setup() successfully completed in 8.61s...............
2023-04-27 09:38:25,344:INFO:Initializing compare_models()
2023-04-27 09:38:25,344:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-27 09:38:25,344:INFO:Checking exceptions
2023-04-27 09:38:25,349:INFO:Preparing display monitor
2023-04-27 09:38:25,390:INFO:Initializing Logistic Regression
2023-04-27 09:38:25,390:INFO:Total runtime is 0.0 minutes
2023-04-27 09:38:25,394:INFO:SubProcess create_model() called ==================================
2023-04-27 09:38:25,395:INFO:Initializing create_model()
2023-04-27 09:38:25,396:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A401930>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:38:25,396:INFO:Checking exceptions
2023-04-27 09:38:25,396:INFO:Importing libraries
2023-04-27 09:38:25,396:INFO:Copying training dataset
2023-04-27 09:38:25,402:INFO:Defining folds
2023-04-27 09:38:25,402:INFO:Declaring metric variables
2023-04-27 09:38:25,412:INFO:Importing untrained model
2023-04-27 09:38:25,419:INFO:Logistic Regression Imported successfully
2023-04-27 09:38:25,431:INFO:Starting cross validation
2023-04-27 09:38:25,433:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:38:28,302:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:28,363:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:28,398:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:28,565:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:28,600:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:28,681:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:28,792:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:28,861:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:30,628:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:30,686:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:30,736:INFO:Calculating mean and std
2023-04-27 09:38:30,738:INFO:Creating metrics dataframe
2023-04-27 09:38:30,848:INFO:Uploading results into container
2023-04-27 09:38:30,849:INFO:Uploading model into container now
2023-04-27 09:38:30,850:INFO:_master_model_container: 1
2023-04-27 09:38:30,850:INFO:_display_container: 2
2023-04-27 09:38:30,851:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-27 09:38:30,851:INFO:create_model() successfully completed......................................
2023-04-27 09:38:30,994:INFO:SubProcess create_model() end ==================================
2023-04-27 09:38:30,994:INFO:Creating metrics dataframe
2023-04-27 09:38:31,006:INFO:Initializing K Neighbors Classifier
2023-04-27 09:38:31,006:INFO:Total runtime is 0.09359636306762695 minutes
2023-04-27 09:38:31,010:INFO:SubProcess create_model() called ==================================
2023-04-27 09:38:31,010:INFO:Initializing create_model()
2023-04-27 09:38:31,011:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A401930>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:38:31,011:INFO:Checking exceptions
2023-04-27 09:38:31,011:INFO:Importing libraries
2023-04-27 09:38:31,011:INFO:Copying training dataset
2023-04-27 09:38:31,016:INFO:Defining folds
2023-04-27 09:38:31,017:INFO:Declaring metric variables
2023-04-27 09:38:31,023:INFO:Importing untrained model
2023-04-27 09:38:31,029:INFO:K Neighbors Classifier Imported successfully
2023-04-27 09:38:31,040:INFO:Starting cross validation
2023-04-27 09:38:31,042:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:38:35,205:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:35,398:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:35,400:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:35,484:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:35,828:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:35,828:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:35,889:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:38,776:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:38,902:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:38,956:INFO:Calculating mean and std
2023-04-27 09:38:38,958:INFO:Creating metrics dataframe
2023-04-27 09:38:39,132:INFO:Uploading results into container
2023-04-27 09:38:39,133:INFO:Uploading model into container now
2023-04-27 09:38:39,133:INFO:_master_model_container: 2
2023-04-27 09:38:39,134:INFO:_display_container: 2
2023-04-27 09:38:39,135:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-27 09:38:39,135:INFO:create_model() successfully completed......................................
2023-04-27 09:38:39,268:INFO:SubProcess create_model() end ==================================
2023-04-27 09:38:39,268:INFO:Creating metrics dataframe
2023-04-27 09:38:39,280:INFO:Initializing Naive Bayes
2023-04-27 09:38:39,280:INFO:Total runtime is 0.23149857918421426 minutes
2023-04-27 09:38:39,284:INFO:SubProcess create_model() called ==================================
2023-04-27 09:38:39,285:INFO:Initializing create_model()
2023-04-27 09:38:39,286:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A401930>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:38:39,286:INFO:Checking exceptions
2023-04-27 09:38:39,286:INFO:Importing libraries
2023-04-27 09:38:39,286:INFO:Copying training dataset
2023-04-27 09:38:39,293:INFO:Defining folds
2023-04-27 09:38:39,293:INFO:Declaring metric variables
2023-04-27 09:38:39,297:INFO:Importing untrained model
2023-04-27 09:38:39,303:INFO:Naive Bayes Imported successfully
2023-04-27 09:38:39,312:INFO:Starting cross validation
2023-04-27 09:38:39,313:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:38:42,037:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:38:42,038:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:38:42,043:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:38:42,043:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:38:42,310:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:38:42,311:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:38:42,317:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:38:42,329:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:42,340:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:42,346:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 09:38:42,346:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 09:38:42,349:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:38:42,372:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:42,421:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:42,809:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:42,861:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:42,935:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:43,028:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:44,653:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:44,665:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:44,762:INFO:Calculating mean and std
2023-04-27 09:38:44,763:INFO:Creating metrics dataframe
2023-04-27 09:38:44,891:INFO:Uploading results into container
2023-04-27 09:38:44,892:INFO:Uploading model into container now
2023-04-27 09:38:44,893:INFO:_master_model_container: 3
2023-04-27 09:38:44,893:INFO:_display_container: 2
2023-04-27 09:38:44,893:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-27 09:38:44,893:INFO:create_model() successfully completed......................................
2023-04-27 09:38:45,022:INFO:SubProcess create_model() end ==================================
2023-04-27 09:38:45,023:INFO:Creating metrics dataframe
2023-04-27 09:38:45,035:INFO:Initializing Decision Tree Classifier
2023-04-27 09:38:45,036:INFO:Total runtime is 0.32743493318557737 minutes
2023-04-27 09:38:45,041:INFO:SubProcess create_model() called ==================================
2023-04-27 09:38:45,041:INFO:Initializing create_model()
2023-04-27 09:38:45,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A401930>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:38:45,042:INFO:Checking exceptions
2023-04-27 09:38:45,042:INFO:Importing libraries
2023-04-27 09:38:45,042:INFO:Copying training dataset
2023-04-27 09:38:45,048:INFO:Defining folds
2023-04-27 09:38:45,048:INFO:Declaring metric variables
2023-04-27 09:38:45,054:INFO:Importing untrained model
2023-04-27 09:38:45,061:INFO:Decision Tree Classifier Imported successfully
2023-04-27 09:38:45,073:INFO:Starting cross validation
2023-04-27 09:38:45,074:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:38:48,053:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:48,146:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:48,185:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:48,276:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:48,478:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:48,500:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:48,636:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:48,995:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:50,592:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:50,686:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:50,766:INFO:Calculating mean and std
2023-04-27 09:38:50,771:INFO:Creating metrics dataframe
2023-04-27 09:38:50,945:INFO:Uploading results into container
2023-04-27 09:38:50,946:INFO:Uploading model into container now
2023-04-27 09:38:50,947:INFO:_master_model_container: 4
2023-04-27 09:38:50,948:INFO:_display_container: 2
2023-04-27 09:38:50,949:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5259, splitter='best')
2023-04-27 09:38:50,949:INFO:create_model() successfully completed......................................
2023-04-27 09:38:51,090:INFO:SubProcess create_model() end ==================================
2023-04-27 09:38:51,090:INFO:Creating metrics dataframe
2023-04-27 09:38:51,105:INFO:Initializing SVM - Linear Kernel
2023-04-27 09:38:51,106:INFO:Total runtime is 0.428609299659729 minutes
2023-04-27 09:38:51,110:INFO:SubProcess create_model() called ==================================
2023-04-27 09:38:51,111:INFO:Initializing create_model()
2023-04-27 09:38:51,111:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A401930>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:38:51,111:INFO:Checking exceptions
2023-04-27 09:38:51,112:INFO:Importing libraries
2023-04-27 09:38:51,112:INFO:Copying training dataset
2023-04-27 09:38:51,118:INFO:Defining folds
2023-04-27 09:38:51,119:INFO:Declaring metric variables
2023-04-27 09:38:51,125:INFO:Importing untrained model
2023-04-27 09:38:51,132:INFO:SVM - Linear Kernel Imported successfully
2023-04-27 09:38:51,145:INFO:Starting cross validation
2023-04-27 09:38:51,147:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:38:53,789:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:38:53,813:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:53,948:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:38:53,969:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:54,025:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:38:54,032:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:38:54,061:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:54,200:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:38:54,221:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:54,364:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:38:54,384:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:54,569:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:38:54,586:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:38:54,588:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:54,607:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:54,649:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:38:54,670:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:56,173:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:38:56,228:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 09:38:56,237:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:56,294:INFO:Calculating mean and std
2023-04-27 09:38:56,295:INFO:Creating metrics dataframe
2023-04-27 09:38:56,437:INFO:Uploading results into container
2023-04-27 09:38:56,438:INFO:Uploading model into container now
2023-04-27 09:38:56,439:INFO:_master_model_container: 5
2023-04-27 09:38:56,439:INFO:_display_container: 2
2023-04-27 09:38:56,440:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5259, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-27 09:38:56,440:INFO:create_model() successfully completed......................................
2023-04-27 09:38:56,567:INFO:SubProcess create_model() end ==================================
2023-04-27 09:38:56,567:INFO:Creating metrics dataframe
2023-04-27 09:38:56,579:INFO:Initializing Ridge Classifier
2023-04-27 09:38:56,580:INFO:Total runtime is 0.5198445002237956 minutes
2023-04-27 09:38:56,584:INFO:SubProcess create_model() called ==================================
2023-04-27 09:38:56,584:INFO:Initializing create_model()
2023-04-27 09:38:56,585:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A401930>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:38:56,585:INFO:Checking exceptions
2023-04-27 09:38:56,585:INFO:Importing libraries
2023-04-27 09:38:56,585:INFO:Copying training dataset
2023-04-27 09:38:56,592:INFO:Defining folds
2023-04-27 09:38:56,592:INFO:Declaring metric variables
2023-04-27 09:38:56,596:INFO:Importing untrained model
2023-04-27 09:38:56,602:INFO:Ridge Classifier Imported successfully
2023-04-27 09:38:56,611:INFO:Starting cross validation
2023-04-27 09:38:56,613:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:38:59,246:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:38:59,264:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:59,321:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:38:59,341:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:59,345:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:38:59,367:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:59,564:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:38:59,573:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:38:59,591:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:59,592:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:59,665:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:38:59,675:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:38:59,684:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:59,715:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:38:59,721:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:38:59,742:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:01,361:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:39:01,371:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:01,411:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 09:39:01,421:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:01,498:INFO:Calculating mean and std
2023-04-27 09:39:01,499:INFO:Creating metrics dataframe
2023-04-27 09:39:01,655:INFO:Uploading results into container
2023-04-27 09:39:01,656:INFO:Uploading model into container now
2023-04-27 09:39:01,657:INFO:_master_model_container: 6
2023-04-27 09:39:01,657:INFO:_display_container: 2
2023-04-27 09:39:01,657:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5259, solver='auto',
                tol=0.0001)
2023-04-27 09:39:01,657:INFO:create_model() successfully completed......................................
2023-04-27 09:39:01,781:INFO:SubProcess create_model() end ==================================
2023-04-27 09:39:01,781:INFO:Creating metrics dataframe
2023-04-27 09:39:01,795:INFO:Initializing Random Forest Classifier
2023-04-27 09:39:01,795:INFO:Total runtime is 0.6067538301150004 minutes
2023-04-27 09:39:01,799:INFO:SubProcess create_model() called ==================================
2023-04-27 09:39:01,800:INFO:Initializing create_model()
2023-04-27 09:39:01,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A401930>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:39:01,800:INFO:Checking exceptions
2023-04-27 09:39:01,800:INFO:Importing libraries
2023-04-27 09:39:01,800:INFO:Copying training dataset
2023-04-27 09:39:01,811:INFO:Defining folds
2023-04-27 09:39:01,812:INFO:Declaring metric variables
2023-04-27 09:39:01,816:INFO:Importing untrained model
2023-04-27 09:39:01,823:INFO:Random Forest Classifier Imported successfully
2023-04-27 09:39:01,832:INFO:Starting cross validation
2023-04-27 09:39:01,833:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:39:05,909:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:05,995:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:06,052:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:06,075:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:06,249:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.65s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:06,476:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:06,531:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:06,652:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:06,694:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:07,205:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:07,217:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:07,222:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:07,343:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:10,301:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:10,350:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:10,465:INFO:Calculating mean and std
2023-04-27 09:39:10,467:INFO:Creating metrics dataframe
2023-04-27 09:39:10,657:INFO:Uploading results into container
2023-04-27 09:39:10,658:INFO:Uploading model into container now
2023-04-27 09:39:10,659:INFO:_master_model_container: 7
2023-04-27 09:39:10,660:INFO:_display_container: 2
2023-04-27 09:39:10,661:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5259, verbose=0, warm_start=False)
2023-04-27 09:39:10,661:INFO:create_model() successfully completed......................................
2023-04-27 09:39:10,808:INFO:SubProcess create_model() end ==================================
2023-04-27 09:39:10,809:INFO:Creating metrics dataframe
2023-04-27 09:39:10,830:INFO:Initializing Quadratic Discriminant Analysis
2023-04-27 09:39:10,830:INFO:Total runtime is 0.7573392828305562 minutes
2023-04-27 09:39:10,837:INFO:SubProcess create_model() called ==================================
2023-04-27 09:39:10,838:INFO:Initializing create_model()
2023-04-27 09:39:10,839:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A401930>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:39:10,839:INFO:Checking exceptions
2023-04-27 09:39:10,839:INFO:Importing libraries
2023-04-27 09:39:10,839:INFO:Copying training dataset
2023-04-27 09:39:10,846:INFO:Defining folds
2023-04-27 09:39:10,846:INFO:Declaring metric variables
2023-04-27 09:39:10,857:INFO:Importing untrained model
2023-04-27 09:39:10,863:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-27 09:39:10,876:INFO:Starting cross validation
2023-04-27 09:39:10,878:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:39:12,386:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:39:12,455:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:39:12,517:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:39:12,559:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:39:12,630:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:39:12,723:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:39:12,788:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:39:12,874:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:39:13,638:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:13,639:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:13,712:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:13,713:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:13,779:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:13,779:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:13,912:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:13,912:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:13,930:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:13,930:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:13,982:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:13,982:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:13,985:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:39:14,010:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:14,011:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

in self.scalings_])

2023-04-27 09:39:14,011:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:14,014:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:39:14,014:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:14,029:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:14,030:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:14,032:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:14,048:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:14,048:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:14,051:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:39:14,069:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:14,188:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:14,189:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:14,192:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:39:14,201:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:14,201:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:14,219:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:14,219:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:14,223:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

ns that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:39:14,241:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:14,305:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:14,307:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:14,311:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:39:14,328:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:14,329:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:14,332:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:39:14,333:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:14,375:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:14,463:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:14,464:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:14,469:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:39:14,491:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:15,385:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:39:15,462:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 09:39:16,176:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:16,176:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:16,244:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:16,244:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:16,348:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:16,348:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:16,349:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:39:16,359:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:16,412:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 09:39:16,412:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 09:39:16,414:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 09:39:16,424:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:16,495:INFO:Calculating mean and std
2023-04-27 09:39:16,497:INFO:Creating metrics dataframe
2023-04-27 09:39:16,663:INFO:Uploading results into container
2023-04-27 09:39:16,664:INFO:Uploading model into container now
2023-04-27 09:39:16,664:INFO:_master_model_container: 8
2023-04-27 09:39:16,664:INFO:_display_container: 2
2023-04-27 09:39:16,665:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-27 09:39:16,665:INFO:create_model() successfully completed......................................
2023-04-27 09:39:16,791:INFO:SubProcess create_model() end ==================================
2023-04-27 09:39:16,791:INFO:Creating metrics dataframe
2023-04-27 09:39:16,806:INFO:Initializing Ada Boost Classifier
2023-04-27 09:39:16,806:INFO:Total runtime is 0.8569310983022054 minutes
2023-04-27 09:39:16,812:INFO:SubProcess create_model() called ==================================
2023-04-27 09:39:16,812:INFO:Initializing create_model()
2023-04-27 09:39:16,812:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A401930>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:39:16,812:INFO:Checking exceptions
2023-04-27 09:39:16,812:INFO:Importing libraries
2023-04-27 09:39:16,812:INFO:Copying training dataset
2023-04-27 09:39:16,819:INFO:Defining folds
2023-04-27 09:39:16,819:INFO:Declaring metric variables
2023-04-27 09:39:16,827:INFO:Importing untrained model
2023-04-27 09:39:16,831:INFO:Ada Boost Classifier Imported successfully
2023-04-27 09:39:16,843:INFO:Starting cross validation
2023-04-27 09:39:16,844:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:39:20,830:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:20,918:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.78s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:21,331:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:21,395:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:21,573:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:21,720:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:21,747:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:21,841:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.87s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:21,884:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:22,099:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.76s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:22,104:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:22,295:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:22,361:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:22,592:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:25,278:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:25,296:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:25,499:INFO:Calculating mean and std
2023-04-27 09:39:25,502:INFO:Creating metrics dataframe
2023-04-27 09:39:25,743:INFO:Uploading results into container
2023-04-27 09:39:25,745:INFO:Uploading model into container now
2023-04-27 09:39:25,746:INFO:_master_model_container: 9
2023-04-27 09:39:25,747:INFO:_display_container: 2
2023-04-27 09:39:25,748:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=5259)
2023-04-27 09:39:25,749:INFO:create_model() successfully completed......................................
2023-04-27 09:39:25,963:INFO:SubProcess create_model() end ==================================
2023-04-27 09:39:25,964:INFO:Creating metrics dataframe
2023-04-27 09:39:25,994:INFO:Initializing Gradient Boosting Classifier
2023-04-27 09:39:25,995:INFO:Total runtime is 1.010089635848999 minutes
2023-04-27 09:39:26,002:INFO:SubProcess create_model() called ==================================
2023-04-27 09:39:26,003:INFO:Initializing create_model()
2023-04-27 09:39:26,003:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A401930>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:39:26,004:INFO:Checking exceptions
2023-04-27 09:39:26,004:INFO:Importing libraries
2023-04-27 09:39:26,004:INFO:Copying training dataset
2023-04-27 09:39:26,015:INFO:Defining folds
2023-04-27 09:39:26,015:INFO:Declaring metric variables
2023-04-27 09:39:26,024:INFO:Importing untrained model
2023-04-27 09:39:26,033:INFO:Gradient Boosting Classifier Imported successfully
2023-04-27 09:39:26,049:INFO:Starting cross validation
2023-04-27 09:39:26,051:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:39:29,493:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:29,579:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:29,796:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:29,828:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:29,994:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:30,007:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:30,186:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:30,199:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:30,289:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:30,427:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:30,447:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:30,478:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:30,561:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:30,650:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:30,828:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:30,964:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:32,893:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:33,018:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:33,039:INFO:Calculating mean and std
2023-04-27 09:39:33,041:INFO:Creating metrics dataframe
2023-04-27 09:39:33,227:INFO:Uploading results into container
2023-04-27 09:39:33,228:INFO:Uploading model into container now
2023-04-27 09:39:33,229:INFO:_master_model_container: 10
2023-04-27 09:39:33,229:INFO:_display_container: 2
2023-04-27 09:39:33,230:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5259, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-27 09:39:33,230:INFO:create_model() successfully completed......................................
2023-04-27 09:39:33,350:INFO:SubProcess create_model() end ==================================
2023-04-27 09:39:33,350:INFO:Creating metrics dataframe
2023-04-27 09:39:33,367:INFO:Initializing Linear Discriminant Analysis
2023-04-27 09:39:33,367:INFO:Total runtime is 1.1329527099927266 minutes
2023-04-27 09:39:33,371:INFO:SubProcess create_model() called ==================================
2023-04-27 09:39:33,372:INFO:Initializing create_model()
2023-04-27 09:39:33,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A401930>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:39:33,372:INFO:Checking exceptions
2023-04-27 09:39:33,372:INFO:Importing libraries
2023-04-27 09:39:33,373:INFO:Copying training dataset
2023-04-27 09:39:33,379:INFO:Defining folds
2023-04-27 09:39:33,379:INFO:Declaring metric variables
2023-04-27 09:39:33,383:INFO:Importing untrained model
2023-04-27 09:39:33,391:INFO:Linear Discriminant Analysis Imported successfully
2023-04-27 09:39:33,400:INFO:Starting cross validation
2023-04-27 09:39:33,401:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:39:36,057:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:36,445:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:36,524:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:36,577:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:36,593:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:36,749:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:36,888:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:36,912:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:37,781:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:38,736:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:38,748:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py", line 622, in fit
    self._solve_svd(X, y)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py", line 533, in _solve_svd
    _, S, Vt = svd(X, full_matrices=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\scipy\linalg\_decomp_svd.py", line 123, in svd
    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\scipy\linalg\lapack.py", line 1004, in _compute_lwork
    raise ValueError("Internal work array size computation failed: "
ValueError: Internal work array size computation failed: -10

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-04-27 09:39:38,748:INFO:Calculating mean and std
2023-04-27 09:39:38,751:INFO:Creating metrics dataframe
2023-04-27 09:39:38,992:INFO:Uploading results into container
2023-04-27 09:39:38,993:INFO:Uploading model into container now
2023-04-27 09:39:38,994:INFO:_master_model_container: 11
2023-04-27 09:39:38,994:INFO:_display_container: 2
2023-04-27 09:39:38,995:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-27 09:39:38,996:INFO:create_model() successfully completed......................................
2023-04-27 09:39:39,120:INFO:SubProcess create_model() end ==================================
2023-04-27 09:39:39,121:INFO:Creating metrics dataframe
2023-04-27 09:39:39,139:INFO:Initializing Extra Trees Classifier
2023-04-27 09:39:39,139:INFO:Total runtime is 1.2291502396265666 minutes
2023-04-27 09:39:39,148:INFO:SubProcess create_model() called ==================================
2023-04-27 09:39:39,149:INFO:Initializing create_model()
2023-04-27 09:39:39,149:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A401930>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:39:39,149:INFO:Checking exceptions
2023-04-27 09:39:39,149:INFO:Importing libraries
2023-04-27 09:39:39,149:INFO:Copying training dataset
2023-04-27 09:39:39,158:INFO:Defining folds
2023-04-27 09:39:39,158:INFO:Declaring metric variables
2023-04-27 09:39:39,164:INFO:Importing untrained model
2023-04-27 09:39:39,171:INFO:Extra Trees Classifier Imported successfully
2023-04-27 09:39:39,184:INFO:Starting cross validation
2023-04-27 09:39:39,186:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:39:43,221:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:43,268:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:43,386:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:43,404:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:43,730:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:43,870:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:43,927:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:44,025:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:44,034:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.71s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 09:39:44,047:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:44,209:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:44,224:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:44,585:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:44,593:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:44,614:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:44,790:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:47,058:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:47,168:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:47,216:INFO:Calculating mean and std
2023-04-27 09:39:47,217:INFO:Creating metrics dataframe
2023-04-27 09:39:47,413:INFO:Uploading results into container
2023-04-27 09:39:47,414:INFO:Uploading model into container now
2023-04-27 09:39:47,414:INFO:_master_model_container: 12
2023-04-27 09:39:47,414:INFO:_display_container: 2
2023-04-27 09:39:47,415:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5259, verbose=0, warm_start=False)
2023-04-27 09:39:47,415:INFO:create_model() successfully completed......................................
2023-04-27 09:39:47,535:INFO:SubProcess create_model() end ==================================
2023-04-27 09:39:47,535:INFO:Creating metrics dataframe
2023-04-27 09:39:47,553:INFO:Initializing Light Gradient Boosting Machine
2023-04-27 09:39:47,553:INFO:Total runtime is 1.3693907380104064 minutes
2023-04-27 09:39:47,561:INFO:SubProcess create_model() called ==================================
2023-04-27 09:39:47,561:INFO:Initializing create_model()
2023-04-27 09:39:47,561:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A401930>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:39:47,562:INFO:Checking exceptions
2023-04-27 09:39:47,562:INFO:Importing libraries
2023-04-27 09:39:47,562:INFO:Copying training dataset
2023-04-27 09:39:47,567:INFO:Defining folds
2023-04-27 09:39:47,567:INFO:Declaring metric variables
2023-04-27 09:39:47,572:INFO:Importing untrained model
2023-04-27 09:39:47,577:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-27 09:39:47,585:INFO:Starting cross validation
2023-04-27 09:39:47,587:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:39:50,399:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:50,460:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:50,617:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:50,762:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:50,765:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:50,872:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:50,890:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:51,004:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:52,921:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:53,079:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:53,116:INFO:Calculating mean and std
2023-04-27 09:39:53,118:INFO:Creating metrics dataframe
2023-04-27 09:39:53,370:INFO:Uploading results into container
2023-04-27 09:39:53,372:INFO:Uploading model into container now
2023-04-27 09:39:53,374:INFO:_master_model_container: 13
2023-04-27 09:39:53,374:INFO:_display_container: 2
2023-04-27 09:39:53,375:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5259, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-27 09:39:53,376:INFO:create_model() successfully completed......................................
2023-04-27 09:39:53,525:INFO:SubProcess create_model() end ==================================
2023-04-27 09:39:53,525:INFO:Creating metrics dataframe
2023-04-27 09:39:53,544:INFO:Initializing Dummy Classifier
2023-04-27 09:39:53,544:INFO:Total runtime is 1.4692433238029479 minutes
2023-04-27 09:39:53,549:INFO:SubProcess create_model() called ==================================
2023-04-27 09:39:53,550:INFO:Initializing create_model()
2023-04-27 09:39:53,550:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001871A401930>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:39:53,551:INFO:Checking exceptions
2023-04-27 09:39:53,551:INFO:Importing libraries
2023-04-27 09:39:53,551:INFO:Copying training dataset
2023-04-27 09:39:53,560:INFO:Defining folds
2023-04-27 09:39:53,560:INFO:Declaring metric variables
2023-04-27 09:39:53,564:INFO:Importing untrained model
2023-04-27 09:39:53,571:INFO:Dummy Classifier Imported successfully
2023-04-27 09:39:53,585:INFO:Starting cross validation
2023-04-27 09:39:53,586:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:39:56,488:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:56,610:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:56,649:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:56,882:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:57,031:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:57,227:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:57,333:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:57,356:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:59,135:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:59,374:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:39:59,385:INFO:Calculating mean and std
2023-04-27 09:39:59,388:INFO:Creating metrics dataframe
2023-04-27 09:39:59,617:INFO:Uploading results into container
2023-04-27 09:39:59,619:INFO:Uploading model into container now
2023-04-27 09:39:59,619:INFO:_master_model_container: 14
2023-04-27 09:39:59,619:INFO:_display_container: 2
2023-04-27 09:39:59,619:INFO:DummyClassifier(constant=None, random_state=5259, strategy='prior')
2023-04-27 09:39:59,620:INFO:create_model() successfully completed......................................
2023-04-27 09:39:59,738:INFO:SubProcess create_model() end ==================================
2023-04-27 09:39:59,738:INFO:Creating metrics dataframe
2023-04-27 09:39:59,767:INFO:Initializing create_model()
2023-04-27 09:39:59,768:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:39:59,768:INFO:Checking exceptions
2023-04-27 09:39:59,770:INFO:Importing libraries
2023-04-27 09:39:59,770:INFO:Copying training dataset
2023-04-27 09:39:59,775:INFO:Defining folds
2023-04-27 09:39:59,775:INFO:Declaring metric variables
2023-04-27 09:39:59,775:INFO:Importing untrained model
2023-04-27 09:39:59,775:INFO:Declaring custom model
2023-04-27 09:39:59,776:INFO:Logistic Regression Imported successfully
2023-04-27 09:39:59,777:INFO:Cross validation set to False
2023-04-27 09:39:59,777:INFO:Fitting Model
2023-04-27 09:40:00,940:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-27 09:40:00,941:INFO:create_model() successfully completed......................................
2023-04-27 09:40:01,112:INFO:_master_model_container: 14
2023-04-27 09:40:01,112:INFO:_display_container: 2
2023-04-27 09:40:01,112:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-27 09:40:01,113:INFO:compare_models() successfully completed......................................
2023-04-27 09:42:02,155:INFO:Initializing create_model()
2023-04-27 09:42:02,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, cross_validation=True, predict=True, fit_kwargs=None, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=True, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-27 09:42:02,156:INFO:Checking exceptions
2023-04-27 09:42:02,192:INFO:Importing libraries
2023-04-27 09:42:02,192:INFO:Copying training dataset
2023-04-27 09:42:02,207:INFO:Defining folds
2023-04-27 09:42:02,207:INFO:Declaring metric variables
2023-04-27 09:42:02,215:INFO:Importing untrained model
2023-04-27 09:42:02,215:INFO:Declaring custom model
2023-04-27 09:42:02,223:INFO:Logistic Regression Imported successfully
2023-04-27 09:42:02,238:INFO:Starting cross validation
2023-04-27 09:42:02,240:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 09:42:04,851:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:42:05,080:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:42:05,108:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:42:05,124:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:42:05,326:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:42:05,444:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:42:05,519:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:42:05,524:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:42:06,958:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:42:07,262:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 09:42:07,273:INFO:Calculating mean and std
2023-04-27 09:42:07,274:INFO:Creating metrics dataframe
2023-04-27 09:42:07,283:INFO:Finalizing model
2023-04-27 09:42:08,290:INFO:Uploading results into container
2023-04-27 09:42:08,291:INFO:Uploading model into container now
2023-04-27 09:42:08,311:INFO:_master_model_container: 15
2023-04-27 09:42:08,311:INFO:_display_container: 3
2023-04-27 09:42:08,311:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-27 09:42:08,312:INFO:create_model() successfully completed......................................
2023-04-27 09:42:16,417:INFO:Initializing evaluate_model()
2023-04-27 09:42:16,418:INFO:evaluate_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, fit_kwargs=None, plot_kwargs=None, feature_name=None, groups=None, use_train_data=False)
2023-04-27 09:42:16,440:INFO:Initializing plot_model()
2023-04-27 09:42:16,440:INFO:plot_model(plot=pipeline, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), use_train_data=False, verbose=False, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs={}, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, system=True)
2023-04-27 09:42:16,440:INFO:Checking exceptions
2023-04-27 09:42:16,444:INFO:Preloading libraries
2023-04-27 09:42:16,445:INFO:Copying training dataset
2023-04-27 09:42:16,445:INFO:Plot type: pipeline
2023-04-27 09:42:20,889:INFO:Initializing plot_model()
2023-04-27 09:42:20,889:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, system=True)
2023-04-27 09:42:20,890:INFO:Checking exceptions
2023-04-27 09:42:20,895:INFO:Preloading libraries
2023-04-27 09:42:20,895:INFO:Copying training dataset
2023-04-27 09:42:20,895:INFO:Plot type: confusion_matrix
2023-04-27 09:42:21,525:INFO:Fitting Model
2023-04-27 09:42:21,528:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-27 09:42:21,529:INFO:Scoring test/hold-out set
2023-04-27 09:42:21,735:INFO:Visual Rendered Successfully
2023-04-27 09:42:21,878:INFO:plot_model() successfully completed......................................
2023-04-27 09:42:24,580:INFO:Initializing plot_model()
2023-04-27 09:42:24,581:INFO:plot_model(plot=auc, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, system=True)
2023-04-27 09:42:24,582:INFO:Checking exceptions
2023-04-27 09:42:24,590:INFO:Preloading libraries
2023-04-27 09:42:24,591:INFO:Copying training dataset
2023-04-27 09:42:24,591:INFO:Plot type: auc
2023-04-27 09:42:25,246:INFO:Fitting Model
2023-04-27 09:42:25,248:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-27 09:42:25,249:INFO:Scoring test/hold-out set
2023-04-27 09:42:25,699:INFO:Visual Rendered Successfully
2023-04-27 09:42:25,856:INFO:plot_model() successfully completed......................................
2023-04-27 09:42:28,687:INFO:Initializing plot_model()
2023-04-27 09:42:28,687:INFO:plot_model(plot=pr, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, system=True)
2023-04-27 09:42:28,687:INFO:Checking exceptions
2023-04-27 09:42:28,696:INFO:Preloading libraries
2023-04-27 09:42:28,696:INFO:Copying training dataset
2023-04-27 09:42:28,697:INFO:Plot type: pr
2023-04-27 09:42:29,329:INFO:Fitting Model
2023-04-27 09:42:29,330:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-04-27 09:42:29,331:INFO:Scoring test/hold-out set
2023-04-27 09:42:29,683:INFO:Visual Rendered Successfully
2023-04-27 09:42:29,824:INFO:plot_model() successfully completed......................................
2023-04-27 09:42:32,429:INFO:Initializing plot_model()
2023-04-27 09:42:32,429:INFO:plot_model(plot=feature, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, system=True)
2023-04-27 09:42:32,429:INFO:Checking exceptions
2023-04-27 09:42:32,438:INFO:Preloading libraries
2023-04-27 09:42:32,438:INFO:Copying training dataset
2023-04-27 09:42:32,439:INFO:Plot type: feature
2023-04-27 09:42:32,962:INFO:Visual Rendered Successfully
2023-04-27 09:42:33,110:INFO:plot_model() successfully completed......................................
2023-04-27 09:42:37,446:INFO:Initializing predict_model()
2023-04-27 09:42:37,446:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000187232CA8C0>)
2023-04-27 09:42:37,446:INFO:Checking exceptions
2023-04-27 09:42:37,446:INFO:Preloading libraries
2023-04-27 09:42:42,460:INFO:Initializing predict_model()
2023-04-27 09:42:42,461:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=True, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x00000187232CAF80>)
2023-04-27 09:42:42,461:INFO:Checking exceptions
2023-04-27 09:42:42,461:INFO:Preloading libraries
2023-04-27 10:21:42,937:WARNING:C:\Users\vande\AppData\Local\Temp\ipykernel_18888\994037262.py:4: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').
  text_box.on_submit(handle_submit)

2023-04-27 10:47:25,154:WARNING:C:\Users\vande\AppData\Local\Temp\ipykernel_18888\3292738187.py:15: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').
  text_box.on_submit(handle_submit)

2023-04-27 10:48:39,993:WARNING:C:\Users\vande\AppData\Local\Temp\ipykernel_18888\3292738187.py:15: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').
  text_box.on_submit(handle_submit)

2023-04-27 10:50:47,412:WARNING:C:\Users\vande\AppData\Local\Temp\ipykernel_18888\3761105954.py:15: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').
  text_box.on_submit(handle_submit)

2023-04-27 10:52:22,280:WARNING:C:\Users\vande\AppData\Local\Temp\ipykernel_18888\3761105954.py:15: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').
  text_box.on_submit(handle_submit)

2023-04-27 10:53:02,020:WARNING:C:\Users\vande\AppData\Local\Temp\ipykernel_18888\3761105954.py:15: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').
  text_box.on_submit(handle_submit)

2023-04-27 10:55:33,878:INFO:Initializing compare_models()
2023-04-27 10:55:33,878:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-04-27 10:55:33,879:INFO:Checking exceptions
2023-04-27 10:55:33,982:INFO:Preparing display monitor
2023-04-27 10:55:34,169:INFO:Initializing Logistic Regression
2023-04-27 10:55:34,170:INFO:Total runtime is 3.344217936197917e-05 minutes
2023-04-27 10:55:34,178:INFO:SubProcess create_model() called ==================================
2023-04-27 10:55:34,188:INFO:Initializing create_model()
2023-04-27 10:55:34,189:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018724561DE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:55:34,189:INFO:Checking exceptions
2023-04-27 10:55:34,190:INFO:Importing libraries
2023-04-27 10:55:34,190:INFO:Copying training dataset
2023-04-27 10:55:34,203:INFO:Defining folds
2023-04-27 10:55:34,203:INFO:Declaring metric variables
2023-04-27 10:55:34,218:INFO:Importing untrained model
2023-04-27 10:55:34,227:INFO:Logistic Regression Imported successfully
2023-04-27 10:55:34,247:INFO:Starting cross validation
2023-04-27 10:55:34,280:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 10:55:48,470:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:49,036:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:49,161:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:49,609:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:49,659:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:49,693:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:49,786:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:50,272:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:51,552:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:51,819:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:51,843:INFO:Calculating mean and std
2023-04-27 10:55:51,850:INFO:Creating metrics dataframe
2023-04-27 10:55:52,217:INFO:Uploading results into container
2023-04-27 10:55:52,219:INFO:Uploading model into container now
2023-04-27 10:55:52,229:INFO:_master_model_container: 16
2023-04-27 10:55:52,230:INFO:_display_container: 6
2023-04-27 10:55:52,231:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-27 10:55:52,232:INFO:create_model() successfully completed......................................
2023-04-27 10:55:53,254:INFO:SubProcess create_model() end ==================================
2023-04-27 10:55:53,254:INFO:Creating metrics dataframe
2023-04-27 10:55:53,279:INFO:Initializing K Neighbors Classifier
2023-04-27 10:55:53,279:INFO:Total runtime is 0.31850870450337726 minutes
2023-04-27 10:55:53,288:INFO:SubProcess create_model() called ==================================
2023-04-27 10:55:53,288:INFO:Initializing create_model()
2023-04-27 10:55:53,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018724561DE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:55:53,289:INFO:Checking exceptions
2023-04-27 10:55:53,289:INFO:Importing libraries
2023-04-27 10:55:53,289:INFO:Copying training dataset
2023-04-27 10:55:53,297:INFO:Defining folds
2023-04-27 10:55:53,297:INFO:Declaring metric variables
2023-04-27 10:55:53,306:INFO:Importing untrained model
2023-04-27 10:55:53,315:INFO:K Neighbors Classifier Imported successfully
2023-04-27 10:55:53,330:INFO:Starting cross validation
2023-04-27 10:55:53,334:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 10:55:58,085:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:55:58,157:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:55:58,302:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:58,388:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:55:58,449:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:55:58,633:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:58,659:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:55:58,720:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:55:58,770:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:58,807:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:55:58,933:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:59,014:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:59,032:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:55:59,178:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:55:59,423:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:01,666:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:01,788:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:01,929:INFO:Calculating mean and std
2023-04-27 10:56:01,934:INFO:Creating metrics dataframe
2023-04-27 10:56:02,206:INFO:Uploading results into container
2023-04-27 10:56:02,207:INFO:Uploading model into container now
2023-04-27 10:56:02,208:INFO:_master_model_container: 17
2023-04-27 10:56:02,208:INFO:_display_container: 6
2023-04-27 10:56:02,209:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-04-27 10:56:02,209:INFO:create_model() successfully completed......................................
2023-04-27 10:56:02,358:INFO:SubProcess create_model() end ==================================
2023-04-27 10:56:02,358:INFO:Creating metrics dataframe
2023-04-27 10:56:02,374:INFO:Initializing Naive Bayes
2023-04-27 10:56:02,374:INFO:Total runtime is 0.47009191115697224 minutes
2023-04-27 10:56:02,379:INFO:SubProcess create_model() called ==================================
2023-04-27 10:56:02,380:INFO:Initializing create_model()
2023-04-27 10:56:02,380:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018724561DE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:56:02,380:INFO:Checking exceptions
2023-04-27 10:56:02,380:INFO:Importing libraries
2023-04-27 10:56:02,380:INFO:Copying training dataset
2023-04-27 10:56:02,387:INFO:Defining folds
2023-04-27 10:56:02,387:INFO:Declaring metric variables
2023-04-27 10:56:02,391:INFO:Importing untrained model
2023-04-27 10:56:02,396:INFO:Naive Bayes Imported successfully
2023-04-27 10:56:02,441:INFO:Starting cross validation
2023-04-27 10:56:02,443:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 10:56:04,378:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 10:56:04,378:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 10:56:04,477:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 10:56:04,477:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 10:56:04,632:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:04,666:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 10:56:04,667:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 10:56:04,685:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 10:56:04,707:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:04,784:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-04-27 10:56:04,784:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-04-27 10:56:04,809:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 10:56:04,836:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:04,847:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:04,909:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:05,017:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:05,241:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:05,392:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:06,713:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:06,819:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:06,962:INFO:Calculating mean and std
2023-04-27 10:56:06,964:INFO:Creating metrics dataframe
2023-04-27 10:56:07,194:INFO:Uploading results into container
2023-04-27 10:56:07,195:INFO:Uploading model into container now
2023-04-27 10:56:07,196:INFO:_master_model_container: 18
2023-04-27 10:56:07,196:INFO:_display_container: 6
2023-04-27 10:56:07,196:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-04-27 10:56:07,196:INFO:create_model() successfully completed......................................
2023-04-27 10:56:07,345:INFO:SubProcess create_model() end ==================================
2023-04-27 10:56:07,345:INFO:Creating metrics dataframe
2023-04-27 10:56:07,362:INFO:Initializing Decision Tree Classifier
2023-04-27 10:56:07,362:INFO:Total runtime is 0.5532321095466614 minutes
2023-04-27 10:56:07,369:INFO:SubProcess create_model() called ==================================
2023-04-27 10:56:07,369:INFO:Initializing create_model()
2023-04-27 10:56:07,370:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018724561DE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:56:07,370:INFO:Checking exceptions
2023-04-27 10:56:07,370:INFO:Importing libraries
2023-04-27 10:56:07,370:INFO:Copying training dataset
2023-04-27 10:56:07,377:INFO:Defining folds
2023-04-27 10:56:07,378:INFO:Declaring metric variables
2023-04-27 10:56:07,387:INFO:Importing untrained model
2023-04-27 10:56:07,395:INFO:Decision Tree Classifier Imported successfully
2023-04-27 10:56:07,411:INFO:Starting cross validation
2023-04-27 10:56:07,413:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 10:56:09,627:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:09,722:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:09,767:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:09,931:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:10,193:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:10,326:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:10,421:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:10,530:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:11,861:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:12,039:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:12,367:INFO:Calculating mean and std
2023-04-27 10:56:12,369:INFO:Creating metrics dataframe
2023-04-27 10:56:12,643:INFO:Uploading results into container
2023-04-27 10:56:12,644:INFO:Uploading model into container now
2023-04-27 10:56:12,645:INFO:_master_model_container: 19
2023-04-27 10:56:12,645:INFO:_display_container: 6
2023-04-27 10:56:12,647:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=5259, splitter='best')
2023-04-27 10:56:12,648:INFO:create_model() successfully completed......................................
2023-04-27 10:56:12,806:INFO:SubProcess create_model() end ==================================
2023-04-27 10:56:12,807:INFO:Creating metrics dataframe
2023-04-27 10:56:12,823:INFO:Initializing SVM - Linear Kernel
2023-04-27 10:56:12,823:INFO:Total runtime is 0.64424729347229 minutes
2023-04-27 10:56:12,828:INFO:SubProcess create_model() called ==================================
2023-04-27 10:56:12,829:INFO:Initializing create_model()
2023-04-27 10:56:12,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018724561DE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:56:12,829:INFO:Checking exceptions
2023-04-27 10:56:12,829:INFO:Importing libraries
2023-04-27 10:56:12,829:INFO:Copying training dataset
2023-04-27 10:56:12,838:INFO:Defining folds
2023-04-27 10:56:12,838:INFO:Declaring metric variables
2023-04-27 10:56:12,844:INFO:Importing untrained model
2023-04-27 10:56:12,854:INFO:SVM - Linear Kernel Imported successfully
2023-04-27 10:56:12,865:INFO:Starting cross validation
2023-04-27 10:56:12,867:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 10:56:14,950:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 10:56:15,008:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:15,124:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 10:56:15,162:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:15,222:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 10:56:15,277:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:15,313:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 10:56:15,336:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:15,728:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 10:56:15,752:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:15,760:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 10:56:15,793:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:15,840:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 10:56:15,859:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:15,865:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 10:56:15,892:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:17,102:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 10:56:17,252:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-04-27 10:56:17,262:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:17,688:INFO:Calculating mean and std
2023-04-27 10:56:17,690:INFO:Creating metrics dataframe
2023-04-27 10:56:17,887:INFO:Uploading results into container
2023-04-27 10:56:17,888:INFO:Uploading model into container now
2023-04-27 10:56:17,888:INFO:_master_model_container: 20
2023-04-27 10:56:17,888:INFO:_display_container: 6
2023-04-27 10:56:17,889:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=5259, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-04-27 10:56:17,889:INFO:create_model() successfully completed......................................
2023-04-27 10:56:18,020:INFO:SubProcess create_model() end ==================================
2023-04-27 10:56:18,020:INFO:Creating metrics dataframe
2023-04-27 10:56:18,037:INFO:Initializing Ridge Classifier
2023-04-27 10:56:18,037:INFO:Total runtime is 0.7311509331067403 minutes
2023-04-27 10:56:18,041:INFO:SubProcess create_model() called ==================================
2023-04-27 10:56:18,042:INFO:Initializing create_model()
2023-04-27 10:56:18,042:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018724561DE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:56:18,042:INFO:Checking exceptions
2023-04-27 10:56:18,042:INFO:Importing libraries
2023-04-27 10:56:18,042:INFO:Copying training dataset
2023-04-27 10:56:18,046:INFO:Defining folds
2023-04-27 10:56:18,047:INFO:Declaring metric variables
2023-04-27 10:56:18,052:INFO:Importing untrained model
2023-04-27 10:56:18,059:INFO:Ridge Classifier Imported successfully
2023-04-27 10:56:18,069:INFO:Starting cross validation
2023-04-27 10:56:18,071:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 10:56:19,844:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 10:56:19,851:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 10:56:19,864:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:19,872:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:19,925:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 10:56:19,945:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:20,190:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 10:56:20,199:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 10:56:20,211:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:20,233:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:20,360:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 10:56:20,384:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 10:56:20,387:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:20,408:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:20,680:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 10:56:20,703:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:21,647:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 10:56:21,660:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:21,795:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-04-27 10:56:21,811:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:22,132:INFO:Calculating mean and std
2023-04-27 10:56:22,134:INFO:Creating metrics dataframe
2023-04-27 10:56:22,332:INFO:Uploading results into container
2023-04-27 10:56:22,334:INFO:Uploading model into container now
2023-04-27 10:56:22,335:INFO:_master_model_container: 21
2023-04-27 10:56:22,335:INFO:_display_container: 6
2023-04-27 10:56:22,337:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=5259, solver='auto',
                tol=0.0001)
2023-04-27 10:56:22,337:INFO:create_model() successfully completed......................................
2023-04-27 10:56:22,469:INFO:SubProcess create_model() end ==================================
2023-04-27 10:56:22,469:INFO:Creating metrics dataframe
2023-04-27 10:56:22,490:INFO:Initializing Random Forest Classifier
2023-04-27 10:56:22,491:INFO:Total runtime is 0.8053812821706136 minutes
2023-04-27 10:56:22,494:INFO:SubProcess create_model() called ==================================
2023-04-27 10:56:22,495:INFO:Initializing create_model()
2023-04-27 10:56:22,495:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018724561DE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:56:22,495:INFO:Checking exceptions
2023-04-27 10:56:22,495:INFO:Importing libraries
2023-04-27 10:56:22,495:INFO:Copying training dataset
2023-04-27 10:56:22,503:INFO:Defining folds
2023-04-27 10:56:22,503:INFO:Declaring metric variables
2023-04-27 10:56:22,508:INFO:Importing untrained model
2023-04-27 10:56:22,518:INFO:Random Forest Classifier Imported successfully
2023-04-27 10:56:22,544:INFO:Starting cross validation
2023-04-27 10:56:22,547:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 10:56:25,827:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:25,837:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:25,838:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:26,275:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:26,337:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:27,972:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:28,174:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:28,239:INFO:Calculating mean and std
2023-04-27 10:56:28,241:INFO:Creating metrics dataframe
2023-04-27 10:56:28,517:INFO:Uploading results into container
2023-04-27 10:56:28,518:INFO:Uploading model into container now
2023-04-27 10:56:28,518:INFO:_master_model_container: 22
2023-04-27 10:56:28,519:INFO:_display_container: 6
2023-04-27 10:56:28,519:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=5259, verbose=0, warm_start=False)
2023-04-27 10:56:28,520:INFO:create_model() successfully completed......................................
2023-04-27 10:56:28,659:INFO:SubProcess create_model() end ==================================
2023-04-27 10:56:28,659:INFO:Creating metrics dataframe
2023-04-27 10:56:28,680:INFO:Initializing Quadratic Discriminant Analysis
2023-04-27 10:56:28,680:INFO:Total runtime is 0.9085296432177226 minutes
2023-04-27 10:56:28,688:INFO:SubProcess create_model() called ==================================
2023-04-27 10:56:28,688:INFO:Initializing create_model()
2023-04-27 10:56:28,689:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018724561DE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:56:28,689:INFO:Checking exceptions
2023-04-27 10:56:28,689:INFO:Importing libraries
2023-04-27 10:56:28,690:INFO:Copying training dataset
2023-04-27 10:56:28,698:INFO:Defining folds
2023-04-27 10:56:28,698:INFO:Declaring metric variables
2023-04-27 10:56:28,707:INFO:Importing untrained model
2023-04-27 10:56:28,721:INFO:Quadratic Discriminant Analysis Imported successfully
2023-04-27 10:56:28,736:INFO:Starting cross validation
2023-04-27 10:56:28,738:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 10:56:30,258:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 10:56:30,354:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 10:56:30,390:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 10:56:30,582:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:30,591:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:30,621:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 10:56:30,638:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:30,638:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:30,693:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:30,694:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:30,763:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 10:56:30,927:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:30,935:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:30,938:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:30,939:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 10:56:30,939:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:30,958:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:30,976:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:30,977:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:31,004:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 10:56:31,026:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:31,030:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:31,030:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:31,046:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 10:56:31,064:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 10:56:31,075:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:31,071:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:31,091:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:31,132:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 10:56:31,205:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 10:56:31,233:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:31,233:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:31,291:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 10:56:31,333:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:31,344:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:31,344:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:31,388:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:31,389:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:31,441:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 10:56:31,463:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:31,488:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:31,488:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:31,520:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:31,520:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:31,640:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:31,640:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:31,656:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 10:56:31,690:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:31,760:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:31,761:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:31,841:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 10:56:31,845:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:31,845:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:31,850:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 10:56:31,867:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:31,873:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:32,701:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 10:56:32,849:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-04-27 10:56:32,904:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:32,905:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:33,061:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:33,061:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:33,108:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:33,109:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:33,110:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 10:56:33,122:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:33,247:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-04-27 10:56:33,247:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-04-27 10:56:33,250:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-04-27 10:56:33,262:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:33,614:INFO:Calculating mean and std
2023-04-27 10:56:33,617:INFO:Creating metrics dataframe
2023-04-27 10:56:33,846:INFO:Uploading results into container
2023-04-27 10:56:33,847:INFO:Uploading model into container now
2023-04-27 10:56:33,848:INFO:_master_model_container: 23
2023-04-27 10:56:33,848:INFO:_display_container: 6
2023-04-27 10:56:33,849:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-04-27 10:56:33,850:INFO:create_model() successfully completed......................................
2023-04-27 10:56:33,976:INFO:SubProcess create_model() end ==================================
2023-04-27 10:56:33,977:INFO:Creating metrics dataframe
2023-04-27 10:56:33,992:INFO:Initializing Ada Boost Classifier
2023-04-27 10:56:33,992:INFO:Total runtime is 0.9970577637354533 minutes
2023-04-27 10:56:33,996:INFO:SubProcess create_model() called ==================================
2023-04-27 10:56:33,997:INFO:Initializing create_model()
2023-04-27 10:56:33,997:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018724561DE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:56:33,997:INFO:Checking exceptions
2023-04-27 10:56:33,997:INFO:Importing libraries
2023-04-27 10:56:33,997:INFO:Copying training dataset
2023-04-27 10:56:34,004:INFO:Defining folds
2023-04-27 10:56:34,005:INFO:Declaring metric variables
2023-04-27 10:56:34,010:INFO:Importing untrained model
2023-04-27 10:56:34,015:INFO:Ada Boost Classifier Imported successfully
2023-04-27 10:56:34,026:INFO:Starting cross validation
2023-04-27 10:56:34,027:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 10:56:36,206:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:36,401:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:36,530:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:36,548:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:36,675:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:36,944:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:37,012:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:37,104:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:38,407:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:38,624:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:38,672:INFO:Calculating mean and std
2023-04-27 10:56:38,675:INFO:Creating metrics dataframe
2023-04-27 10:56:38,928:INFO:Uploading results into container
2023-04-27 10:56:38,929:INFO:Uploading model into container now
2023-04-27 10:56:38,930:INFO:_master_model_container: 24
2023-04-27 10:56:38,930:INFO:_display_container: 6
2023-04-27 10:56:38,931:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=5259)
2023-04-27 10:56:38,931:INFO:create_model() successfully completed......................................
2023-04-27 10:56:39,057:INFO:SubProcess create_model() end ==================================
2023-04-27 10:56:39,057:INFO:Creating metrics dataframe
2023-04-27 10:56:39,077:INFO:Initializing Gradient Boosting Classifier
2023-04-27 10:56:39,078:INFO:Total runtime is 1.0818254391352335 minutes
2023-04-27 10:56:39,081:INFO:SubProcess create_model() called ==================================
2023-04-27 10:56:39,082:INFO:Initializing create_model()
2023-04-27 10:56:39,082:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018724561DE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:56:39,082:INFO:Checking exceptions
2023-04-27 10:56:39,082:INFO:Importing libraries
2023-04-27 10:56:39,082:INFO:Copying training dataset
2023-04-27 10:56:39,089:INFO:Defining folds
2023-04-27 10:56:39,089:INFO:Declaring metric variables
2023-04-27 10:56:39,093:INFO:Importing untrained model
2023-04-27 10:56:39,098:INFO:Gradient Boosting Classifier Imported successfully
2023-04-27 10:56:39,110:INFO:Starting cross validation
2023-04-27 10:56:39,112:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 10:56:42,125:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:56:42,460:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:56:42,476:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.73s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:56:42,661:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.74s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:56:42,754:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:42,961:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:42,968:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:42,991:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.64s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:56:43,179:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.68s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:56:43,239:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:56:43,321:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:43,492:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.67s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-04-27 10:56:43,574:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:43,665:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:43,760:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:43,922:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:46,042:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:46,313:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:46,328:INFO:Calculating mean and std
2023-04-27 10:56:46,330:INFO:Creating metrics dataframe
2023-04-27 10:56:46,605:INFO:Uploading results into container
2023-04-27 10:56:46,606:INFO:Uploading model into container now
2023-04-27 10:56:46,606:INFO:_master_model_container: 25
2023-04-27 10:56:46,606:INFO:_display_container: 6
2023-04-27 10:56:46,607:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=5259, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-04-27 10:56:46,608:INFO:create_model() successfully completed......................................
2023-04-27 10:56:46,775:INFO:SubProcess create_model() end ==================================
2023-04-27 10:56:46,776:INFO:Creating metrics dataframe
2023-04-27 10:56:46,799:INFO:Initializing Linear Discriminant Analysis
2023-04-27 10:56:46,799:INFO:Total runtime is 1.2105035026868185 minutes
2023-04-27 10:56:46,808:INFO:SubProcess create_model() called ==================================
2023-04-27 10:56:46,808:INFO:Initializing create_model()
2023-04-27 10:56:46,809:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018724561DE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:56:46,809:INFO:Checking exceptions
2023-04-27 10:56:46,809:INFO:Importing libraries
2023-04-27 10:56:46,809:INFO:Copying training dataset
2023-04-27 10:56:46,815:INFO:Defining folds
2023-04-27 10:56:46,816:INFO:Declaring metric variables
2023-04-27 10:56:46,827:INFO:Importing untrained model
2023-04-27 10:56:46,835:INFO:Linear Discriminant Analysis Imported successfully
2023-04-27 10:56:46,854:INFO:Starting cross validation
2023-04-27 10:56:46,856:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 10:56:49,374:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:49,513:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:49,805:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:49,959:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:50,145:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:50,160:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:51,058:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:51,189:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:51,503:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py", line 622, in fit
    self._solve_svd(X, y)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py", line 533, in _solve_svd
    _, S, Vt = svd(X, full_matrices=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\scipy\linalg\_decomp_svd.py", line 123, in svd
    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\scipy\linalg\lapack.py", line 1004, in _compute_lwork
    raise ValueError("Internal work array size computation failed: "
ValueError: Internal work array size computation failed: -10

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-04-27 10:56:51,503:INFO:Calculating mean and std
2023-04-27 10:56:51,505:INFO:Creating metrics dataframe
2023-04-27 10:56:51,720:INFO:Uploading results into container
2023-04-27 10:56:51,721:INFO:Uploading model into container now
2023-04-27 10:56:51,721:INFO:_master_model_container: 26
2023-04-27 10:56:51,721:INFO:_display_container: 6
2023-04-27 10:56:51,722:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-04-27 10:56:51,722:INFO:create_model() successfully completed......................................
2023-04-27 10:56:51,852:INFO:SubProcess create_model() end ==================================
2023-04-27 10:56:51,852:INFO:Creating metrics dataframe
2023-04-27 10:56:51,877:INFO:Initializing Extra Trees Classifier
2023-04-27 10:56:51,878:INFO:Total runtime is 1.295158882935842 minutes
2023-04-27 10:56:51,882:INFO:SubProcess create_model() called ==================================
2023-04-27 10:56:51,883:INFO:Initializing create_model()
2023-04-27 10:56:51,883:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018724561DE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:56:51,883:INFO:Checking exceptions
2023-04-27 10:56:51,884:INFO:Importing libraries
2023-04-27 10:56:51,884:INFO:Copying training dataset
2023-04-27 10:56:51,891:INFO:Defining folds
2023-04-27 10:56:51,891:INFO:Declaring metric variables
2023-04-27 10:56:51,896:INFO:Importing untrained model
2023-04-27 10:56:51,903:INFO:Extra Trees Classifier Imported successfully
2023-04-27 10:56:51,913:INFO:Starting cross validation
2023-04-27 10:56:51,915:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 10:56:54,378:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:54,646:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:54,755:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:54,776:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:55,065:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:55,088:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:55,362:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:55,383:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:56,961:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:57,282:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:56:57,297:INFO:Calculating mean and std
2023-04-27 10:56:57,299:INFO:Creating metrics dataframe
2023-04-27 10:56:57,582:INFO:Uploading results into container
2023-04-27 10:56:57,584:INFO:Uploading model into container now
2023-04-27 10:56:57,586:INFO:_master_model_container: 27
2023-04-27 10:56:57,586:INFO:_display_container: 6
2023-04-27 10:56:57,587:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=5259, verbose=0, warm_start=False)
2023-04-27 10:56:57,587:INFO:create_model() successfully completed......................................
2023-04-27 10:56:57,737:INFO:SubProcess create_model() end ==================================
2023-04-27 10:56:57,737:INFO:Creating metrics dataframe
2023-04-27 10:56:57,756:INFO:Initializing Light Gradient Boosting Machine
2023-04-27 10:56:57,757:INFO:Total runtime is 1.393147905667623 minutes
2023-04-27 10:56:57,762:INFO:SubProcess create_model() called ==================================
2023-04-27 10:56:57,763:INFO:Initializing create_model()
2023-04-27 10:56:57,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018724561DE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:56:57,763:INFO:Checking exceptions
2023-04-27 10:56:57,763:INFO:Importing libraries
2023-04-27 10:56:57,764:INFO:Copying training dataset
2023-04-27 10:56:57,773:INFO:Defining folds
2023-04-27 10:56:57,773:INFO:Declaring metric variables
2023-04-27 10:56:57,780:INFO:Importing untrained model
2023-04-27 10:56:57,789:INFO:Light Gradient Boosting Machine Imported successfully
2023-04-27 10:56:57,799:INFO:Starting cross validation
2023-04-27 10:56:57,800:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 10:57:00,110:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:00,130:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:00,238:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:00,380:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:00,421:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:00,540:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:00,782:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:00,815:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:02,443:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:02,615:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:02,890:INFO:Calculating mean and std
2023-04-27 10:57:02,892:INFO:Creating metrics dataframe
2023-04-27 10:57:03,170:INFO:Uploading results into container
2023-04-27 10:57:03,171:INFO:Uploading model into container now
2023-04-27 10:57:03,171:INFO:_master_model_container: 28
2023-04-27 10:57:03,172:INFO:_display_container: 6
2023-04-27 10:57:03,173:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=5259, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-04-27 10:57:03,173:INFO:create_model() successfully completed......................................
2023-04-27 10:57:03,309:INFO:SubProcess create_model() end ==================================
2023-04-27 10:57:03,309:INFO:Creating metrics dataframe
2023-04-27 10:57:03,331:INFO:Initializing Dummy Classifier
2023-04-27 10:57:03,331:INFO:Total runtime is 1.4860397895177206 minutes
2023-04-27 10:57:03,335:INFO:SubProcess create_model() called ==================================
2023-04-27 10:57:03,336:INFO:Initializing create_model()
2023-04-27 10:57:03,336:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000018724561DE0>, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:57:03,337:INFO:Checking exceptions
2023-04-27 10:57:03,338:INFO:Importing libraries
2023-04-27 10:57:03,338:INFO:Copying training dataset
2023-04-27 10:57:03,344:INFO:Defining folds
2023-04-27 10:57:03,344:INFO:Declaring metric variables
2023-04-27 10:57:03,349:INFO:Importing untrained model
2023-04-27 10:57:03,356:INFO:Dummy Classifier Imported successfully
2023-04-27 10:57:03,369:INFO:Starting cross validation
2023-04-27 10:57:03,371:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-04-27 10:57:05,394:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:05,400:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:05,480:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:05,716:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:05,716:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:05,935:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:06,073:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:06,124:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:07,291:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:07,439:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-04-27 10:57:07,697:INFO:Calculating mean and std
2023-04-27 10:57:07,698:INFO:Creating metrics dataframe
2023-04-27 10:57:07,936:INFO:Uploading results into container
2023-04-27 10:57:07,937:INFO:Uploading model into container now
2023-04-27 10:57:07,938:INFO:_master_model_container: 29
2023-04-27 10:57:07,938:INFO:_display_container: 6
2023-04-27 10:57:07,939:INFO:DummyClassifier(constant=None, random_state=5259, strategy='prior')
2023-04-27 10:57:07,939:INFO:create_model() successfully completed......................................
2023-04-27 10:57:08,096:INFO:SubProcess create_model() end ==================================
2023-04-27 10:57:08,096:INFO:Creating metrics dataframe
2023-04-27 10:57:08,131:INFO:Initializing create_model()
2023-04-27 10:57:08,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187233078B0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-04-27 10:57:08,132:INFO:Checking exceptions
2023-04-27 10:57:08,135:INFO:Importing libraries
2023-04-27 10:57:08,135:INFO:Copying training dataset
2023-04-27 10:57:08,140:INFO:Defining folds
2023-04-27 10:57:08,140:INFO:Declaring metric variables
2023-04-27 10:57:08,140:INFO:Importing untrained model
2023-04-27 10:57:08,141:INFO:Declaring custom model
2023-04-27 10:57:08,142:INFO:Logistic Regression Imported successfully
2023-04-27 10:57:08,144:INFO:Cross validation set to False
2023-04-27 10:57:08,144:INFO:Fitting Model
2023-04-27 10:57:09,449:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-27 10:57:09,450:INFO:create_model() successfully completed......................................
2023-04-27 10:57:09,629:INFO:_master_model_container: 29
2023-04-27 10:57:09,629:INFO:_display_container: 6
2023-04-27 10:57:09,630:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=5259, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-04-27 10:57:09,630:INFO:compare_models() successfully completed......................................
2023-04-27 11:04:08,542:WARNING:C:\Users\vande\AppData\Local\Temp\ipykernel_18888\3761105954.py:15: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').
  text_box.on_submit(handle_submit)

2023-04-27 11:15:28,072:WARNING:C:\Users\vande\AppData\Local\Temp\ipykernel_18888\3761105954.py:15: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').
  text_box.on_submit(handle_submit)

2023-04-27 11:16:02,615:WARNING:C:\Users\vande\AppData\Local\Temp\ipykernel_18888\3634912151.py:14: DeprecationWarning: on_submit is deprecated. Instead, set the .continuous_update attribute to False and observe the value changing with: mywidget.observe(callback, 'value').
  text_box.on_submit(handle_submit)

2023-04-28 11:27:24,986:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-28 11:27:24,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-28 11:27:24,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-28 11:27:24,987:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-04-28 11:27:26,487:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-05 09:21:29,499:WARNING:C:\Users\vande\AppData\Local\Temp\ipykernel_22140\269526256.py:37: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.
  link = soup.find('a', text='Última')

2023-05-05 09:23:27,445:WARNING:C:\Users\vande\AppData\Local\Temp\ipykernel_22140\2118862304.py:37: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.
  link = soup.find('a', text='Última')

2023-05-05 09:26:34,020:WARNING:C:\Users\vande\AppData\Local\Temp\ipykernel_22140\4275832341.py:37: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.
  link = soup.find('a', text='Última')

2023-05-05 09:27:24,719:WARNING:C:\Users\vande\AppData\Local\Temp\ipykernel_22140\1704856173.py:37: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.
  link = soup.find('a', text='Última')

2023-05-05 09:32:11,005:WARNING:C:\Users\vande\AppData\Local\Temp\ipykernel_22140\3084951440.py:38: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.
  link = soup.find('a', text='Última')

2023-05-09 09:19:52,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-09 09:19:52,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-09 09:19:52,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-09 09:19:52,566:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-09 09:19:54,607:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-09 09:19:58,676:INFO:PyCaret ClassificationExperiment
2023-05-09 09:19:58,676:INFO:Logging name: clf-default-name
2023-05-09 09:19:58,676:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-09 09:19:58,676:INFO:version 3.0.0
2023-05-09 09:19:58,676:INFO:Initializing setup()
2023-05-09 09:19:58,676:INFO:self.USI: 19f9
2023-05-09 09:19:58,676:INFO:self._variable_keys: {'y', 'exp_name_log', 'seed', 'y_test', 'X', 'X_train', 'data', '_available_plots', 'html_param', 'idx', 'gpu_n_jobs_param', '_ml_usecase', 'log_plots_param', 'USI', 'y_train', 'X_test', 'logging_param', 'fold_groups_param', 'fix_imbalance', 'gpu_param', 'pipeline', 'n_jobs_param', 'exp_id', 'fold_shuffle_param', 'is_multiclass', 'target_param', 'memory', 'fold_generator'}
2023-05-09 09:19:58,676:INFO:Checking environment
2023-05-09 09:19:58,676:INFO:python_version: 3.10.10
2023-05-09 09:19:58,676:INFO:python_build: ('main', 'Mar 24 2023 20:00:38')
2023-05-09 09:19:58,676:INFO:machine: AMD64
2023-05-09 09:19:58,677:INFO:platform: Windows-10-10.0.19041-SP0
2023-05-09 09:19:58,682:INFO:Memory: svmem(total=8375230464, available=923852800, percent=89.0, used=7451377664, free=923852800)
2023-05-09 09:19:58,682:INFO:Physical Core: 4
2023-05-09 09:19:58,682:INFO:Logical Core: 8
2023-05-09 09:19:58,682:INFO:Checking libraries
2023-05-09 09:19:58,682:INFO:System:
2023-05-09 09:19:58,682:INFO:    python: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:00:38) [MSC v.1934 64 bit (AMD64)]
2023-05-09 09:19:58,683:INFO:executable: c:\Users\vande\anaconda3\envs\article\python.exe
2023-05-09 09:19:58,683:INFO:   machine: Windows-10-10.0.19041-SP0
2023-05-09 09:19:58,683:INFO:PyCaret required dependencies:
2023-05-09 09:19:58,683:INFO:                 pip: 23.1.2
2023-05-09 09:19:58,683:INFO:          setuptools: 67.7.2
2023-05-09 09:19:58,683:INFO:             pycaret: 3.0.0
2023-05-09 09:19:58,683:INFO:             IPython: 8.12.0
2023-05-09 09:19:58,683:INFO:          ipywidgets: 8.0.6
2023-05-09 09:19:58,683:INFO:                tqdm: 4.65.0
2023-05-09 09:19:58,683:INFO:               numpy: 1.24.3
2023-05-09 09:19:58,683:INFO:              pandas: 1.5.3
2023-05-09 09:19:58,684:INFO:              jinja2: 3.1.2
2023-05-09 09:19:58,684:INFO:               scipy: 1.10.1
2023-05-09 09:19:58,684:INFO:              joblib: 1.2.0
2023-05-09 09:19:58,684:INFO:             sklearn: 1.2.2
2023-05-09 09:19:58,684:INFO:                pyod: 1.0.9
2023-05-09 09:19:58,684:INFO:            imblearn: 0.10.1
2023-05-09 09:19:58,684:INFO:   category_encoders: 2.6.0
2023-05-09 09:19:58,684:INFO:            lightgbm: 3.3.5
2023-05-09 09:19:58,684:INFO:               numba: 0.56.4
2023-05-09 09:19:58,684:INFO:            requests: 2.29.0
2023-05-09 09:19:58,684:INFO:          matplotlib: 3.7.1
2023-05-09 09:19:58,684:INFO:          scikitplot: 0.3.7
2023-05-09 09:19:58,684:INFO:         yellowbrick: 1.5
2023-05-09 09:19:58,684:INFO:              plotly: 5.14.1
2023-05-09 09:19:58,684:INFO:             kaleido: 0.2.1
2023-05-09 09:19:58,684:INFO:         statsmodels: 0.13.5
2023-05-09 09:19:58,684:INFO:              sktime: 0.17.2
2023-05-09 09:19:58,684:INFO:               tbats: 1.1.3
2023-05-09 09:19:58,684:INFO:            pmdarima: 2.0.3
2023-05-09 09:19:58,684:INFO:              psutil: 5.9.5
2023-05-09 09:19:58,684:INFO:PyCaret optional dependencies:
2023-05-09 09:19:58,701:INFO:                shap: Not installed
2023-05-09 09:19:58,701:INFO:           interpret: Not installed
2023-05-09 09:19:58,701:INFO:                umap: Not installed
2023-05-09 09:19:58,701:INFO:    pandas_profiling: Not installed
2023-05-09 09:19:58,701:INFO:  explainerdashboard: Not installed
2023-05-09 09:19:58,702:INFO:             autoviz: Not installed
2023-05-09 09:19:58,702:INFO:           fairlearn: Not installed
2023-05-09 09:19:58,702:INFO:             xgboost: Not installed
2023-05-09 09:19:58,702:INFO:            catboost: Not installed
2023-05-09 09:19:58,702:INFO:              kmodes: Not installed
2023-05-09 09:19:58,702:INFO:             mlxtend: Not installed
2023-05-09 09:19:58,702:INFO:       statsforecast: Not installed
2023-05-09 09:19:58,702:INFO:        tune_sklearn: Not installed
2023-05-09 09:19:58,702:INFO:                 ray: Not installed
2023-05-09 09:19:58,702:INFO:            hyperopt: Not installed
2023-05-09 09:19:58,702:INFO:              optuna: Not installed
2023-05-09 09:19:58,702:INFO:               skopt: Not installed
2023-05-09 09:19:58,702:INFO:              mlflow: Not installed
2023-05-09 09:19:58,702:INFO:              gradio: Not installed
2023-05-09 09:19:58,702:INFO:             fastapi: Not installed
2023-05-09 09:19:58,702:INFO:             uvicorn: Not installed
2023-05-09 09:19:58,702:INFO:              m2cgen: Not installed
2023-05-09 09:19:58,702:INFO:           evidently: Not installed
2023-05-09 09:19:58,702:INFO:               fugue: Not installed
2023-05-09 09:19:58,702:INFO:           streamlit: Not installed
2023-05-09 09:19:58,702:INFO:             prophet: Not installed
2023-05-09 09:19:58,703:INFO:None
2023-05-09 09:19:58,703:INFO:Set up data.
2023-05-09 09:20:12,669:INFO:PyCaret ClassificationExperiment
2023-05-09 09:20:12,669:INFO:Logging name: clf-default-name
2023-05-09 09:20:12,669:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-09 09:20:12,669:INFO:version 3.0.0
2023-05-09 09:20:12,669:INFO:Initializing setup()
2023-05-09 09:20:12,669:INFO:self.USI: 6bb2
2023-05-09 09:20:12,669:INFO:self._variable_keys: {'y', 'exp_name_log', 'seed', 'y_test', 'X', 'X_train', 'data', '_available_plots', 'html_param', 'idx', 'gpu_n_jobs_param', '_ml_usecase', 'log_plots_param', 'USI', 'y_train', 'X_test', 'logging_param', 'fold_groups_param', 'fix_imbalance', 'gpu_param', 'pipeline', 'n_jobs_param', 'exp_id', 'fold_shuffle_param', 'is_multiclass', 'target_param', 'memory', 'fold_generator'}
2023-05-09 09:20:12,669:INFO:Checking environment
2023-05-09 09:20:12,670:INFO:python_version: 3.10.10
2023-05-09 09:20:12,670:INFO:python_build: ('main', 'Mar 24 2023 20:00:38')
2023-05-09 09:20:12,670:INFO:machine: AMD64
2023-05-09 09:20:12,670:INFO:platform: Windows-10-10.0.19041-SP0
2023-05-09 09:20:12,676:INFO:Memory: svmem(total=8375230464, available=877142016, percent=89.5, used=7498088448, free=877142016)
2023-05-09 09:20:12,676:INFO:Physical Core: 4
2023-05-09 09:20:12,676:INFO:Logical Core: 8
2023-05-09 09:20:12,676:INFO:Checking libraries
2023-05-09 09:20:12,676:INFO:System:
2023-05-09 09:20:12,676:INFO:    python: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:00:38) [MSC v.1934 64 bit (AMD64)]
2023-05-09 09:20:12,676:INFO:executable: c:\Users\vande\anaconda3\envs\article\python.exe
2023-05-09 09:20:12,676:INFO:   machine: Windows-10-10.0.19041-SP0
2023-05-09 09:20:12,676:INFO:PyCaret required dependencies:
2023-05-09 09:20:12,677:INFO:                 pip: 23.1.2
2023-05-09 09:20:12,677:INFO:          setuptools: 67.7.2
2023-05-09 09:20:12,677:INFO:             pycaret: 3.0.0
2023-05-09 09:20:12,677:INFO:             IPython: 8.12.0
2023-05-09 09:20:12,677:INFO:          ipywidgets: 8.0.6
2023-05-09 09:20:12,677:INFO:                tqdm: 4.65.0
2023-05-09 09:20:12,677:INFO:               numpy: 1.24.3
2023-05-09 09:20:12,677:INFO:              pandas: 1.5.3
2023-05-09 09:20:12,677:INFO:              jinja2: 3.1.2
2023-05-09 09:20:12,677:INFO:               scipy: 1.10.1
2023-05-09 09:20:12,677:INFO:              joblib: 1.2.0
2023-05-09 09:20:12,677:INFO:             sklearn: 1.2.2
2023-05-09 09:20:12,677:INFO:                pyod: 1.0.9
2023-05-09 09:20:12,678:INFO:            imblearn: 0.10.1
2023-05-09 09:20:12,678:INFO:   category_encoders: 2.6.0
2023-05-09 09:20:12,678:INFO:            lightgbm: 3.3.5
2023-05-09 09:20:12,678:INFO:               numba: 0.56.4
2023-05-09 09:20:12,678:INFO:            requests: 2.29.0
2023-05-09 09:20:12,678:INFO:          matplotlib: 3.7.1
2023-05-09 09:20:12,678:INFO:          scikitplot: 0.3.7
2023-05-09 09:20:12,678:INFO:         yellowbrick: 1.5
2023-05-09 09:20:12,678:INFO:              plotly: 5.14.1
2023-05-09 09:20:12,678:INFO:             kaleido: 0.2.1
2023-05-09 09:20:12,678:INFO:         statsmodels: 0.13.5
2023-05-09 09:20:12,678:INFO:              sktime: 0.17.2
2023-05-09 09:20:12,678:INFO:               tbats: 1.1.3
2023-05-09 09:20:12,678:INFO:            pmdarima: 2.0.3
2023-05-09 09:20:12,678:INFO:              psutil: 5.9.5
2023-05-09 09:20:12,679:INFO:PyCaret optional dependencies:
2023-05-09 09:20:12,679:INFO:                shap: Not installed
2023-05-09 09:20:12,679:INFO:           interpret: Not installed
2023-05-09 09:20:12,679:INFO:                umap: Not installed
2023-05-09 09:20:12,679:INFO:    pandas_profiling: Not installed
2023-05-09 09:20:12,679:INFO:  explainerdashboard: Not installed
2023-05-09 09:20:12,679:INFO:             autoviz: Not installed
2023-05-09 09:20:12,679:INFO:           fairlearn: Not installed
2023-05-09 09:20:12,679:INFO:             xgboost: Not installed
2023-05-09 09:20:12,679:INFO:            catboost: Not installed
2023-05-09 09:20:12,679:INFO:              kmodes: Not installed
2023-05-09 09:20:12,679:INFO:             mlxtend: Not installed
2023-05-09 09:20:12,679:INFO:       statsforecast: Not installed
2023-05-09 09:20:12,679:INFO:        tune_sklearn: Not installed
2023-05-09 09:20:12,680:INFO:                 ray: Not installed
2023-05-09 09:20:12,680:INFO:            hyperopt: Not installed
2023-05-09 09:20:12,680:INFO:              optuna: Not installed
2023-05-09 09:20:12,680:INFO:               skopt: Not installed
2023-05-09 09:20:12,680:INFO:              mlflow: Not installed
2023-05-09 09:20:12,680:INFO:              gradio: Not installed
2023-05-09 09:20:12,680:INFO:             fastapi: Not installed
2023-05-09 09:20:12,680:INFO:             uvicorn: Not installed
2023-05-09 09:20:12,680:INFO:              m2cgen: Not installed
2023-05-09 09:20:12,680:INFO:           evidently: Not installed
2023-05-09 09:20:12,680:INFO:               fugue: Not installed
2023-05-09 09:20:12,680:INFO:           streamlit: Not installed
2023-05-09 09:20:12,680:INFO:             prophet: Not installed
2023-05-09 09:20:12,681:INFO:None
2023-05-09 09:20:12,681:INFO:Set up data.
2023-05-09 09:20:12,773:INFO:Set up train/test split.
2023-05-09 09:20:12,829:INFO:Set up index.
2023-05-09 09:20:12,830:INFO:Set up folding strategy.
2023-05-09 09:20:12,830:INFO:Assigning column types.
2023-05-09 09:20:12,834:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-09 09:20:12,890:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-09 09:20:12,895:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-09 09:20:12,944:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:12,982:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:13,031:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-09 09:20:13,032:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-09 09:20:13,061:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:13,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:13,062:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-09 09:20:13,119:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-09 09:20:13,156:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:13,156:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:13,213:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-09 09:20:13,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:13,246:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:13,246:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-09 09:20:13,324:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:13,325:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:13,409:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:13,410:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:13,414:INFO:Preparing preprocessing pipeline...
2023-05-09 09:20:13,415:INFO:Set up label encoding.
2023-05-09 09:20:13,415:INFO:Set up simple imputation.
2023-05-09 09:20:13,420:INFO:Set up encoding of categorical features.
2023-05-09 09:20:14,411:INFO:Finished creating preprocessing pipeline.
2023-05-09 09:20:14,417:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vande\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['preprocessed_news'],
                                    transformer=LeaveOneOutEncoder(cols=['preprocessed_news'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=123,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0)))],
         verbose=False)
2023-05-09 09:20:14,418:INFO:Creating final display dataframe.
2023-05-09 09:20:16,316:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, true: 1
4           Original data shape         (7200, 2)
5        Transformed data shape         (7200, 2)
6   Transformed train set shape         (5040, 2)
7    Transformed test set shape         (2160, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              6bb2
2023-05-09 09:20:16,433:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:16,434:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:16,514:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:16,514:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:20:16,515:INFO:setup() successfully completed in 3.99s...............
2023-05-09 09:20:27,695:INFO:Initializing compare_models()
2023-05-09 09:20:27,696:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-09 09:20:27,696:INFO:Checking exceptions
2023-05-09 09:20:27,703:INFO:Preparing display monitor
2023-05-09 09:20:27,751:INFO:Initializing Logistic Regression
2023-05-09 09:20:27,752:INFO:Total runtime is 1.6641616821289062e-05 minutes
2023-05-09 09:20:27,759:INFO:SubProcess create_model() called ==================================
2023-05-09 09:20:27,760:INFO:Initializing create_model()
2023-05-09 09:20:27,760:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B28C880>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:20:27,760:INFO:Checking exceptions
2023-05-09 09:20:27,760:INFO:Importing libraries
2023-05-09 09:20:27,760:INFO:Copying training dataset
2023-05-09 09:20:27,800:INFO:Defining folds
2023-05-09 09:20:27,801:INFO:Declaring metric variables
2023-05-09 09:20:27,813:INFO:Importing untrained model
2023-05-09 09:20:27,821:INFO:Logistic Regression Imported successfully
2023-05-09 09:20:27,835:INFO:Starting cross validation
2023-05-09 09:20:27,838:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:20:39,319:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:238: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, y = self._memory_transform(

2023-05-09 09:20:40,983:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:20:41,401:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:20:42,205:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:231: UserWarning: Persisting input arguments took 0.72s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  fitted_transformer = self._memory_fit(

2023-05-09 09:20:42,591:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:20:43,312:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:20:44,590:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:20:44,830:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.81s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:20:44,984:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:20:45,129:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:20:45,317:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:20:45,385:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:20:45,421:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:20:45,543:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:20:45,773:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:20:46,513:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:20:47,345:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:20:47,360:INFO:Calculating mean and std
2023-05-09 09:20:47,363:INFO:Creating metrics dataframe
2023-05-09 09:20:47,593:INFO:Uploading results into container
2023-05-09 09:20:47,595:INFO:Uploading model into container now
2023-05-09 09:20:47,596:INFO:_master_model_container: 1
2023-05-09 09:20:47,596:INFO:_display_container: 2
2023-05-09 09:20:47,597:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-09 09:20:47,597:INFO:create_model() successfully completed......................................
2023-05-09 09:20:47,778:INFO:SubProcess create_model() end ==================================
2023-05-09 09:20:47,779:INFO:Creating metrics dataframe
2023-05-09 09:20:47,790:INFO:Initializing K Neighbors Classifier
2023-05-09 09:20:47,791:INFO:Total runtime is 0.3339816252390544 minutes
2023-05-09 09:20:47,795:INFO:SubProcess create_model() called ==================================
2023-05-09 09:20:47,796:INFO:Initializing create_model()
2023-05-09 09:20:47,796:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B28C880>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:20:47,797:INFO:Checking exceptions
2023-05-09 09:20:47,797:INFO:Importing libraries
2023-05-09 09:20:47,797:INFO:Copying training dataset
2023-05-09 09:20:47,803:INFO:Defining folds
2023-05-09 09:20:47,803:INFO:Declaring metric variables
2023-05-09 09:20:47,809:INFO:Importing untrained model
2023-05-09 09:20:47,817:INFO:K Neighbors Classifier Imported successfully
2023-05-09 09:20:47,828:INFO:Starting cross validation
2023-05-09 09:20:47,830:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:20:51,778:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:20:52,983:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:20:56,783:INFO:Calculating mean and std
2023-05-09 09:20:56,785:INFO:Creating metrics dataframe
2023-05-09 09:20:56,979:INFO:Uploading results into container
2023-05-09 09:20:56,980:INFO:Uploading model into container now
2023-05-09 09:20:56,981:INFO:_master_model_container: 2
2023-05-09 09:20:56,981:INFO:_display_container: 2
2023-05-09 09:20:56,981:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-09 09:20:56,981:INFO:create_model() successfully completed......................................
2023-05-09 09:20:57,110:INFO:SubProcess create_model() end ==================================
2023-05-09 09:20:57,110:INFO:Creating metrics dataframe
2023-05-09 09:20:57,127:INFO:Initializing Naive Bayes
2023-05-09 09:20:57,127:INFO:Total runtime is 0.4895928025245667 minutes
2023-05-09 09:20:57,132:INFO:SubProcess create_model() called ==================================
2023-05-09 09:20:57,133:INFO:Initializing create_model()
2023-05-09 09:20:57,134:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B28C880>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:20:57,134:INFO:Checking exceptions
2023-05-09 09:20:57,134:INFO:Importing libraries
2023-05-09 09:20:57,134:INFO:Copying training dataset
2023-05-09 09:20:57,141:INFO:Defining folds
2023-05-09 09:20:57,141:INFO:Declaring metric variables
2023-05-09 09:20:57,148:INFO:Importing untrained model
2023-05-09 09:20:57,153:INFO:Naive Bayes Imported successfully
2023-05-09 09:20:57,165:INFO:Starting cross validation
2023-05-09 09:20:57,168:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:21:00,041:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-05-09 09:21:00,042:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-05-09 09:21:00,223:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:00,253:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:00,361:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-05-09 09:21:00,362:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-05-09 09:21:00,382:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:00,405:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:21:00,435:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:00,501:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:00,743:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:00,888:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:00,991:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:02,595:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-05-09 09:21:02,596:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-05-09 09:21:02,733:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:02,765:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-05-09 09:21:02,765:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-05-09 09:21:02,772:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:21:02,785:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:02,908:INFO:Calculating mean and std
2023-05-09 09:21:02,911:INFO:Creating metrics dataframe
2023-05-09 09:21:03,128:INFO:Uploading results into container
2023-05-09 09:21:03,129:INFO:Uploading model into container now
2023-05-09 09:21:03,129:INFO:_master_model_container: 3
2023-05-09 09:21:03,130:INFO:_display_container: 2
2023-05-09 09:21:03,130:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-09 09:21:03,130:INFO:create_model() successfully completed......................................
2023-05-09 09:21:03,267:INFO:SubProcess create_model() end ==================================
2023-05-09 09:21:03,267:INFO:Creating metrics dataframe
2023-05-09 09:21:03,282:INFO:Initializing Decision Tree Classifier
2023-05-09 09:21:03,282:INFO:Total runtime is 0.5921806494394939 minutes
2023-05-09 09:21:03,288:INFO:SubProcess create_model() called ==================================
2023-05-09 09:21:03,288:INFO:Initializing create_model()
2023-05-09 09:21:03,289:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B28C880>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:21:03,289:INFO:Checking exceptions
2023-05-09 09:21:03,289:INFO:Importing libraries
2023-05-09 09:21:03,289:INFO:Copying training dataset
2023-05-09 09:21:03,298:INFO:Defining folds
2023-05-09 09:21:03,298:INFO:Declaring metric variables
2023-05-09 09:21:03,304:INFO:Importing untrained model
2023-05-09 09:21:03,312:INFO:Decision Tree Classifier Imported successfully
2023-05-09 09:21:03,321:INFO:Starting cross validation
2023-05-09 09:21:03,323:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:21:06,481:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:06,594:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:06,694:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:06,706:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:06,711:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:06,786:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:07,008:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:07,065:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:07,067:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:07,085:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:09,165:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:09,193:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:09,339:INFO:Calculating mean and std
2023-05-09 09:21:09,340:INFO:Creating metrics dataframe
2023-05-09 09:21:09,546:INFO:Uploading results into container
2023-05-09 09:21:09,547:INFO:Uploading model into container now
2023-05-09 09:21:09,547:INFO:_master_model_container: 4
2023-05-09 09:21:09,548:INFO:_display_container: 2
2023-05-09 09:21:09,548:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-09 09:21:09,548:INFO:create_model() successfully completed......................................
2023-05-09 09:21:09,673:INFO:SubProcess create_model() end ==================================
2023-05-09 09:21:09,673:INFO:Creating metrics dataframe
2023-05-09 09:21:09,687:INFO:Initializing SVM - Linear Kernel
2023-05-09 09:21:09,687:INFO:Total runtime is 0.698924485842387 minutes
2023-05-09 09:21:09,692:INFO:SubProcess create_model() called ==================================
2023-05-09 09:21:09,692:INFO:Initializing create_model()
2023-05-09 09:21:09,692:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B28C880>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:21:09,692:INFO:Checking exceptions
2023-05-09 09:21:09,692:INFO:Importing libraries
2023-05-09 09:21:09,692:INFO:Copying training dataset
2023-05-09 09:21:09,701:INFO:Defining folds
2023-05-09 09:21:09,701:INFO:Declaring metric variables
2023-05-09 09:21:09,705:INFO:Importing untrained model
2023-05-09 09:21:09,713:INFO:SVM - Linear Kernel Imported successfully
2023-05-09 09:21:09,723:INFO:Starting cross validation
2023-05-09 09:21:09,724:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:21:12,290:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:21:12,340:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:21:12,373:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:12,532:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:21:12,732:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:21:12,789:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:21:12,882:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:21:12,920:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:13,040:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:21:13,062:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:13,216:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:21:14,657:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:21:14,721:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:21:14,733:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:14,825:INFO:Calculating mean and std
2023-05-09 09:21:14,828:INFO:Creating metrics dataframe
2023-05-09 09:21:15,047:INFO:Uploading results into container
2023-05-09 09:21:15,049:INFO:Uploading model into container now
2023-05-09 09:21:15,049:INFO:_master_model_container: 5
2023-05-09 09:21:15,049:INFO:_display_container: 2
2023-05-09 09:21:15,050:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-09 09:21:15,050:INFO:create_model() successfully completed......................................
2023-05-09 09:21:15,182:INFO:SubProcess create_model() end ==================================
2023-05-09 09:21:15,182:INFO:Creating metrics dataframe
2023-05-09 09:21:15,198:INFO:Initializing Ridge Classifier
2023-05-09 09:21:15,198:INFO:Total runtime is 0.7907804131507874 minutes
2023-05-09 09:21:15,205:INFO:SubProcess create_model() called ==================================
2023-05-09 09:21:15,205:INFO:Initializing create_model()
2023-05-09 09:21:15,205:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B28C880>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:21:15,205:INFO:Checking exceptions
2023-05-09 09:21:15,206:INFO:Importing libraries
2023-05-09 09:21:15,206:INFO:Copying training dataset
2023-05-09 09:21:15,214:INFO:Defining folds
2023-05-09 09:21:15,214:INFO:Declaring metric variables
2023-05-09 09:21:15,220:INFO:Importing untrained model
2023-05-09 09:21:15,229:INFO:Ridge Classifier Imported successfully
2023-05-09 09:21:15,241:INFO:Starting cross validation
2023-05-09 09:21:15,243:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:21:17,807:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:21:17,822:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:21:17,826:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:17,842:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:17,905:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:21:17,952:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:18,064:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:21:18,091:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:18,256:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:21:18,275:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:18,392:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:21:18,413:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:18,541:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:21:18,558:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:21:18,563:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:18,577:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:20,405:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:21:20,417:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:20,455:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:21:20,469:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:20,618:INFO:Calculating mean and std
2023-05-09 09:21:20,620:INFO:Creating metrics dataframe
2023-05-09 09:21:20,896:INFO:Uploading results into container
2023-05-09 09:21:20,897:INFO:Uploading model into container now
2023-05-09 09:21:20,897:INFO:_master_model_container: 6
2023-05-09 09:21:20,897:INFO:_display_container: 2
2023-05-09 09:21:20,898:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-09 09:21:20,898:INFO:create_model() successfully completed......................................
2023-05-09 09:21:21,050:INFO:SubProcess create_model() end ==================================
2023-05-09 09:21:21,050:INFO:Creating metrics dataframe
2023-05-09 09:21:21,068:INFO:Initializing Random Forest Classifier
2023-05-09 09:21:21,069:INFO:Total runtime is 0.8886276324590048 minutes
2023-05-09 09:21:21,075:INFO:SubProcess create_model() called ==================================
2023-05-09 09:21:21,075:INFO:Initializing create_model()
2023-05-09 09:21:21,075:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B28C880>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:21:21,075:INFO:Checking exceptions
2023-05-09 09:21:21,075:INFO:Importing libraries
2023-05-09 09:21:21,076:INFO:Copying training dataset
2023-05-09 09:21:21,086:INFO:Defining folds
2023-05-09 09:21:21,087:INFO:Declaring metric variables
2023-05-09 09:21:21,095:INFO:Importing untrained model
2023-05-09 09:21:21,102:INFO:Random Forest Classifier Imported successfully
2023-05-09 09:21:21,115:INFO:Starting cross validation
2023-05-09 09:21:21,118:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:21:25,233:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:25,252:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:25,410:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:25,736:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:25,835:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:25,899:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.60s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:25,912:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:25,920:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:25,926:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:26,078:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.63s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:26,368:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:26,659:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:26,730:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:26,859:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:26,882:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:29,069:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:29,107:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:29,233:INFO:Calculating mean and std
2023-05-09 09:21:29,235:INFO:Creating metrics dataframe
2023-05-09 09:21:29,454:INFO:Uploading results into container
2023-05-09 09:21:29,455:INFO:Uploading model into container now
2023-05-09 09:21:29,455:INFO:_master_model_container: 7
2023-05-09 09:21:29,455:INFO:_display_container: 2
2023-05-09 09:21:29,456:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-09 09:21:29,457:INFO:create_model() successfully completed......................................
2023-05-09 09:21:29,582:INFO:SubProcess create_model() end ==================================
2023-05-09 09:21:29,582:INFO:Creating metrics dataframe
2023-05-09 09:21:29,601:INFO:Initializing Quadratic Discriminant Analysis
2023-05-09 09:21:29,601:INFO:Total runtime is 1.0308339516321818 minutes
2023-05-09 09:21:29,606:INFO:SubProcess create_model() called ==================================
2023-05-09 09:21:29,607:INFO:Initializing create_model()
2023-05-09 09:21:29,607:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B28C880>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:21:29,608:INFO:Checking exceptions
2023-05-09 09:21:29,608:INFO:Importing libraries
2023-05-09 09:21:29,608:INFO:Copying training dataset
2023-05-09 09:21:29,616:INFO:Defining folds
2023-05-09 09:21:29,616:INFO:Declaring metric variables
2023-05-09 09:21:29,622:INFO:Importing untrained model
2023-05-09 09:21:29,628:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-09 09:21:29,640:INFO:Starting cross validation
2023-05-09 09:21:29,642:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:21:30,838:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:21:30,941:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:21:30,975:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:21:31,087:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:21:31,367:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:21:31,382:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:21:31,459:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:21:31,576:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:21:32,051:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:32,053:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:32,098:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:32,098:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:32,165:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:32,166:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:32,282:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:32,282:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:32,336:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:32,336:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:32,345:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:32,346:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:32,347:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:21:32,364:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:32,385:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:21:32,426:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:32,474:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:32,474:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:32,477:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:21:32,516:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:32,590:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:32,590:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:32,597:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:32,597:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:32,640:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:32,640:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:32,643:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:21:32,677:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:32,688:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:32,688:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:32,838:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:32,839:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:32,880:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:32,881:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:32,883:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:21:32,904:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:32,946:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:32,946:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:32,973:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:21:32,995:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:33,008:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:33,008:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:33,049:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:21:33,067:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:33,108:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:33,109:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:33,131:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:21:33,150:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:33,953:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:21:34,006:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:21:34,870:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:34,870:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:34,907:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:34,907:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:35,029:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:35,029:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:35,031:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:21:35,040:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:35,059:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:21:35,059:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:21:35,062:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:21:35,071:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:35,235:INFO:Calculating mean and std
2023-05-09 09:21:35,237:INFO:Creating metrics dataframe
2023-05-09 09:21:35,520:INFO:Uploading results into container
2023-05-09 09:21:35,521:INFO:Uploading model into container now
2023-05-09 09:21:35,522:INFO:_master_model_container: 8
2023-05-09 09:21:35,522:INFO:_display_container: 2
2023-05-09 09:21:35,523:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-09 09:21:35,523:INFO:create_model() successfully completed......................................
2023-05-09 09:21:35,658:INFO:SubProcess create_model() end ==================================
2023-05-09 09:21:35,659:INFO:Creating metrics dataframe
2023-05-09 09:21:35,675:INFO:Initializing Ada Boost Classifier
2023-05-09 09:21:35,675:INFO:Total runtime is 1.1320597370465597 minutes
2023-05-09 09:21:35,681:INFO:SubProcess create_model() called ==================================
2023-05-09 09:21:35,681:INFO:Initializing create_model()
2023-05-09 09:21:35,681:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B28C880>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:21:35,681:INFO:Checking exceptions
2023-05-09 09:21:35,682:INFO:Importing libraries
2023-05-09 09:21:35,682:INFO:Copying training dataset
2023-05-09 09:21:35,688:INFO:Defining folds
2023-05-09 09:21:35,688:INFO:Declaring metric variables
2023-05-09 09:21:35,692:INFO:Importing untrained model
2023-05-09 09:21:35,700:INFO:Ada Boost Classifier Imported successfully
2023-05-09 09:21:35,710:INFO:Starting cross validation
2023-05-09 09:21:35,713:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:21:39,141:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:39,159:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:39,304:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:39,358:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:39,491:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:39,517:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:39,581:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:39,606:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:39,855:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:39,892:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:40,000:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:40,047:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:40,317:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:42,476:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:42,636:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:42,716:INFO:Calculating mean and std
2023-05-09 09:21:42,718:INFO:Creating metrics dataframe
2023-05-09 09:21:42,962:INFO:Uploading results into container
2023-05-09 09:21:42,963:INFO:Uploading model into container now
2023-05-09 09:21:42,964:INFO:_master_model_container: 9
2023-05-09 09:21:42,964:INFO:_display_container: 2
2023-05-09 09:21:42,964:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-09 09:21:42,965:INFO:create_model() successfully completed......................................
2023-05-09 09:21:43,104:INFO:SubProcess create_model() end ==================================
2023-05-09 09:21:43,104:INFO:Creating metrics dataframe
2023-05-09 09:21:43,124:INFO:Initializing Gradient Boosting Classifier
2023-05-09 09:21:43,124:INFO:Total runtime is 1.2562065402666729 minutes
2023-05-09 09:21:43,131:INFO:SubProcess create_model() called ==================================
2023-05-09 09:21:43,131:INFO:Initializing create_model()
2023-05-09 09:21:43,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B28C880>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:21:43,131:INFO:Checking exceptions
2023-05-09 09:21:43,132:INFO:Importing libraries
2023-05-09 09:21:43,132:INFO:Copying training dataset
2023-05-09 09:21:43,142:INFO:Defining folds
2023-05-09 09:21:43,142:INFO:Declaring metric variables
2023-05-09 09:21:43,148:INFO:Importing untrained model
2023-05-09 09:21:43,154:INFO:Gradient Boosting Classifier Imported successfully
2023-05-09 09:21:43,165:INFO:Starting cross validation
2023-05-09 09:21:43,167:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:21:47,056:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.86s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:47,125:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:47,205:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.75s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:47,289:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:47,369:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:47,651:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.69s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:47,724:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:47,785:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:47,831:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.70s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:48,035:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.88s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:21:48,142:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:48,197:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:48,388:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:48,447:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:48,631:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:50,808:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:50,818:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:51,088:INFO:Calculating mean and std
2023-05-09 09:21:51,091:INFO:Creating metrics dataframe
2023-05-09 09:21:51,431:INFO:Uploading results into container
2023-05-09 09:21:51,433:INFO:Uploading model into container now
2023-05-09 09:21:51,434:INFO:_master_model_container: 10
2023-05-09 09:21:51,434:INFO:_display_container: 2
2023-05-09 09:21:51,435:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-09 09:21:51,435:INFO:create_model() successfully completed......................................
2023-05-09 09:21:51,605:INFO:SubProcess create_model() end ==================================
2023-05-09 09:21:51,606:INFO:Creating metrics dataframe
2023-05-09 09:21:51,635:INFO:Initializing Linear Discriminant Analysis
2023-05-09 09:21:51,635:INFO:Total runtime is 1.3980572978655499 minutes
2023-05-09 09:21:51,642:INFO:SubProcess create_model() called ==================================
2023-05-09 09:21:51,642:INFO:Initializing create_model()
2023-05-09 09:21:51,643:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B28C880>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:21:51,643:INFO:Checking exceptions
2023-05-09 09:21:51,643:INFO:Importing libraries
2023-05-09 09:21:51,643:INFO:Copying training dataset
2023-05-09 09:21:51,653:INFO:Defining folds
2023-05-09 09:21:51,654:INFO:Declaring metric variables
2023-05-09 09:21:51,661:INFO:Importing untrained model
2023-05-09 09:21:51,669:INFO:Linear Discriminant Analysis Imported successfully
2023-05-09 09:21:51,685:INFO:Starting cross validation
2023-05-09 09:21:51,687:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:21:54,679:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:54,730:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:54,980:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:55,108:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:55,316:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:55,350:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:55,398:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:57,186:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:21:57,200:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py", line 622, in fit
    self._solve_svd(X, y)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py", line 533, in _solve_svd
    _, S, Vt = svd(X, full_matrices=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\scipy\linalg\_decomp_svd.py", line 123, in svd
    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\scipy\linalg\lapack.py", line 1004, in _compute_lwork
    raise ValueError("Internal work array size computation failed: "
ValueError: Internal work array size computation failed: -10

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-05-09 09:21:57,201:INFO:Calculating mean and std
2023-05-09 09:21:57,202:INFO:Creating metrics dataframe
2023-05-09 09:21:57,491:INFO:Uploading results into container
2023-05-09 09:21:57,492:INFO:Uploading model into container now
2023-05-09 09:21:57,492:INFO:_master_model_container: 11
2023-05-09 09:21:57,493:INFO:_display_container: 2
2023-05-09 09:21:57,493:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-09 09:21:57,493:INFO:create_model() successfully completed......................................
2023-05-09 09:21:57,705:INFO:SubProcess create_model() end ==================================
2023-05-09 09:21:57,705:INFO:Creating metrics dataframe
2023-05-09 09:21:57,726:INFO:Initializing Extra Trees Classifier
2023-05-09 09:21:57,726:INFO:Total runtime is 1.4995772202809654 minutes
2023-05-09 09:21:57,735:INFO:SubProcess create_model() called ==================================
2023-05-09 09:21:57,735:INFO:Initializing create_model()
2023-05-09 09:21:57,735:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B28C880>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:21:57,735:INFO:Checking exceptions
2023-05-09 09:21:57,735:INFO:Importing libraries
2023-05-09 09:21:57,736:INFO:Copying training dataset
2023-05-09 09:21:57,742:INFO:Defining folds
2023-05-09 09:21:57,743:INFO:Declaring metric variables
2023-05-09 09:21:57,750:INFO:Importing untrained model
2023-05-09 09:21:57,756:INFO:Extra Trees Classifier Imported successfully
2023-05-09 09:21:57,769:INFO:Starting cross validation
2023-05-09 09:21:57,771:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:22:01,632:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:22:01,714:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:22:01,744:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:22:02,011:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:22:02,154:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:22:02,206:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:22:02,310:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:02,329:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:02,360:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:22:02,458:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:22:02,526:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:02,945:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:02,949:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:02,987:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:03,234:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:03,236:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:05,705:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:05,791:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:05,937:INFO:Calculating mean and std
2023-05-09 09:22:05,939:INFO:Creating metrics dataframe
2023-05-09 09:22:06,201:INFO:Uploading results into container
2023-05-09 09:22:06,202:INFO:Uploading model into container now
2023-05-09 09:22:06,204:INFO:_master_model_container: 12
2023-05-09 09:22:06,204:INFO:_display_container: 2
2023-05-09 09:22:06,205:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-09 09:22:06,205:INFO:create_model() successfully completed......................................
2023-05-09 09:22:06,343:INFO:SubProcess create_model() end ==================================
2023-05-09 09:22:06,343:INFO:Creating metrics dataframe
2023-05-09 09:22:06,359:INFO:Initializing Light Gradient Boosting Machine
2023-05-09 09:22:06,360:INFO:Total runtime is 1.6434771458307904 minutes
2023-05-09 09:22:06,364:INFO:SubProcess create_model() called ==================================
2023-05-09 09:22:06,365:INFO:Initializing create_model()
2023-05-09 09:22:06,365:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B28C880>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:22:06,366:INFO:Checking exceptions
2023-05-09 09:22:06,366:INFO:Importing libraries
2023-05-09 09:22:06,366:INFO:Copying training dataset
2023-05-09 09:22:06,375:INFO:Defining folds
2023-05-09 09:22:06,375:INFO:Declaring metric variables
2023-05-09 09:22:06,381:INFO:Importing untrained model
2023-05-09 09:22:06,387:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-09 09:22:06,396:INFO:Starting cross validation
2023-05-09 09:22:06,398:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:22:09,237:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:09,390:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:09,586:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:09,666:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:09,729:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:09,852:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:09,900:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:22:10,099:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:10,281:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:12,045:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:12,130:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:12,276:INFO:Calculating mean and std
2023-05-09 09:22:12,278:INFO:Creating metrics dataframe
2023-05-09 09:22:12,593:INFO:Uploading results into container
2023-05-09 09:22:12,594:INFO:Uploading model into container now
2023-05-09 09:22:12,594:INFO:_master_model_container: 13
2023-05-09 09:22:12,595:INFO:_display_container: 2
2023-05-09 09:22:12,596:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-09 09:22:12,597:INFO:create_model() successfully completed......................................
2023-05-09 09:22:12,747:INFO:SubProcess create_model() end ==================================
2023-05-09 09:22:12,747:INFO:Creating metrics dataframe
2023-05-09 09:22:12,764:INFO:Initializing Dummy Classifier
2023-05-09 09:22:12,764:INFO:Total runtime is 1.7502050399780276 minutes
2023-05-09 09:22:12,770:INFO:SubProcess create_model() called ==================================
2023-05-09 09:22:12,771:INFO:Initializing create_model()
2023-05-09 09:22:12,771:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B28C880>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:22:12,771:INFO:Checking exceptions
2023-05-09 09:22:12,772:INFO:Importing libraries
2023-05-09 09:22:12,772:INFO:Copying training dataset
2023-05-09 09:22:12,778:INFO:Defining folds
2023-05-09 09:22:12,778:INFO:Declaring metric variables
2023-05-09 09:22:12,784:INFO:Importing untrained model
2023-05-09 09:22:12,790:INFO:Dummy Classifier Imported successfully
2023-05-09 09:22:12,801:INFO:Starting cross validation
2023-05-09 09:22:12,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:22:15,520:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:15,850:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:16,014:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:16,048:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:16,181:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:16,295:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:16,356:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:16,536:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:18,365:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:18,535:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:22:18,570:INFO:Calculating mean and std
2023-05-09 09:22:18,572:INFO:Creating metrics dataframe
2023-05-09 09:22:18,871:INFO:Uploading results into container
2023-05-09 09:22:18,872:INFO:Uploading model into container now
2023-05-09 09:22:18,873:INFO:_master_model_container: 14
2023-05-09 09:22:18,873:INFO:_display_container: 2
2023-05-09 09:22:18,873:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-09 09:22:18,873:INFO:create_model() successfully completed......................................
2023-05-09 09:22:19,012:INFO:SubProcess create_model() end ==================================
2023-05-09 09:22:19,013:INFO:Creating metrics dataframe
2023-05-09 09:22:19,046:INFO:Initializing create_model()
2023-05-09 09:22:19,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:22:19,047:INFO:Checking exceptions
2023-05-09 09:22:19,050:INFO:Importing libraries
2023-05-09 09:22:19,050:INFO:Copying training dataset
2023-05-09 09:22:19,054:INFO:Defining folds
2023-05-09 09:22:19,054:INFO:Declaring metric variables
2023-05-09 09:22:19,055:INFO:Importing untrained model
2023-05-09 09:22:19,055:INFO:Declaring custom model
2023-05-09 09:22:19,056:INFO:Logistic Regression Imported successfully
2023-05-09 09:22:19,058:INFO:Cross validation set to False
2023-05-09 09:22:19,058:INFO:Fitting Model
2023-05-09 09:22:20,350:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-09 09:22:20,351:INFO:create_model() successfully completed......................................
2023-05-09 09:22:20,516:INFO:_master_model_container: 14
2023-05-09 09:22:20,517:INFO:_display_container: 2
2023-05-09 09:22:20,517:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-09 09:22:20,518:INFO:compare_models() successfully completed......................................
2023-05-09 09:23:58,157:INFO:Initializing tune_model()
2023-05-09 09:23:58,157:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>)
2023-05-09 09:23:58,158:INFO:Checking exceptions
2023-05-09 09:23:58,190:INFO:Copying training dataset
2023-05-09 09:23:58,197:INFO:Checking base model
2023-05-09 09:23:58,197:INFO:Base model : Logistic Regression
2023-05-09 09:23:58,205:INFO:Declaring metric variables
2023-05-09 09:23:58,211:INFO:Defining Hyperparameters
2023-05-09 09:23:58,401:INFO:Tuning with n_jobs=-1
2023-05-09 09:23:58,402:INFO:Initializing RandomizedSearchCV
2023-05-09 09:24:16,587:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:20,275:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:21,514:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:23,163:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:23,538:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:23,910:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.61s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:24,719:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.59s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:25,448:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:26,221:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.54s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:28,348:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.66s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:28,705:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.56s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:32,113:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:32,594:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.53s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:33,133:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:33,734:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:35,853:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.58s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:36,513:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:37,455:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.57s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:38,303:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.62s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:42,796:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 0.049}
2023-05-09 09:24:42,797:INFO:Hyperparameter search completed
2023-05-09 09:24:42,797:INFO:SubProcess create_model() called ==================================
2023-05-09 09:24:42,798:INFO:Initializing create_model()
2023-05-09 09:24:42,798:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x0000019D7B58C070>, model_only=True, return_train_score=False, kwargs={'class_weight': 'balanced', 'C': 0.049})
2023-05-09 09:24:42,798:INFO:Checking exceptions
2023-05-09 09:24:42,798:INFO:Importing libraries
2023-05-09 09:24:42,798:INFO:Copying training dataset
2023-05-09 09:24:42,808:INFO:Defining folds
2023-05-09 09:24:42,808:INFO:Declaring metric variables
2023-05-09 09:24:42,812:INFO:Importing untrained model
2023-05-09 09:24:42,812:INFO:Declaring custom model
2023-05-09 09:24:42,818:INFO:Logistic Regression Imported successfully
2023-05-09 09:24:42,830:INFO:Starting cross validation
2023-05-09 09:24:42,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:24:45,522:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:45,650:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:45,847:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:45,891:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:46,139:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:46,275:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:46,379:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:46,514:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:48,463:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:48,647:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:48,821:INFO:Calculating mean and std
2023-05-09 09:24:48,824:INFO:Creating metrics dataframe
2023-05-09 09:24:48,836:INFO:Finalizing model
2023-05-09 09:24:50,044:INFO:Uploading results into container
2023-05-09 09:24:50,045:INFO:Uploading model into container now
2023-05-09 09:24:50,046:INFO:_master_model_container: 15
2023-05-09 09:24:50,046:INFO:_display_container: 3
2023-05-09 09:24:50,047:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-09 09:24:50,047:INFO:create_model() successfully completed......................................
2023-05-09 09:24:50,210:INFO:SubProcess create_model() end ==================================
2023-05-09 09:24:50,210:INFO:choose_better activated
2023-05-09 09:24:50,217:INFO:SubProcess create_model() called ==================================
2023-05-09 09:24:50,217:INFO:Initializing create_model()
2023-05-09 09:24:50,218:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:24:50,218:INFO:Checking exceptions
2023-05-09 09:24:50,220:INFO:Importing libraries
2023-05-09 09:24:50,221:INFO:Copying training dataset
2023-05-09 09:24:50,228:INFO:Defining folds
2023-05-09 09:24:50,229:INFO:Declaring metric variables
2023-05-09 09:24:50,229:INFO:Importing untrained model
2023-05-09 09:24:50,229:INFO:Declaring custom model
2023-05-09 09:24:50,230:INFO:Logistic Regression Imported successfully
2023-05-09 09:24:50,230:INFO:Starting cross validation
2023-05-09 09:24:50,231:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:24:52,980:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:53,245:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:53,346:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:53,368:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:53,780:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:53,837:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:53,849:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:53,870:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.50s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:24:53,884:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:54,235:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:55,984:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:56,109:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:24:56,302:INFO:Calculating mean and std
2023-05-09 09:24:56,302:INFO:Creating metrics dataframe
2023-05-09 09:24:56,305:INFO:Finalizing model
2023-05-09 09:24:57,380:INFO:Uploading results into container
2023-05-09 09:24:57,381:INFO:Uploading model into container now
2023-05-09 09:24:57,381:INFO:_master_model_container: 16
2023-05-09 09:24:57,381:INFO:_display_container: 4
2023-05-09 09:24:57,382:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-09 09:24:57,382:INFO:create_model() successfully completed......................................
2023-05-09 09:24:57,522:INFO:SubProcess create_model() end ==================================
2023-05-09 09:24:57,524:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.5
2023-05-09 09:24:57,525:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.5
2023-05-09 09:24:57,525:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-05-09 09:24:57,526:INFO:choose_better completed
2023-05-09 09:24:57,526:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-05-09 09:24:57,540:INFO:_master_model_container: 16
2023-05-09 09:24:57,540:INFO:_display_container: 3
2023-05-09 09:24:57,541:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-09 09:24:57,541:INFO:tune_model() successfully completed......................................
2023-05-09 09:25:06,923:INFO:Initializing plot_model()
2023-05-09 09:25:06,925:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000019D7B755540>, system=True)
2023-05-09 09:25:06,925:INFO:Checking exceptions
2023-05-09 09:25:06,931:INFO:Preloading libraries
2023-05-09 09:25:06,932:INFO:Copying training dataset
2023-05-09 09:25:06,932:INFO:Plot type: confusion_matrix
2023-05-09 09:25:07,597:INFO:Fitting Model
2023-05-09 09:25:07,599:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-05-09 09:25:07,600:INFO:Scoring test/hold-out set
2023-05-09 09:25:07,894:INFO:Visual Rendered Successfully
2023-05-09 09:25:08,072:INFO:plot_model() successfully completed......................................
2023-05-09 09:35:16,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-09 09:35:16,467:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-09 09:35:16,468:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-09 09:35:16,468:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2023-05-09 09:35:18,036:WARNING:
'prophet' is a soft dependency and not included in the pycaret installation. Please run: `pip install prophet` to install.
2023-05-09 09:35:18,673:INFO:PyCaret ClassificationExperiment
2023-05-09 09:35:18,673:INFO:Logging name: clf-default-name
2023-05-09 09:35:18,674:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2023-05-09 09:35:18,674:INFO:version 3.0.0
2023-05-09 09:35:18,674:INFO:Initializing setup()
2023-05-09 09:35:18,674:INFO:self.USI: 00c8
2023-05-09 09:35:18,674:INFO:self._variable_keys: {'n_jobs_param', 'fold_generator', 'html_param', 'pipeline', 'memory', 'exp_name_log', 'y', 'log_plots_param', '_available_plots', 'target_param', 'gpu_n_jobs_param', 'USI', 'y_train', 'y_test', 'fix_imbalance', 'gpu_param', 'logging_param', 'data', 'X', 'X_train', 'is_multiclass', 'idx', 'seed', 'fold_groups_param', 'X_test', '_ml_usecase', 'fold_shuffle_param', 'exp_id'}
2023-05-09 09:35:18,674:INFO:Checking environment
2023-05-09 09:35:18,674:INFO:python_version: 3.10.10
2023-05-09 09:35:18,674:INFO:python_build: ('main', 'Mar 24 2023 20:00:38')
2023-05-09 09:35:18,674:INFO:machine: AMD64
2023-05-09 09:35:18,674:INFO:platform: Windows-10-10.0.19041-SP0
2023-05-09 09:35:18,680:INFO:Memory: svmem(total=8375230464, available=1041027072, percent=87.6, used=7334203392, free=1041027072)
2023-05-09 09:35:18,680:INFO:Physical Core: 4
2023-05-09 09:35:18,680:INFO:Logical Core: 8
2023-05-09 09:35:18,680:INFO:Checking libraries
2023-05-09 09:35:18,680:INFO:System:
2023-05-09 09:35:18,680:INFO:    python: 3.10.10 | packaged by conda-forge | (main, Mar 24 2023, 20:00:38) [MSC v.1934 64 bit (AMD64)]
2023-05-09 09:35:18,680:INFO:executable: c:\Users\vande\anaconda3\envs\article\python.exe
2023-05-09 09:35:18,680:INFO:   machine: Windows-10-10.0.19041-SP0
2023-05-09 09:35:18,681:INFO:PyCaret required dependencies:
2023-05-09 09:35:18,681:INFO:                 pip: 23.1.2
2023-05-09 09:35:18,681:INFO:          setuptools: 67.7.2
2023-05-09 09:35:18,681:INFO:             pycaret: 3.0.0
2023-05-09 09:35:18,681:INFO:             IPython: 8.12.0
2023-05-09 09:35:18,681:INFO:          ipywidgets: 8.0.6
2023-05-09 09:35:18,681:INFO:                tqdm: 4.65.0
2023-05-09 09:35:18,681:INFO:               numpy: 1.24.3
2023-05-09 09:35:18,681:INFO:              pandas: 1.5.3
2023-05-09 09:35:18,681:INFO:              jinja2: 3.1.2
2023-05-09 09:35:18,681:INFO:               scipy: 1.10.1
2023-05-09 09:35:18,681:INFO:              joblib: 1.2.0
2023-05-09 09:35:18,681:INFO:             sklearn: 1.2.2
2023-05-09 09:35:18,681:INFO:                pyod: 1.0.9
2023-05-09 09:35:18,681:INFO:            imblearn: 0.10.1
2023-05-09 09:35:18,681:INFO:   category_encoders: 2.6.0
2023-05-09 09:35:18,681:INFO:            lightgbm: 3.3.5
2023-05-09 09:35:18,681:INFO:               numba: 0.56.4
2023-05-09 09:35:18,682:INFO:            requests: 2.29.0
2023-05-09 09:35:18,682:INFO:          matplotlib: 3.7.1
2023-05-09 09:35:18,682:INFO:          scikitplot: 0.3.7
2023-05-09 09:35:18,682:INFO:         yellowbrick: 1.5
2023-05-09 09:35:18,682:INFO:              plotly: 5.14.1
2023-05-09 09:35:18,682:INFO:             kaleido: 0.2.1
2023-05-09 09:35:18,682:INFO:         statsmodels: 0.13.5
2023-05-09 09:35:18,682:INFO:              sktime: 0.17.2
2023-05-09 09:35:18,682:INFO:               tbats: 1.1.3
2023-05-09 09:35:18,682:INFO:            pmdarima: 2.0.3
2023-05-09 09:35:18,682:INFO:              psutil: 5.9.5
2023-05-09 09:35:18,682:INFO:PyCaret optional dependencies:
2023-05-09 09:35:18,697:INFO:                shap: Not installed
2023-05-09 09:35:18,697:INFO:           interpret: Not installed
2023-05-09 09:35:18,697:INFO:                umap: Not installed
2023-05-09 09:35:18,697:INFO:    pandas_profiling: Not installed
2023-05-09 09:35:18,697:INFO:  explainerdashboard: Not installed
2023-05-09 09:35:18,697:INFO:             autoviz: Not installed
2023-05-09 09:35:18,697:INFO:           fairlearn: Not installed
2023-05-09 09:35:18,697:INFO:             xgboost: Not installed
2023-05-09 09:35:18,697:INFO:            catboost: Not installed
2023-05-09 09:35:18,697:INFO:              kmodes: Not installed
2023-05-09 09:35:18,697:INFO:             mlxtend: Not installed
2023-05-09 09:35:18,697:INFO:       statsforecast: Not installed
2023-05-09 09:35:18,697:INFO:        tune_sklearn: Not installed
2023-05-09 09:35:18,697:INFO:                 ray: Not installed
2023-05-09 09:35:18,698:INFO:            hyperopt: Not installed
2023-05-09 09:35:18,698:INFO:              optuna: Not installed
2023-05-09 09:35:18,698:INFO:               skopt: Not installed
2023-05-09 09:35:18,698:INFO:              mlflow: Not installed
2023-05-09 09:35:18,698:INFO:              gradio: Not installed
2023-05-09 09:35:18,698:INFO:             fastapi: Not installed
2023-05-09 09:35:18,698:INFO:             uvicorn: Not installed
2023-05-09 09:35:18,698:INFO:              m2cgen: Not installed
2023-05-09 09:35:18,698:INFO:           evidently: Not installed
2023-05-09 09:35:18,698:INFO:               fugue: Not installed
2023-05-09 09:35:18,698:INFO:           streamlit: Not installed
2023-05-09 09:35:18,698:INFO:             prophet: Not installed
2023-05-09 09:35:18,698:INFO:None
2023-05-09 09:35:18,698:INFO:Set up data.
2023-05-09 09:35:18,782:INFO:Set up train/test split.
2023-05-09 09:35:18,826:INFO:Set up index.
2023-05-09 09:35:18,827:INFO:Set up folding strategy.
2023-05-09 09:35:18,827:INFO:Assigning column types.
2023-05-09 09:35:18,830:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2023-05-09 09:35:18,880:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-09 09:35:18,884:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-09 09:35:18,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:18,961:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:19,011:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2023-05-09 09:35:19,012:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-09 09:35:19,042:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:19,043:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:19,043:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2023-05-09 09:35:19,094:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-09 09:35:19,128:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:19,129:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:19,186:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2023-05-09 09:35:19,226:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:19,226:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:19,227:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2023-05-09 09:35:19,307:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:19,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:19,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:19,388:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:19,391:INFO:Preparing preprocessing pipeline...
2023-05-09 09:35:19,394:INFO:Set up label encoding.
2023-05-09 09:35:19,394:INFO:Set up simple imputation.
2023-05-09 09:35:19,396:INFO:Set up encoding of categorical features.
2023-05-09 09:35:20,070:INFO:Finished creating preprocessing pipeline.
2023-05-09 09:35:20,079:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\vande\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,...
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent',
                                                              verbose='deprecated'))),
                ('rest_encoding',
                 TransformerWrapper(exclude=None, include=['preprocessed_news'],
                                    transformer=LeaveOneOutEncoder(cols=['preprocessed_news'],
                                                                   drop_invariant=False,
                                                                   handle_missing='return_nan',
                                                                   handle_unknown='value',
                                                                   random_state=123,
                                                                   return_df=True,
                                                                   sigma=None,
                                                                   verbose=0)))],
         verbose=False)
2023-05-09 09:35:20,079:INFO:Creating final display dataframe.
2023-05-09 09:35:22,063:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target             label
2                   Target type            Binary
3                Target mapping  fake: 0, true: 1
4           Original data shape         (7200, 2)
5        Transformed data shape         (7200, 2)
6   Transformed train set shape         (5040, 2)
7    Transformed test set shape         (2160, 2)
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator   StratifiedKFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  clf-default-name
21                          USI              00c8
2023-05-09 09:35:22,161:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:22,162:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:22,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:22,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2023-05-09 09:35:22,246:INFO:setup() successfully completed in 3.83s...............
2023-05-09 09:35:22,299:INFO:Initializing compare_models()
2023-05-09 09:35:22,299:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, include=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>}, exclude=None)
2023-05-09 09:35:22,299:INFO:Checking exceptions
2023-05-09 09:35:22,305:INFO:Preparing display monitor
2023-05-09 09:35:22,354:INFO:Initializing Logistic Regression
2023-05-09 09:35:22,354:INFO:Total runtime is 0.0 minutes
2023-05-09 09:35:22,362:INFO:SubProcess create_model() called ==================================
2023-05-09 09:35:22,363:INFO:Initializing create_model()
2023-05-09 09:35:22,363:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F65B31DAB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:35:22,363:INFO:Checking exceptions
2023-05-09 09:35:22,363:INFO:Importing libraries
2023-05-09 09:35:22,363:INFO:Copying training dataset
2023-05-09 09:35:22,368:INFO:Defining folds
2023-05-09 09:35:22,369:INFO:Declaring metric variables
2023-05-09 09:35:22,372:INFO:Importing untrained model
2023-05-09 09:35:22,380:INFO:Logistic Regression Imported successfully
2023-05-09 09:35:22,393:INFO:Starting cross validation
2023-05-09 09:35:22,395:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:35:32,034:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:32,247:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:32,573:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:32,792:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:32,956:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:32,966:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:33,168:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:33,481:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:34,821:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:34,985:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:35,690:INFO:Calculating mean and std
2023-05-09 09:35:35,692:INFO:Creating metrics dataframe
2023-05-09 09:35:36,013:INFO:Uploading results into container
2023-05-09 09:35:36,014:INFO:Uploading model into container now
2023-05-09 09:35:36,015:INFO:_master_model_container: 1
2023-05-09 09:35:36,015:INFO:_display_container: 2
2023-05-09 09:35:36,015:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-09 09:35:36,015:INFO:create_model() successfully completed......................................
2023-05-09 09:35:36,097:INFO:SubProcess create_model() end ==================================
2023-05-09 09:35:36,097:INFO:Creating metrics dataframe
2023-05-09 09:35:36,110:INFO:Initializing K Neighbors Classifier
2023-05-09 09:35:36,111:INFO:Total runtime is 0.22929120858510335 minutes
2023-05-09 09:35:36,117:INFO:SubProcess create_model() called ==================================
2023-05-09 09:35:36,117:INFO:Initializing create_model()
2023-05-09 09:35:36,118:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F65B31DAB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:35:36,118:INFO:Checking exceptions
2023-05-09 09:35:36,118:INFO:Importing libraries
2023-05-09 09:35:36,118:INFO:Copying training dataset
2023-05-09 09:35:36,125:INFO:Defining folds
2023-05-09 09:35:36,125:INFO:Declaring metric variables
2023-05-09 09:35:36,131:INFO:Importing untrained model
2023-05-09 09:35:36,138:INFO:K Neighbors Classifier Imported successfully
2023-05-09 09:35:36,149:INFO:Starting cross validation
2023-05-09 09:35:36,151:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:35:39,539:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:40,051:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:35:40,341:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:319: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:35:42,889:INFO:Calculating mean and std
2023-05-09 09:35:42,891:INFO:Creating metrics dataframe
2023-05-09 09:35:43,234:INFO:Uploading results into container
2023-05-09 09:35:43,235:INFO:Uploading model into container now
2023-05-09 09:35:43,235:INFO:_master_model_container: 2
2023-05-09 09:35:43,235:INFO:_display_container: 2
2023-05-09 09:35:43,236:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2023-05-09 09:35:43,236:INFO:create_model() successfully completed......................................
2023-05-09 09:35:43,309:INFO:SubProcess create_model() end ==================================
2023-05-09 09:35:43,309:INFO:Creating metrics dataframe
2023-05-09 09:35:43,322:INFO:Initializing Naive Bayes
2023-05-09 09:35:43,323:INFO:Total runtime is 0.3494908452033997 minutes
2023-05-09 09:35:43,329:INFO:SubProcess create_model() called ==================================
2023-05-09 09:35:43,330:INFO:Initializing create_model()
2023-05-09 09:35:43,330:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F65B31DAB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:35:43,330:INFO:Checking exceptions
2023-05-09 09:35:43,330:INFO:Importing libraries
2023-05-09 09:35:43,330:INFO:Copying training dataset
2023-05-09 09:35:43,336:INFO:Defining folds
2023-05-09 09:35:43,336:INFO:Declaring metric variables
2023-05-09 09:35:43,340:INFO:Importing untrained model
2023-05-09 09:35:43,347:INFO:Naive Bayes Imported successfully
2023-05-09 09:35:43,359:INFO:Starting cross validation
2023-05-09 09:35:43,362:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:35:45,234:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-05-09 09:35:45,234:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-05-09 09:35:45,449:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:45,524:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:45,558:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:45,590:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:45,603:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-05-09 09:35:45,604:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-05-09 09:35:45,682:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:35:45,701:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:46,055:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:46,149:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:46,223:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:47,552:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-05-09 09:35:47,552:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-05-09 09:35:47,642:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:47,733:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:515: RuntimeWarning: divide by zero encountered in log
  n_ij = -0.5 * np.sum(np.log(2.0 * np.pi * self.var_[i, :]))

2023-05-09 09:35:47,734:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\naive_bayes.py:516: RuntimeWarning: invalid value encountered in divide
  n_ij -= 0.5 * np.sum(((X - self.theta_[i, :]) ** 2) / (self.var_[i, :]), 1)

2023-05-09 09:35:47,739:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:35:47,750:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:48,515:INFO:Calculating mean and std
2023-05-09 09:35:48,517:INFO:Creating metrics dataframe
2023-05-09 09:35:48,855:INFO:Uploading results into container
2023-05-09 09:35:48,856:INFO:Uploading model into container now
2023-05-09 09:35:48,856:INFO:_master_model_container: 3
2023-05-09 09:35:48,857:INFO:_display_container: 2
2023-05-09 09:35:48,857:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2023-05-09 09:35:48,857:INFO:create_model() successfully completed......................................
2023-05-09 09:35:48,930:INFO:SubProcess create_model() end ==================================
2023-05-09 09:35:48,931:INFO:Creating metrics dataframe
2023-05-09 09:35:48,943:INFO:Initializing Decision Tree Classifier
2023-05-09 09:35:48,944:INFO:Total runtime is 0.4431693951288859 minutes
2023-05-09 09:35:48,948:INFO:SubProcess create_model() called ==================================
2023-05-09 09:35:48,948:INFO:Initializing create_model()
2023-05-09 09:35:48,949:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F65B31DAB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:35:48,949:INFO:Checking exceptions
2023-05-09 09:35:48,949:INFO:Importing libraries
2023-05-09 09:35:48,949:INFO:Copying training dataset
2023-05-09 09:35:48,953:INFO:Defining folds
2023-05-09 09:35:48,953:INFO:Declaring metric variables
2023-05-09 09:35:48,957:INFO:Importing untrained model
2023-05-09 09:35:48,962:INFO:Decision Tree Classifier Imported successfully
2023-05-09 09:35:48,973:INFO:Starting cross validation
2023-05-09 09:35:48,975:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:35:50,749:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:50,872:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:51,196:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:51,208:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:51,358:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:51,450:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:51,685:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:51,712:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:52,791:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:52,980:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:53,513:INFO:Calculating mean and std
2023-05-09 09:35:53,515:INFO:Creating metrics dataframe
2023-05-09 09:35:53,864:INFO:Uploading results into container
2023-05-09 09:35:53,865:INFO:Uploading model into container now
2023-05-09 09:35:53,866:INFO:_master_model_container: 4
2023-05-09 09:35:53,866:INFO:_display_container: 2
2023-05-09 09:35:53,866:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       random_state=123, splitter='best')
2023-05-09 09:35:53,866:INFO:create_model() successfully completed......................................
2023-05-09 09:35:53,947:INFO:SubProcess create_model() end ==================================
2023-05-09 09:35:53,947:INFO:Creating metrics dataframe
2023-05-09 09:35:53,960:INFO:Initializing SVM - Linear Kernel
2023-05-09 09:35:53,961:INFO:Total runtime is 0.5267928878466288 minutes
2023-05-09 09:35:53,966:INFO:SubProcess create_model() called ==================================
2023-05-09 09:35:53,966:INFO:Initializing create_model()
2023-05-09 09:35:53,966:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F65B31DAB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:35:53,966:INFO:Checking exceptions
2023-05-09 09:35:53,967:INFO:Importing libraries
2023-05-09 09:35:53,967:INFO:Copying training dataset
2023-05-09 09:35:53,971:INFO:Defining folds
2023-05-09 09:35:53,972:INFO:Declaring metric variables
2023-05-09 09:35:53,976:INFO:Importing untrained model
2023-05-09 09:35:53,983:INFO:SVM - Linear Kernel Imported successfully
2023-05-09 09:35:53,995:INFO:Starting cross validation
2023-05-09 09:35:53,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:35:55,525:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:35:55,579:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:35:55,600:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:55,686:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:35:55,736:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:35:55,752:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:56,023:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:35:56,042:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:56,059:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:35:56,069:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:35:56,265:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:35:57,415:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:35:57,516:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\_available_if.py", line 32, in __get__
    if not self.check(obj):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\linear_model\_stochastic_gradient.py", line 1235, in _check_proba
    raise AttributeError(
AttributeError: probability estimates are not available for loss='hinge'

  warnings.warn(

2023-05-09 09:35:57,523:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:35:58,262:INFO:Calculating mean and std
2023-05-09 09:35:58,263:INFO:Creating metrics dataframe
2023-05-09 09:35:58,591:INFO:Uploading results into container
2023-05-09 09:35:58,592:INFO:Uploading model into container now
2023-05-09 09:35:58,593:INFO:_master_model_container: 5
2023-05-09 09:35:58,594:INFO:_display_container: 2
2023-05-09 09:35:58,595:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2023-05-09 09:35:58,595:INFO:create_model() successfully completed......................................
2023-05-09 09:35:58,671:INFO:SubProcess create_model() end ==================================
2023-05-09 09:35:58,672:INFO:Creating metrics dataframe
2023-05-09 09:35:58,690:INFO:Initializing Ridge Classifier
2023-05-09 09:35:58,690:INFO:Total runtime is 0.6056092818578084 minutes
2023-05-09 09:35:58,697:INFO:SubProcess create_model() called ==================================
2023-05-09 09:35:58,697:INFO:Initializing create_model()
2023-05-09 09:35:58,697:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F65B31DAB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:35:58,698:INFO:Checking exceptions
2023-05-09 09:35:58,698:INFO:Importing libraries
2023-05-09 09:35:58,698:INFO:Copying training dataset
2023-05-09 09:35:58,704:INFO:Defining folds
2023-05-09 09:35:58,704:INFO:Declaring metric variables
2023-05-09 09:35:58,712:INFO:Importing untrained model
2023-05-09 09:35:58,719:INFO:Ridge Classifier Imported successfully
2023-05-09 09:35:58,733:INFO:Starting cross validation
2023-05-09 09:35:58,735:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:36:00,348:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:36:00,364:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:00,428:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:36:00,452:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:00,463:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:36:00,508:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:00,778:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:36:00,800:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:01,036:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:36:01,047:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:36:01,057:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:01,071:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:01,262:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:36:01,300:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:01,344:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:36:01,369:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:02,394:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:36:02,408:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:02,581:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 76, in _cached_call
    return cache[method]
KeyError: 'predict_proba'

During handling of the above exception, another exception occurred:

Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 316, in _score
    y_pred = method_caller(clf, "predict_proba", X)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 78, in _cached_call
    result = getattr(estimator, method)(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 121, in __getattr__
    return getattr(self._final_estimator, name)
AttributeError: 'RidgeClassifier' object has no attribute 'predict_proba'

  warnings.warn(

2023-05-09 09:36:02,596:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:03,375:INFO:Calculating mean and std
2023-05-09 09:36:03,377:INFO:Creating metrics dataframe
2023-05-09 09:36:03,743:INFO:Uploading results into container
2023-05-09 09:36:03,745:INFO:Uploading model into container now
2023-05-09 09:36:03,745:INFO:_master_model_container: 6
2023-05-09 09:36:03,746:INFO:_display_container: 2
2023-05-09 09:36:03,746:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2023-05-09 09:36:03,746:INFO:create_model() successfully completed......................................
2023-05-09 09:36:03,831:INFO:SubProcess create_model() end ==================================
2023-05-09 09:36:03,832:INFO:Creating metrics dataframe
2023-05-09 09:36:03,847:INFO:Initializing Random Forest Classifier
2023-05-09 09:36:03,847:INFO:Total runtime is 0.6915485421816507 minutes
2023-05-09 09:36:03,853:INFO:SubProcess create_model() called ==================================
2023-05-09 09:36:03,853:INFO:Initializing create_model()
2023-05-09 09:36:03,853:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F65B31DAB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:36:03,853:INFO:Checking exceptions
2023-05-09 09:36:03,853:INFO:Importing libraries
2023-05-09 09:36:03,854:INFO:Copying training dataset
2023-05-09 09:36:03,859:INFO:Defining folds
2023-05-09 09:36:03,859:INFO:Declaring metric variables
2023-05-09 09:36:03,864:INFO:Importing untrained model
2023-05-09 09:36:03,871:INFO:Random Forest Classifier Imported successfully
2023-05-09 09:36:03,882:INFO:Starting cross validation
2023-05-09 09:36:03,884:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:36:06,221:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:06,369:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:06,380:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:06,803:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:06,864:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:06,964:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:06,966:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:06,972:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:08,536:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:08,537:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:09,069:INFO:Calculating mean and std
2023-05-09 09:36:09,070:INFO:Creating metrics dataframe
2023-05-09 09:36:09,383:INFO:Uploading results into container
2023-05-09 09:36:09,384:INFO:Uploading model into container now
2023-05-09 09:36:09,385:INFO:_master_model_container: 7
2023-05-09 09:36:09,385:INFO:_display_container: 2
2023-05-09 09:36:09,385:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       n_estimators=100, n_jobs=-1, oob_score=False,
                       random_state=123, verbose=0, warm_start=False)
2023-05-09 09:36:09,385:INFO:create_model() successfully completed......................................
2023-05-09 09:36:09,460:INFO:SubProcess create_model() end ==================================
2023-05-09 09:36:09,460:INFO:Creating metrics dataframe
2023-05-09 09:36:09,474:INFO:Initializing Quadratic Discriminant Analysis
2023-05-09 09:36:09,474:INFO:Total runtime is 0.7853287895520528 minutes
2023-05-09 09:36:09,481:INFO:SubProcess create_model() called ==================================
2023-05-09 09:36:09,481:INFO:Initializing create_model()
2023-05-09 09:36:09,481:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F65B31DAB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:36:09,481:INFO:Checking exceptions
2023-05-09 09:36:09,481:INFO:Importing libraries
2023-05-09 09:36:09,481:INFO:Copying training dataset
2023-05-09 09:36:09,488:INFO:Defining folds
2023-05-09 09:36:09,488:INFO:Declaring metric variables
2023-05-09 09:36:09,492:INFO:Importing untrained model
2023-05-09 09:36:09,498:INFO:Quadratic Discriminant Analysis Imported successfully
2023-05-09 09:36:09,508:INFO:Starting cross validation
2023-05-09 09:36:09,509:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:36:10,764:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:36:10,764:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:36:10,781:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:36:10,940:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:36:11,020:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,022:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,032:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,032:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,033:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:36:11,039:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,039:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,113:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:36:11,209:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,209:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,266:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,266:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,269:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:36:11,272:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,273:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,281:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:36:11,286:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:11,290:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:36:11,292:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,293:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,301:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:11,303:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:36:11,332:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:11,337:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,337:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,370:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:36:11,385:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,386:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,442:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,443:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,474:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:36:11,508:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:11,547:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,548:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,592:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,592:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,595:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:36:11,606:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,606:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,629:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:11,645:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,645:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,657:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:36:11,699:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:11,849:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,849:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,861:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:36:11,864:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:11,864:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:11,885:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:11,889:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:36:11,909:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:12,935:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:36:13,013:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:926: UserWarning: Variables are collinear
  warnings.warn("Variables are collinear")

2023-05-09 09:36:13,094:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:13,094:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:13,165:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:13,166:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:13,239:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:13,240:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:13,241:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:36:13,251:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:13,316:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:951: RuntimeWarning: divide by zero encountered in power
  X2 = np.dot(Xm, R * (S ** (-0.5)))

2023-05-09 09:36:13,316:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py:954: RuntimeWarning: divide by zero encountered in log
  u = np.asarray([np.sum(np.log(s)) for s in self.scalings_])

2023-05-09 09:36:13,318:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py:138: FitFailedWarning: Metric 'make_scorer(roc_auc_score, needs_proba=True, error_score=0.0, average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 130, in _score
    return super()._score(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_scorer.py", line 327, in _score
    return self._sign * self._score_func(y, y_pred, **self._kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\metrics.py", line 35, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_ranking.py", line 551, in roc_auc_score
    y_score = check_array(y_score, ensure_2d=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 921, in check_array
    _assert_all_finite(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\utils\validation.py", line 161, in _assert_all_finite
    raise ValueError(msg_err)
ValueError: Input contains NaN.

  warnings.warn(

2023-05-09 09:36:13,326:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:13,959:INFO:Calculating mean and std
2023-05-09 09:36:13,960:INFO:Creating metrics dataframe
2023-05-09 09:36:14,311:INFO:Uploading results into container
2023-05-09 09:36:14,312:INFO:Uploading model into container now
2023-05-09 09:36:14,314:INFO:_master_model_container: 8
2023-05-09 09:36:14,314:INFO:_display_container: 2
2023-05-09 09:36:14,315:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2023-05-09 09:36:14,315:INFO:create_model() successfully completed......................................
2023-05-09 09:36:14,397:INFO:SubProcess create_model() end ==================================
2023-05-09 09:36:14,397:INFO:Creating metrics dataframe
2023-05-09 09:36:14,411:INFO:Initializing Ada Boost Classifier
2023-05-09 09:36:14,412:INFO:Total runtime is 0.8676290353139241 minutes
2023-05-09 09:36:14,417:INFO:SubProcess create_model() called ==================================
2023-05-09 09:36:14,417:INFO:Initializing create_model()
2023-05-09 09:36:14,418:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F65B31DAB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:36:14,418:INFO:Checking exceptions
2023-05-09 09:36:14,418:INFO:Importing libraries
2023-05-09 09:36:14,418:INFO:Copying training dataset
2023-05-09 09:36:14,423:INFO:Defining folds
2023-05-09 09:36:14,423:INFO:Declaring metric variables
2023-05-09 09:36:14,428:INFO:Importing untrained model
2023-05-09 09:36:14,434:INFO:Ada Boost Classifier Imported successfully
2023-05-09 09:36:14,442:INFO:Starting cross validation
2023-05-09 09:36:14,444:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:36:16,602:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:16,675:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:16,797:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:16,936:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:17,102:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:17,385:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:17,507:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:17,511:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:19,100:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:19,191:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:19,918:INFO:Calculating mean and std
2023-05-09 09:36:19,919:INFO:Creating metrics dataframe
2023-05-09 09:36:20,296:INFO:Uploading results into container
2023-05-09 09:36:20,297:INFO:Uploading model into container now
2023-05-09 09:36:20,298:INFO:_master_model_container: 9
2023-05-09 09:36:20,298:INFO:_display_container: 2
2023-05-09 09:36:20,299:INFO:AdaBoostClassifier(algorithm='SAMME.R', base_estimator='deprecated',
                   estimator=None, learning_rate=1.0, n_estimators=50,
                   random_state=123)
2023-05-09 09:36:20,300:INFO:create_model() successfully completed......................................
2023-05-09 09:36:20,381:INFO:SubProcess create_model() end ==================================
2023-05-09 09:36:20,381:INFO:Creating metrics dataframe
2023-05-09 09:36:20,397:INFO:Initializing Gradient Boosting Classifier
2023-05-09 09:36:20,397:INFO:Total runtime is 0.9673923532168069 minutes
2023-05-09 09:36:20,404:INFO:SubProcess create_model() called ==================================
2023-05-09 09:36:20,404:INFO:Initializing create_model()
2023-05-09 09:36:20,404:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F65B31DAB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:36:20,405:INFO:Checking exceptions
2023-05-09 09:36:20,405:INFO:Importing libraries
2023-05-09 09:36:20,405:INFO:Copying training dataset
2023-05-09 09:36:20,412:INFO:Defining folds
2023-05-09 09:36:20,412:INFO:Declaring metric variables
2023-05-09 09:36:20,418:INFO:Importing untrained model
2023-05-09 09:36:20,423:INFO:Gradient Boosting Classifier Imported successfully
2023-05-09 09:36:20,433:INFO:Starting cross validation
2023-05-09 09:36:20,435:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:36:23,214:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.52s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:36:23,584:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:23,621:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:23,656:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.55s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:36:23,706:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:23,843:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:23,904:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py:310: UserWarning: Persisting input arguments took 0.51s to run.
If this happens often in your code, it can cause performance problems 
(results will be correct in all cases). 
The reason for this is probably some large input arguments for a wrapped
 function (e.g. large strings).
THIS IS A JOBLIB ISSUE. If you can, kindly provide the joblib's team with an
 example so that they can fix the problem.
  X, _ = self._memory_full_transform(self, X, None, with_final=False)

2023-05-09 09:36:23,984:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:24,114:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:24,257:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:24,342:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:25,837:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:26,356:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:26,388:INFO:Calculating mean and std
2023-05-09 09:36:26,390:INFO:Creating metrics dataframe
2023-05-09 09:36:26,698:INFO:Uploading results into container
2023-05-09 09:36:26,699:INFO:Uploading model into container now
2023-05-09 09:36:26,700:INFO:_master_model_container: 10
2023-05-09 09:36:26,700:INFO:_display_container: 2
2023-05-09 09:36:26,701:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2023-05-09 09:36:26,701:INFO:create_model() successfully completed......................................
2023-05-09 09:36:26,777:INFO:SubProcess create_model() end ==================================
2023-05-09 09:36:26,777:INFO:Creating metrics dataframe
2023-05-09 09:36:26,794:INFO:Initializing Linear Discriminant Analysis
2023-05-09 09:36:26,794:INFO:Total runtime is 1.0740001440048217 minutes
2023-05-09 09:36:26,799:INFO:SubProcess create_model() called ==================================
2023-05-09 09:36:26,800:INFO:Initializing create_model()
2023-05-09 09:36:26,800:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F65B31DAB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:36:26,800:INFO:Checking exceptions
2023-05-09 09:36:26,800:INFO:Importing libraries
2023-05-09 09:36:26,800:INFO:Copying training dataset
2023-05-09 09:36:26,807:INFO:Defining folds
2023-05-09 09:36:26,807:INFO:Declaring metric variables
2023-05-09 09:36:26,814:INFO:Importing untrained model
2023-05-09 09:36:26,820:INFO:Linear Discriminant Analysis Imported successfully
2023-05-09 09:36:26,831:INFO:Starting cross validation
2023-05-09 09:36:26,832:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:36:28,557:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:28,720:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:28,855:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:29,049:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:29,144:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:29,337:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:29,356:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:30,591:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:31,650:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py:378: FitFailedWarning: 
2 fits failed out of a total of 10.
The score on these train-test partitions for these parameters will be set to 0.
If these failures are not expected, you can try to debug them by setting error_score='raise'.

Below are more details about the failures:
--------------------------------------------------------------------------------
2 fits failed with the following error:
Traceback (most recent call last):
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\model_selection\_validation.py", line 686, in _fit_and_score
    estimator.fit(X_train, y_train, **fit_params)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 260, in fit
    fitted_estimator = self._memory_fit(
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\joblib\memory.py", line 594, in __call__
    return self._cached_call(args, kwargs)[0]
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\memory.py", line 398, in _cached_call
    out, metadata = self.call(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\memory.py", line 309, in call
    output = self.func(*args, **kwargs)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\pycaret\internal\pipeline.py", line 66, in _fit_one
    transformer.fit(*args, **fit_params)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py", line 622, in fit
    self._solve_svd(X, y)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\discriminant_analysis.py", line 533, in _solve_svd
    _, S, Vt = svd(X, full_matrices=False)
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\scipy\linalg\_decomp_svd.py", line 123, in svd
    lwork = _compute_lwork(gesXd_lwork, a1.shape[0], a1.shape[1],
  File "c:\Users\vande\anaconda3\envs\article\lib\site-packages\scipy\linalg\lapack.py", line 1004, in _compute_lwork
    raise ValueError("Internal work array size computation failed: "
ValueError: Internal work array size computation failed: -10

  warnings.warn(some_fits_failed_message, FitFailedWarning)

2023-05-09 09:36:31,650:INFO:Calculating mean and std
2023-05-09 09:36:31,652:INFO:Creating metrics dataframe
2023-05-09 09:36:32,009:INFO:Uploading results into container
2023-05-09 09:36:32,010:INFO:Uploading model into container now
2023-05-09 09:36:32,011:INFO:_master_model_container: 11
2023-05-09 09:36:32,011:INFO:_display_container: 2
2023-05-09 09:36:32,012:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2023-05-09 09:36:32,012:INFO:create_model() successfully completed......................................
2023-05-09 09:36:32,091:INFO:SubProcess create_model() end ==================================
2023-05-09 09:36:32,091:INFO:Creating metrics dataframe
2023-05-09 09:36:32,108:INFO:Initializing Extra Trees Classifier
2023-05-09 09:36:32,108:INFO:Total runtime is 1.1625781734784444 minutes
2023-05-09 09:36:32,112:INFO:SubProcess create_model() called ==================================
2023-05-09 09:36:32,113:INFO:Initializing create_model()
2023-05-09 09:36:32,114:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F65B31DAB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:36:32,114:INFO:Checking exceptions
2023-05-09 09:36:32,114:INFO:Importing libraries
2023-05-09 09:36:32,114:INFO:Copying training dataset
2023-05-09 09:36:32,120:INFO:Defining folds
2023-05-09 09:36:32,120:INFO:Declaring metric variables
2023-05-09 09:36:32,125:INFO:Importing untrained model
2023-05-09 09:36:32,133:INFO:Extra Trees Classifier Imported successfully
2023-05-09 09:36:32,143:INFO:Starting cross validation
2023-05-09 09:36:32,144:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:36:34,937:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:34,958:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:34,967:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:35,131:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:35,509:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:35,519:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:35,622:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:35,784:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:37,449:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:37,535:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:38,034:INFO:Calculating mean and std
2023-05-09 09:36:38,037:INFO:Creating metrics dataframe
2023-05-09 09:36:38,404:INFO:Uploading results into container
2023-05-09 09:36:38,405:INFO:Uploading model into container now
2023-05-09 09:36:38,406:INFO:_master_model_container: 12
2023-05-09 09:36:38,406:INFO:_display_container: 2
2023-05-09 09:36:38,407:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     n_estimators=100, n_jobs=-1, oob_score=False,
                     random_state=123, verbose=0, warm_start=False)
2023-05-09 09:36:38,407:INFO:create_model() successfully completed......................................
2023-05-09 09:36:38,492:INFO:SubProcess create_model() end ==================================
2023-05-09 09:36:38,493:INFO:Creating metrics dataframe
2023-05-09 09:36:38,514:INFO:Initializing Light Gradient Boosting Machine
2023-05-09 09:36:38,515:INFO:Total runtime is 1.2693604985872904 minutes
2023-05-09 09:36:38,520:INFO:SubProcess create_model() called ==================================
2023-05-09 09:36:38,520:INFO:Initializing create_model()
2023-05-09 09:36:38,521:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F65B31DAB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:36:38,521:INFO:Checking exceptions
2023-05-09 09:36:38,521:INFO:Importing libraries
2023-05-09 09:36:38,521:INFO:Copying training dataset
2023-05-09 09:36:38,530:INFO:Defining folds
2023-05-09 09:36:38,531:INFO:Declaring metric variables
2023-05-09 09:36:38,537:INFO:Importing untrained model
2023-05-09 09:36:38,543:INFO:Light Gradient Boosting Machine Imported successfully
2023-05-09 09:36:38,556:INFO:Starting cross validation
2023-05-09 09:36:38,558:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:36:40,315:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:40,390:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:40,485:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:40,630:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:40,784:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:40,898:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:41,034:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:41,073:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:42,329:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:42,401:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:43,091:INFO:Calculating mean and std
2023-05-09 09:36:43,092:INFO:Creating metrics dataframe
2023-05-09 09:36:43,393:INFO:Uploading results into container
2023-05-09 09:36:43,395:INFO:Uploading model into container now
2023-05-09 09:36:43,395:INFO:_master_model_container: 13
2023-05-09 09:36:43,395:INFO:_display_container: 2
2023-05-09 09:36:43,396:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, silent='warn',
               subsample=1.0, subsample_for_bin=200000, subsample_freq=0)
2023-05-09 09:36:43,396:INFO:create_model() successfully completed......................................
2023-05-09 09:36:43,472:INFO:SubProcess create_model() end ==================================
2023-05-09 09:36:43,472:INFO:Creating metrics dataframe
2023-05-09 09:36:43,489:INFO:Initializing Dummy Classifier
2023-05-09 09:36:43,489:INFO:Total runtime is 1.3522572755813598 minutes
2023-05-09 09:36:43,493:INFO:SubProcess create_model() called ==================================
2023-05-09 09:36:43,494:INFO:Initializing create_model()
2023-05-09 09:36:43,494:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F65B31DAB0>, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:36:43,494:INFO:Checking exceptions
2023-05-09 09:36:43,494:INFO:Importing libraries
2023-05-09 09:36:43,494:INFO:Copying training dataset
2023-05-09 09:36:43,503:INFO:Defining folds
2023-05-09 09:36:43,503:INFO:Declaring metric variables
2023-05-09 09:36:43,509:INFO:Importing untrained model
2023-05-09 09:36:43,516:INFO:Dummy Classifier Imported successfully
2023-05-09 09:36:43,525:INFO:Starting cross validation
2023-05-09 09:36:43,527:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:36:45,221:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:45,313:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:45,457:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:45,510:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:45,634:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:45,712:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:45,799:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:45,895:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:47,316:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:47,389:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:36:48,292:INFO:Calculating mean and std
2023-05-09 09:36:48,294:INFO:Creating metrics dataframe
2023-05-09 09:36:48,628:INFO:Uploading results into container
2023-05-09 09:36:48,629:INFO:Uploading model into container now
2023-05-09 09:36:48,630:INFO:_master_model_container: 14
2023-05-09 09:36:48,630:INFO:_display_container: 2
2023-05-09 09:36:48,631:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2023-05-09 09:36:48,631:INFO:create_model() successfully completed......................................
2023-05-09 09:36:48,708:INFO:SubProcess create_model() end ==================================
2023-05-09 09:36:48,708:INFO:Creating metrics dataframe
2023-05-09 09:36:48,740:INFO:Initializing create_model()
2023-05-09 09:36:48,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:36:48,740:INFO:Checking exceptions
2023-05-09 09:36:48,743:INFO:Importing libraries
2023-05-09 09:36:48,743:INFO:Copying training dataset
2023-05-09 09:36:48,749:INFO:Defining folds
2023-05-09 09:36:48,749:INFO:Declaring metric variables
2023-05-09 09:36:48,750:INFO:Importing untrained model
2023-05-09 09:36:48,750:INFO:Declaring custom model
2023-05-09 09:36:48,750:INFO:Logistic Regression Imported successfully
2023-05-09 09:36:48,751:INFO:Cross validation set to False
2023-05-09 09:36:48,751:INFO:Fitting Model
2023-05-09 09:36:49,915:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-09 09:36:49,915:INFO:create_model() successfully completed......................................
2023-05-09 09:36:50,057:INFO:_master_model_container: 14
2023-05-09 09:36:50,058:INFO:_display_container: 2
2023-05-09 09:36:50,058:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-09 09:36:50,059:INFO:compare_models() successfully completed......................................
2023-05-09 09:36:50,178:INFO:Initializing tune_model()
2023-05-09 09:36:50,178:INFO:tune_model(estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=None, round=4, n_iter=10, custom_grid=None, optimize=Accuracy, custom_scorer=None, search_library=scikit-learn, search_algorithm=None, early_stopping=False, early_stopping_max_iters=10, choose_better=True, fit_kwargs=None, groups=None, return_tuner=False, verbose=True, tuner_verbose=True, return_train_score=False, kwargs={}, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>)
2023-05-09 09:36:50,179:INFO:Checking exceptions
2023-05-09 09:36:50,206:INFO:Copying training dataset
2023-05-09 09:36:50,213:INFO:Checking base model
2023-05-09 09:36:50,214:INFO:Base model : Logistic Regression
2023-05-09 09:36:50,221:INFO:Declaring metric variables
2023-05-09 09:36:50,227:INFO:Defining Hyperparameters
2023-05-09 09:36:50,326:INFO:Tuning with n_jobs=-1
2023-05-09 09:36:50,326:INFO:Initializing RandomizedSearchCV
2023-05-09 09:37:30,374:INFO:best_params: {'actual_estimator__class_weight': 'balanced', 'actual_estimator__C': 0.049}
2023-05-09 09:37:30,376:INFO:Hyperparameter search completed
2023-05-09 09:37:30,376:INFO:SubProcess create_model() called ==================================
2023-05-09 09:37:30,377:INFO:Initializing create_model()
2023-05-09 09:37:30,377:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=True, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000001F64A364610>, model_only=True, return_train_score=False, kwargs={'class_weight': 'balanced', 'C': 0.049})
2023-05-09 09:37:30,377:INFO:Checking exceptions
2023-05-09 09:37:30,377:INFO:Importing libraries
2023-05-09 09:37:30,377:INFO:Copying training dataset
2023-05-09 09:37:30,382:INFO:Defining folds
2023-05-09 09:37:30,382:INFO:Declaring metric variables
2023-05-09 09:37:30,387:INFO:Importing untrained model
2023-05-09 09:37:30,387:INFO:Declaring custom model
2023-05-09 09:37:30,393:INFO:Logistic Regression Imported successfully
2023-05-09 09:37:30,403:INFO:Starting cross validation
2023-05-09 09:37:30,404:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:37:31,832:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:31,886:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:31,938:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:32,091:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:32,201:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:32,292:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:32,461:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:32,588:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:33,708:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:33,752:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:34,558:INFO:Calculating mean and std
2023-05-09 09:37:34,560:INFO:Creating metrics dataframe
2023-05-09 09:37:34,572:INFO:Finalizing model
2023-05-09 09:37:35,728:INFO:Uploading results into container
2023-05-09 09:37:35,730:INFO:Uploading model into container now
2023-05-09 09:37:35,731:INFO:_master_model_container: 15
2023-05-09 09:37:35,731:INFO:_display_container: 3
2023-05-09 09:37:35,732:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-09 09:37:35,732:INFO:create_model() successfully completed......................................
2023-05-09 09:37:35,823:INFO:SubProcess create_model() end ==================================
2023-05-09 09:37:35,824:INFO:choose_better activated
2023-05-09 09:37:35,828:INFO:SubProcess create_model() called ==================================
2023-05-09 09:37:35,829:INFO:Initializing create_model()
2023-05-09 09:37:35,829:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, kwargs={})
2023-05-09 09:37:35,829:INFO:Checking exceptions
2023-05-09 09:37:35,832:INFO:Importing libraries
2023-05-09 09:37:35,832:INFO:Copying training dataset
2023-05-09 09:37:35,837:INFO:Defining folds
2023-05-09 09:37:35,837:INFO:Declaring metric variables
2023-05-09 09:37:35,837:INFO:Importing untrained model
2023-05-09 09:37:35,838:INFO:Declaring custom model
2023-05-09 09:37:35,838:INFO:Logistic Regression Imported successfully
2023-05-09 09:37:35,839:INFO:Starting cross validation
2023-05-09 09:37:35,840:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2023-05-09 09:37:37,688:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:37,774:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:37,862:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:38,063:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:38,078:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:38,288:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:38,496:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:38,504:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:39,919:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:39,982:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\metrics\_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, msg_start, len(result))

2023-05-09 09:37:40,682:INFO:Calculating mean and std
2023-05-09 09:37:40,682:INFO:Creating metrics dataframe
2023-05-09 09:37:40,685:INFO:Finalizing model
2023-05-09 09:37:41,715:INFO:Uploading results into container
2023-05-09 09:37:41,716:INFO:Uploading model into container now
2023-05-09 09:37:41,717:INFO:_master_model_container: 16
2023-05-09 09:37:41,717:INFO:_display_container: 4
2023-05-09 09:37:41,718:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-09 09:37:41,718:INFO:create_model() successfully completed......................................
2023-05-09 09:37:41,796:INFO:SubProcess create_model() end ==================================
2023-05-09 09:37:41,796:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.5
2023-05-09 09:37:41,797:INFO:LogisticRegression(C=0.049, class_weight='balanced', dual=False,
                   fit_intercept=True, intercept_scaling=1, l1_ratio=None,
                   max_iter=1000, multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) result for Accuracy is 0.5
2023-05-09 09:37:41,797:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False) is best model
2023-05-09 09:37:41,797:INFO:choose_better completed
2023-05-09 09:37:41,797:INFO:Original model was better than the tuned model, hence it will be returned. NOTE: The display metrics are for the tuned model (not the original one).
2023-05-09 09:37:41,811:INFO:_master_model_container: 16
2023-05-09 09:37:41,812:INFO:_display_container: 3
2023-05-09 09:37:41,812:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2023-05-09 09:37:41,812:INFO:tune_model() successfully completed......................................
2023-05-09 09:37:42,285:INFO:Initializing plot_model()
2023-05-09 09:37:42,285:INFO:plot_model(plot=confusion_matrix, fold=None, use_train_data=False, verbose=True, display=None, display_format=None, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), feature_name=None, fit_kwargs=None, groups=None, label=False, plot_kwargs=None, save=False, scale=1, self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, system=True)
2023-05-09 09:37:42,286:INFO:Checking exceptions
2023-05-09 09:37:42,292:INFO:Preloading libraries
2023-05-09 09:37:42,293:INFO:Copying training dataset
2023-05-09 09:37:42,293:INFO:Plot type: confusion_matrix
2023-05-09 09:37:42,959:INFO:Fitting Model
2023-05-09 09:37:42,962:WARNING:c:\Users\vande\anaconda3\envs\article\lib\site-packages\sklearn\base.py:439: UserWarning: X does not have valid feature names, but LogisticRegression was fitted with feature names
  warnings.warn(

2023-05-09 09:37:42,962:INFO:Scoring test/hold-out set
2023-05-09 09:37:43,245:INFO:Visual Rendered Successfully
2023-05-09 09:37:43,334:INFO:plot_model() successfully completed......................................
2023-05-09 09:39:38,970:INFO:Initializing predict_model()
2023-05-09 09:39:38,970:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001F664684A60>)
2023-05-09 09:39:38,970:INFO:Checking exceptions
2023-05-09 09:39:38,971:INFO:Preloading libraries
2023-05-09 09:40:52,998:INFO:Initializing predict_model()
2023-05-09 09:40:52,999:INFO:predict_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x000001F6631DA230>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, replace_labels_in_column=<function _SupervisedExperiment.predict_model.<locals>.replace_labels_in_column at 0x000001F664685630>)
2023-05-09 09:40:52,999:INFO:Checking exceptions
2023-05-09 09:40:52,999:INFO:Preloading libraries
2023-05-09 09:40:53,002:INFO:Set up data.
2023-05-09 09:40:53,005:INFO:Set up index.
